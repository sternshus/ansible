--- ./docsite/build-site.py	(original)
+++ ./docsite/build-site.py	(refactored)
@@ -24,9 +24,9 @@
 try:
     from sphinx.application import Sphinx
 except ImportError:
-    print "#################################"
-    print "Dependency missing: Python Sphinx"
-    print "#################################"
+    print("#################################")
+    print("Dependency missing: Python Sphinx")
+    print("#################################")
     sys.exit(1)
 import os
 
@@ -40,7 +40,7 @@
         """
         Run the DocCommand.
         """
-        print "Creating html documentation ..."
+        print("Creating html documentation ...")
 
         try:
             buildername = 'html'
@@ -69,10 +69,10 @@
 
             app.builder.build_all()
 
-        except ImportError, ie:
+        except ImportError as ie:
             traceback.print_exc()
-        except Exception, ex:
-            print >> sys.stderr, "FAIL! exiting ... (%s)" % ex
+        except Exception as ex:
+            print("FAIL! exiting ... (%s)" % ex, file=sys.stderr)
 
     def build_docs(self):
         self.app.builder.build_all()
@@ -83,9 +83,9 @@
 
 if __name__ == '__main__':
     if '-h' in sys.argv or '--help' in sys.argv:
-        print "This script builds the html documentation from rst/asciidoc sources.\n"
-        print "    Run 'make docs' to build everything."
-        print "    Run 'make viewdocs' to build and then preview in a web browser."
+        print("This script builds the html documentation from rst/asciidoc sources.\n")
+        print("    Run 'make docs' to build everything.")
+        print("    Run 'make viewdocs' to build and then preview in a web browser.")
         sys.exit(0)
 
     build_rst_docs()
@@ -93,4 +93,4 @@
     if "view" in sys.argv:
         import webbrowser
         if not webbrowser.open('htmlout/index.html'):
-            print >> sys.stderr, "Could not open on your webbrowser."
+            print("Could not open on your webbrowser.", file=sys.stderr)
--- ./examples/scripts/uptime.py	(original)
+++ ./examples/scripts/uptime.py	(refactored)
@@ -12,20 +12,20 @@
 ).run()
 
 if results is None:
-   print "No hosts found"
+   print("No hosts found")
    sys.exit(1)
 
-print "UP ***********"
-for (hostname, result) in results['contacted'].items():
+print("UP ***********")
+for (hostname, result) in list(results['contacted'].items()):
     if not 'failed' in result:
-        print "%s >>> %s" % (hostname, result['stdout'])
+        print("%s >>> %s" % (hostname, result['stdout']))
 
-print "FAILED *******"
-for (hostname, result) in results['contacted'].items():
+print("FAILED *******")
+for (hostname, result) in list(results['contacted'].items()):
     if 'failed' in result:
-        print "%s >>> %s" % (hostname, result['msg'])
+        print("%s >>> %s" % (hostname, result['msg']))
 
-print "DOWN *********"
-for (hostname, result) in results['dark'].items():
-    print "%s >>> %s" % (hostname, result)
+print("DOWN *********")
+for (hostname, result) in list(results['dark'].items()):
+    print("%s >>> %s" % (hostname, result))
 
--- ./examples/scripts/yaml_to_ini.py	(original)
+++ ./examples/scripts/yaml_to_ini.py	(refactored)
@@ -69,7 +69,7 @@
 
                 for subresult in item.get('hosts',[]):
 
-                    if type(subresult) in [ str, unicode ]:
+                    if type(subresult) in [ str, str ]:
                         host = self._make_host(subresult)
                         group.add_host(host)
                         grouped_hosts.append(host)
@@ -78,10 +78,10 @@
                         vars = subresult.get('vars',{})
                         if type(vars) == list:
                             for subitem in vars:
-                                for (k,v) in subitem.items():
+                                for (k,v) in list(subitem.items()):
                                     host.set_variable(k,v)
                         elif type(vars) == dict:
-                            for (k,v) in subresult.get('vars',{}).items():
+                            for (k,v) in list(subresult.get('vars',{}).items()):
                                 host.set_variable(k,v)
                         else:
                             raise errors.AnsibleError("unexpected type for variable")
@@ -90,13 +90,13 @@
 
                 vars = item.get('vars',{})
                 if type(vars) == dict:
-                    for (k,v) in item.get('vars',{}).items():
+                    for (k,v) in list(item.get('vars',{}).items()):
                         group.set_variable(k,v)
                 elif type(vars) == list:
                     for subitem in vars:
                         if type(subitem) != dict:
                             raise errors.AnsibleError("expected a dictionary")
-                        for (k,v) in subitem.items():
+                        for (k,v) in list(subitem.items()):
                             group.set_variable(k,v)
 
                 self.groups[group.name] = group
@@ -104,7 +104,7 @@
 
         # add host definitions
         for item in yaml:
-            if type(item) in [ str, unicode ]:
+            if type(item) in [ str, str ]:
                 host = self._make_host(item)
                 if host not in grouped_hosts:
                     ungrouped.add_host(host)
@@ -117,11 +117,11 @@
                     varlist, vars = vars, {}
                     for subitem in varlist:
                         vars.update(subitem)
-                for (k,v) in vars.items():
+                for (k,v) in list(vars.items()):
                     host.set_variable(k,v)
 
                 groups = item.get('groups', {})
-                if type(groups) in [ str, unicode ]:
+                if type(groups) in [ str, str ]:
                     groups = [ groups ]
                 if type(groups)==list:
                     for subitem in groups:
@@ -142,7 +142,7 @@
 
 if __name__ == "__main__":
     if len(sys.argv) != 2:
-        print "usage: yaml_to_ini.py /path/to/ansible/hosts"
+        print("usage: yaml_to_ini.py /path/to/ansible/hosts")
         sys.exit(1)
 
     result = ""
@@ -151,7 +151,7 @@
     yamlp = InventoryParserYaml(filename=sys.argv[1])
     dirname = os.path.dirname(original)
 
-    group_names = [ g.name for g in yamlp.groups.values() ]
+    group_names = [ g.name for g in list(yamlp.groups.values()) ]
 
     for group_name in sorted(group_names):
 
@@ -168,21 +168,21 @@
 
         groupfiledir = os.path.join(dirname, "group_vars")
         if not os.path.exists(groupfiledir):
-            print "* creating: %s" % groupfiledir
+            print("* creating: %s" % groupfiledir)
             os.makedirs(groupfiledir)
         groupfile = os.path.join(groupfiledir, group_name)
-        print "* writing group variables for %s into %s" % (group_name, groupfile)
+        print("* writing group variables for %s into %s" % (group_name, groupfile))
         groupfh = open(groupfile, 'w')
         groupfh.write(yaml.dump(record.get_variables()))
         groupfh.close()
 
-    for (host_name, host_record) in yamlp._hosts.iteritems():
+    for (host_name, host_record) in yamlp._hosts.items():
         hostfiledir = os.path.join(dirname, "host_vars")
         if not os.path.exists(hostfiledir):
-            print "* creating: %s" % hostfiledir
+            print("* creating: %s" % hostfiledir)
             os.makedirs(hostfiledir)
         hostfile = os.path.join(hostfiledir, host_record.name)
-        print "* writing host variables for %s into %s" % (host_record.name, hostfile)
+        print("* writing host variables for %s into %s" % (host_record.name, hostfile))
         hostfh = open(hostfile, 'w')
         hostfh.write(yaml.dump(host_record.get_variables()))
         hostfh.close()
@@ -197,10 +197,10 @@
     fdh.write(result)
     fdh.close()
 
-    print "* COMPLETE: review your new inventory file and replace your original when ready"
-    print "*           new inventory file saved as %s" % newfilepath
-    print "*           edit group specific variables in %s/group_vars/" % dirname
-    print "*           edit host specific variables in %s/host_vars/" % dirname
+    print("* COMPLETE: review your new inventory file and replace your original when ready")
+    print("*           new inventory file saved as %s" % newfilepath)
+    print("*           edit group specific variables in %s/group_vars/" % dirname)
+    print("*           edit host specific variables in %s/host_vars/" % dirname)
 
     # now need to write this to disk as (oldname).new
     # and inform the user
--- ./hacking/get_library.py	(original)
+++ ./hacking/get_library.py	(refactored)
@@ -22,7 +22,7 @@
 import sys
 
 def main():
-    print C.DEFAULT_MODULE_PATH
+    print(C.DEFAULT_MODULE_PATH)
     return 0
 
 if __name__ == '__main__':
--- ./hacking/module_formatter.py	(original)
+++ ./hacking/module_formatter.py	(refactored)
@@ -115,7 +115,7 @@
         f.write(text.encode('utf-8'))
         f.close()
     else:
-        print text
+        print(text)
 
 #####################################################################################
 
@@ -133,7 +133,7 @@
             if os.path.isdir(d):
 
                 res = list_modules(d, depth + 1)
-                for key in res.keys():
+                for key in list(res.keys()):
                     if key in categories:
                         categories[key] = ansible.utils.merge_hash(categories[key], res[key])
                         res.pop(key, None)
@@ -233,7 +233,7 @@
         deprecated = True
         module = module.replace("_","",1)
 
-    print "rendering: %s" % module
+    print("rendering: %s" % module)
 
     # use ansible core library to parse out doc metadata YAML and plaintext examples
     doc, examples, returndocs= ansible.utils.module_docs.get_docstring(fname, verbose=options.verbose)
@@ -278,7 +278,7 @@
         if added and added_float < TO_OLD_TO_BE_NOTABLE:
             del doc['version_added']
 
-    for (k,v) in doc['options'].iteritems():
+    for (k,v) in doc['options'].items():
         all_keys.append(k)
 
     all_keys = sorted(all_keys)
@@ -322,7 +322,7 @@
 
     category_file_path = os.path.join(options.output_dir, "list_of_%s_modules.rst" % category)
     category_file = open(category_file_path, "w")
-    print "*** recording category %s in %s ***" % (category, category_file_path)
+    print("*** recording category %s in %s ***" % (category, category_file_path))
 
     # TODO: start a new category file
 
@@ -332,10 +332,10 @@
     modules = []
     deprecated = []
     core = []
-    for module in module_map.keys():
+    for module in list(module_map.keys()):
 
         if isinstance(module_map[module], dict):
-            for mod in module_map[module].keys():
+            for mod in list(module_map[module].keys()):
                 if mod.startswith("_"):
                     mod = mod.replace("_","",1)
                     deprecated.append(mod)
@@ -375,7 +375,7 @@
         category_file.write("\n%s\n%s\n\n" % (section.replace("_"," ").title(),'-' * len(section)))
         category_file.write(".. toctree:: :maxdepth: 1\n\n")
 
-        section_modules = module_map[section].keys()
+        section_modules = list(module_map[section].keys())
         section_modules.sort()
         #for module in module_map[section]:
         for module in section_modules:
@@ -397,13 +397,13 @@
     ''' validate option parser options '''
 
     if not options.module_dir:
-        print >>sys.stderr, "--module-dir is required"
+        print("--module-dir is required", file=sys.stderr)
         sys.exit(1)
     if not os.path.exists(options.module_dir):
-        print >>sys.stderr, "--module-dir does not exist: %s" % options.module_dir
+        print("--module-dir does not exist: %s" % options.module_dir, file=sys.stderr)
         sys.exit(1)
     if not options.template_dir:
-        print "--template-dir must be specified"
+        print("--template-dir must be specified")
         sys.exit(1)
 
 #####################################################################################
@@ -419,7 +419,7 @@
 
     categories = list_modules(options.module_dir)
     last_category = None
-    category_names = categories.keys()
+    category_names = list(categories.keys())
     category_names.sort()
 
     category_list_path = os.path.join(options.output_dir, "modules_by_category.rst")
--- ./lib/ansible/callbacks.py	(original)
+++ ./lib/ansible/callbacks.py	(refactored)
@@ -27,7 +27,7 @@
 import fnmatch
 import tempfile
 import fcntl
-import constants
+from . import constants
 import locale
 from ansible.color import stringc
 from ansible.module_utils import basic
@@ -149,12 +149,12 @@
             try:
                 print(msg2)
             except UnicodeEncodeError:
-                print(msg2.encode('utf-8'))
+                print((msg2.encode('utf-8')))
         else:
             try:
-                print >>sys.stderr, msg2
+                print(msg2, file=sys.stderr)
             except UnicodeEncodeError:
-                print >>sys.stderr, msg2.encode('utf-8')
+                print(msg2.encode('utf-8'), file=sys.stderr)
     if constants.DEFAULT_LOG_PATH != '':
         while msg.startswith("\n"):
             msg = msg.replace("\n","")
@@ -219,7 +219,7 @@
     def compute(self, runner_results, setup=False, poll=False, ignore_errors=False):
         ''' walk through all results and increment stats '''
 
-        for (host, value) in runner_results.get('contacted', {}).iteritems():
+        for (host, value) in runner_results.get('contacted', {}).items():
             if not ignore_errors and (('failed' in value and bool(value['failed'])) or
                 ('failed_when_result' in value and [value['failed_when_result']] or ['rc' in value and value['rc'] != 0])[0]):
                 self._increment('failures', host)
@@ -233,7 +233,7 @@
                 if not poll or ('finished' in value and bool(value['finished'])):
                     self._increment('ok', host)
 
-        for (host, value) in runner_results.get('dark', {}).iteritems():
+        for (host, value) in runner_results.get('dark', {}).items():
             self._increment('dark', host)
 
 
@@ -461,12 +461,12 @@
         item = None
         if type(results) == dict:
             item = results.get('item', None)
-            if isinstance(item, unicode):
-                item = utils.unicode.to_bytes(item)
+            if isinstance(item, str):
+                item = utils.str.to_bytes(item)
             results = basic.json_dict_unicode_to_bytes(results)
         else:
-            results = utils.unicode.to_bytes(results)
-        host = utils.unicode.to_bytes(host)
+            results = utils.str.to_bytes(results)
+        host = utils.str.to_bytes(host)
         if item:
             msg = "fatal: [%s] => (item=%s) => %s" % (host, item, results)
         else:
@@ -614,13 +614,13 @@
         call_callback_module('playbook_on_no_hosts_remaining')
 
     def on_task_start(self, name, is_conditional):
-        name = utils.unicode.to_bytes(name)
+        name = utils.str.to_bytes(name)
         msg = "TASK: [%s]" % name
         if is_conditional:
             msg = "NOTIFIED: [%s]" % name
 
         if hasattr(self, 'start_at'):
-            self.start_at = utils.unicode.to_bytes(self.start_at)
+            self.start_at = utils.str.to_bytes(self.start_at)
             if name == self.start_at or fnmatch.fnmatch(name, self.start_at):
                 # we found out match, we can get rid of this now
                 del self.start_at
@@ -634,13 +634,13 @@
             self.skip_task = True
         elif hasattr(self, 'step') and self.step:
             if isinstance(name, str):
-                name = utils.unicode.to_unicode(name)
-            msg = u'Perform task: %s (y/n/c): ' % name
+                name = utils.str.to_unicode(name)
+            msg = 'Perform task: %s (y/n/c): ' % name
             if sys.stdout.encoding:
                 msg = to_bytes(msg, sys.stdout.encoding)
             else:
                 msg = to_bytes(msg)
-            resp = raw_input(msg)
+            resp = input(msg)
             if resp.lower() in ['y','yes']:
                 self.skip_task = False
                 display(banner(msg))
@@ -675,7 +675,7 @@
                 msg = prompt.encode(locale.getpreferredencoding())
             if private:
                 return getpass.getpass(msg)
-            return raw_input(msg)
+            return input(msg)
 
 
         if confirm:
@@ -726,4 +726,4 @@
         call_callback_module('playbook_on_stats', stats)
 
 
-from ansible.utils.unicode import to_unicode, to_bytes
+from ansible.utils.str import to_unicode, to_bytes
--- ./lib/ansible/color.py	(original)
+++ ./lib/ansible/color.py	(refactored)
@@ -16,7 +16,7 @@
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
 import sys
-import constants
+from . import constants
 
 ANSIBLE_COLOR=True
 if constants.ANSIBLE_NOCOLOR:
--- ./lib/ansible/constants.py	(original)
+++ ./lib/ansible/constants.py	(refactored)
@@ -74,7 +74,7 @@
             try:
                 p.read(path)
             except ConfigParser.Error as e:
-                print("Error reading config file: \n%s" % e)
+                print(("Error reading config file: \n%s" % e))
                 sys.exit(1)
             return p
     return None
--- ./lib/ansible/cache/__init__.py	(original)
+++ ./lib/ansible/cache/__init__.py	(refactored)
@@ -44,17 +44,17 @@
         return self._plugin.contains(key)
 
     def __iter__(self):
-        return iter(self._plugin.keys())
+        return iter(list(self._plugin.keys()))
 
     def __len__(self):
-        return len(self._plugin.keys())
+        return len(list(self._plugin.keys()))
 
     def copy(self):
         """ Return a primitive copy of the keys and values from the cache. """
-        return dict([(k, v) for (k, v) in self.iteritems()])
+        return dict([(k, v) for (k, v) in self.items()])
 
     def keys(self):
-        return self._plugin.keys()
+        return list(self._plugin.keys())
 
     def flush(self):
         """ Flush the fact cache of all keys. """
--- ./lib/ansible/cache/jsonfile.py	(original)
+++ ./lib/ansible/cache/jsonfile.py	(refactored)
@@ -118,7 +118,7 @@
         try:
             st = os.stat("%s/%s" % (self._cache_dir, key))
             return True
-        except (OSError,IOError)as e:
+        except (OSError,IOError) as e:
             if e.errno == errno.ENOENT:
                 return False
             else:
@@ -133,11 +133,11 @@
 
     def flush(self):
         self._cache = {}
-        for key in self.keys():
+        for key in list(self.keys()):
             self.delete(key)
 
     def copy(self):
         ret = dict()
-        for key in self.keys():
+        for key in list(self.keys()):
             ret[key] = self.get(key)
         return ret
--- ./lib/ansible/cache/memcached.py	(original)
+++ ./lib/ansible/cache/memcached.py	(refactored)
@@ -129,7 +129,7 @@
         self._cache.set(self.PREFIX, self._keyset)
 
     def remove_by_timerange(self, s_min, s_max):
-        for k in self._keyset.keys():
+        for k in list(self._keyset.keys()):
             t = self._keyset[k]
             if s_min < t < s_max:
                 del self._keyset[k]
@@ -184,7 +184,7 @@
         self._keys.discard(key)
 
     def flush(self):
-        for key in self.keys():
+        for key in list(self.keys()):
             self.delete(key)
 
     def copy(self):
--- ./lib/ansible/cache/memory.py	(original)
+++ ./lib/ansible/cache/memory.py	(refactored)
@@ -29,7 +29,7 @@
         self._cache[key] = value
 
     def keys(self):
-        return self._cache.keys()
+        return list(self._cache.keys())
 
     def contains(self, key):
         return key in self._cache
--- ./lib/ansible/cache/redis.py	(original)
+++ ./lib/ansible/cache/redis.py	(refactored)
@@ -15,7 +15,7 @@
 # You should have received a copy of the GNU General Public License
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
-from __future__ import absolute_import
+
 import collections
 # FIXME: can we store these as something else before we ship it?
 import sys
@@ -96,12 +96,12 @@
         self._cache.zrem(self._keys_set, key)
 
     def flush(self):
-        for key in self.keys():
+        for key in list(self.keys()):
             self.delete(key)
 
     def copy(self):
         # FIXME: there is probably a better way to do this in redis
         ret = dict()
-        for key in self.keys():
+        for key in list(self.keys()):
             ret[key] = self.get(key)
         return ret
--- ./lib/ansible/inventory/__init__.py	(original)
+++ ./lib/ansible/inventory/__init__.py	(refactored)
@@ -98,7 +98,7 @@
                 # Ensure basedir is inside the directory
                 self.host_list = os.path.join(self.host_list, "")
                 self.parser = InventoryDirectory(filename=host_list)
-                self.groups = self.parser.groups.values()
+                self.groups = list(self.parser.groups.values())
             else:
                 # check to see if the specified file starts with a
                 # shebang (#!/), so if an error is raised by the parser
@@ -116,7 +116,7 @@
                 if utils.is_executable(host_list):
                     try:
                         self.parser = InventoryScript(filename=host_list)
-                        self.groups = self.parser.groups.values()
+                        self.groups = list(self.parser.groups.values())
                     except:
                         if not shebang_present:
                             raise errors.AnsibleError("The file %s is marked as executable, but failed to execute correctly. " % host_list + \
@@ -126,7 +126,7 @@
                 else:
                     try:
                         self.parser = InventoryParser(filename=host_list)
-                        self.groups = self.parser.groups.values()
+                        self.groups = list(self.parser.groups.values())
                     except:
                         if shebang_present:
                             raise errors.AnsibleError("The file %s looks like it should be an executable inventory script, but is not marked executable. " % host_list + \
--- ./lib/ansible/inventory/dir.py	(original)
+++ ./lib/ansible/inventory/dir.py	(refactored)
@@ -61,7 +61,7 @@
             # retrieve all groups and hosts form the parser and add them to
             # self, don't look at group lists yet, to avoid
             # recursion trouble, but just make sure all objects exist in self
-            newgroups = parser.groups.values()
+            newgroups = list(parser.groups.values())
             for group in newgroups:
                 for host in group.hosts:
                     self._add_host(host)
@@ -71,7 +71,7 @@
             # now check the objects lists so they contain only objects from
             # self; membership data in groups is already fine (except all &
             # ungrouped, see later), but might still reference objects not in self
-            for group in self.groups.values():
+            for group in list(self.groups.values()):
                 # iterate on a copy of the lists, as those lists get changed in
                 # the loop
                 # list with group's child group objects:
--- ./lib/ansible/inventory/expand_hosts.py	(original)
+++ ./lib/ansible/inventory/expand_hosts.py	(refactored)
@@ -103,7 +103,7 @@
                 raise errors.AnsibleError("host range format incorrectly specified!")
             seq = string.ascii_letters[i_beg:i_end+1]
         except ValueError:  # not an alpha range
-            seq = range(int(beg), int(end)+1, int(step))
+            seq = list(range(int(beg), int(end)+1, int(step)))
 
         for rseq in seq:
             hname = ''.join((head, fill(rseq), tail))
--- ./lib/ansible/inventory/group.py	(original)
+++ ./lib/ansible/inventory/group.py	(refactored)
@@ -113,5 +113,5 @@
 
     def get_ancestors(self):
 
-        return self._get_ancestors().values()
+        return list(self._get_ancestors().values())
 
--- ./lib/ansible/inventory/host.py	(original)
+++ ./lib/ansible/inventory/host.py	(refactored)
@@ -50,7 +50,7 @@
             ancestors = g.get_ancestors()
             for a in ancestors:
                 groups[a.name] = a
-        return groups.values()
+        return list(groups.values())
 
     def get_variables(self):
 
--- ./lib/ansible/inventory/ini.py	(original)
+++ ./lib/ansible/inventory/ini.py	(refactored)
@@ -76,7 +76,7 @@
 
     def _add_allgroup_children(self):
 
-        for group in self.groups.values():
+        for group in list(self.groups.values()):
             if group.depth == 0 and group.name != 'all':
                 self.groups['all'].add_child_group(group)
 
--- ./lib/ansible/inventory/script.py	(original)
+++ ./lib/ansible/inventory/script.py	(refactored)
@@ -70,7 +70,7 @@
             sys.stderr.write(err + "\n")
             raise errors.AnsibleError("failed to parse executable inventory script results: %s" % self.raw)
 
-        for (group_name, data) in self.raw.items():
+        for (group_name, data) in list(self.raw.items()):
 
             # in Ansible 1.3 and later, a "_meta" subelement may contain
             # a variable "hostvars" which contains a hash for each host
@@ -111,14 +111,14 @@
                     raise errors.AnsibleError("You defined a group \"%s\" with bad "
                         "data for variables:\n %s" % (group_name, data))
 
-                for k, v in data['vars'].iteritems():
+                for k, v in data['vars'].items():
                     if group.name == all.name:
                         all.set_variable(k, v)
                     else:
                         group.set_variable(k, v)
 
         # Separate loop to ensure all groups are defined
-        for (group_name, data) in self.raw.items():
+        for (group_name, data) in list(self.raw.items()):
             if group_name == '_meta':
                 continue
             if isinstance(data, dict) and 'children' in data:
@@ -126,7 +126,7 @@
                     if child_name in groups:
                         groups[group_name].add_child_group(groups[child_name])
 
-        for group in groups.values():
+        for group in list(groups.values()):
             if group.depth == 0 and group.name != 'all':
                 all.add_child_group(group)
 
--- ./lib/ansible/module_utils/basic.py	(original)
+++ ./lib/ansible/module_utils/basic.py	(refactored)
@@ -67,6 +67,7 @@
 import platform
 import errno
 import tempfile
+from functools import reduce
 
 try:
     import json
@@ -250,10 +251,10 @@
         and dict container types (the containers that the json module returns)
     '''
 
-    if isinstance(d, unicode):
+    if isinstance(d, str):
         return d.encode('utf-8')
     elif isinstance(d, dict):
-        return dict(map(json_dict_unicode_to_bytes, d.iteritems()))
+        return dict(list(map(json_dict_unicode_to_bytes, iter(d.items()))))
     elif isinstance(d, list):
         return list(map(json_dict_unicode_to_bytes, d))
     elif isinstance(d, tuple):
@@ -269,9 +270,9 @@
     '''
 
     if isinstance(d, str):
-        return unicode(d, 'utf-8')
+        return str(d, 'utf-8')
     elif isinstance(d, dict):
-        return dict(map(json_dict_bytes_to_unicode, d.iteritems()))
+        return dict(list(map(json_dict_bytes_to_unicode, iter(d.items()))))
     elif isinstance(d, list):
         return list(map(json_dict_bytes_to_unicode, d))
     elif isinstance(d, tuple):
@@ -360,7 +361,7 @@
         self.aliases = {}
         
         if add_file_common_args:
-            for k, v in FILE_COMMON_ARGUMENTS.iteritems():
+            for k, v in FILE_COMMON_ARGUMENTS.items():
                 if k not in self.argument_spec:
                     self.argument_spec[k] = v
 
@@ -486,7 +487,7 @@
         that your filesystem encoding is UTF-8.
 
         '''
-        if isinstance(path, unicode):
+        if isinstance(path, str):
             path = path.encode("utf-8")
         return path
 
@@ -789,7 +790,7 @@
         }
 
         # Insert X_perms into user_perms_to_modes
-        for key, value in X_perms.items():
+        for key, value in list(X_perms.items()):
             user_perms_to_modes[key].update(value)
 
         or_reduce = lambda mode, perm: mode | user_perms_to_modes[user][perm]
@@ -879,7 +880,7 @@
 
     def _handle_aliases(self):
         aliases_results = {} #alias:canon
-        for (k,v) in self.argument_spec.iteritems():
+        for (k,v) in self.argument_spec.items():
             self._legal_inputs.append(k)
             aliases = v.get('aliases', None)
             default = v.get('default', None)
@@ -900,7 +901,7 @@
         return aliases_results
 
     def _check_for_check_mode(self):
-        for (k,v) in self.params.iteritems():
+        for (k,v) in self.params.items():
             if k == 'CHECKMODE':
                 if not self.supports_check_mode:
                     self.exit_json(skipped=True, msg="remote module does not support check mode")
@@ -908,12 +909,12 @@
                     self.check_mode = True
 
     def _check_for_no_log(self):
-        for (k,v) in self.params.iteritems():
+        for (k,v) in self.params.items():
             if k == 'NO_LOG':
                 self.no_log = self.boolean(v)
 
     def _check_invalid_arguments(self):
-        for (k,v) in self.params.iteritems():
+        for (k,v) in self.params.items():
             # these should be in legal inputs already
             #if k in ('CHECKMODE', 'NO_LOG'):
             #    continue
@@ -956,7 +957,7 @@
     def _check_required_arguments(self):
         ''' ensure all required arguments are present '''
         missing = []
-        for (k,v) in self.argument_spec.iteritems():
+        for (k,v) in self.argument_spec.items():
             required = v.get('required', False)
             if required and k not in self.params:
                 missing.append(k)
@@ -965,7 +966,7 @@
 
     def _check_argument_values(self):
         ''' ensure all arguments have the requested values, and there are no stray arguments '''
-        for (k,v) in self.argument_spec.iteritems():
+        for (k,v) in self.argument_spec.items():
             choices = v.get('choices',None)
             if choices is None:
                 continue
@@ -981,7 +982,7 @@
     def safe_eval(self, str, locals=None, include_exceptions=False):
 
         # do not allow method calls to modules
-        if not isinstance(str, str):
+        if not isinstance(str, str):
             # already templated to a datastructure, perhaps?
             if include_exceptions:
                 return (str, None)
@@ -1012,7 +1013,7 @@
 
     def _check_argument_types(self):
         ''' ensure all arguments have the requested type '''
-        for (k, v) in self.argument_spec.iteritems():
+        for (k, v) in self.argument_spec.items():
             wanted = v.get('type', None)
             if wanted is None:
                 continue
@@ -1023,11 +1024,11 @@
             is_invalid = False
 
             if wanted == 'str':
-                if not isinstance(value, str):
+                if not isinstance(value, str):
                     self.params[k] = str(value)
             elif wanted == 'list':
                 if not isinstance(value, list):
-                    if isinstance(value, str):
+                    if isinstance(value, str):
                         self.params[k] = value.split(",")
                     elif isinstance(value, int) or isinstance(value, float):
                         self.params[k] = [ str(value) ]
@@ -1035,7 +1036,7 @@
                         is_invalid = True
             elif wanted == 'dict':
                 if not isinstance(value, dict):
-                    if isinstance(value, str):
+                    if isinstance(value, str):
                         if value.startswith("{"):
                             try:
                                 self.params[k] = json.loads(value)
@@ -1052,19 +1053,19 @@
                         is_invalid = True
             elif wanted == 'bool':
                 if not isinstance(value, bool):
-                    if isinstance(value, str):
+                    if isinstance(value, str):
                         self.params[k] = self.boolean(value)
                     else:
                         is_invalid = True
             elif wanted == 'int':
                 if not isinstance(value, int):
-                    if isinstance(value, str):
+                    if isinstance(value, str):
                         self.params[k] = int(value)
                     else:
                         is_invalid = True
             elif wanted == 'float':
                 if not isinstance(value, float):
-                    if isinstance(value, str):
+                    if isinstance(value, str):
                         self.params[k] = float(value)
                     else:
                         is_invalid = True
@@ -1075,7 +1076,7 @@
                 self.fail_json(msg="argument %s is of invalid type: %s, required: %s" % (k, type(value), wanted))
 
     def _set_defaults(self, pre=True):
-        for (k,v) in self.argument_spec.iteritems():
+        for (k,v) in self.argument_spec.items():
             default = v.get('default', None)
             if pre == True:
                 # this prevents setting defaults on required items
@@ -1121,9 +1122,9 @@
                 log_args[param] = 'NOT_LOGGING_PASSWORD'
             else:
                 param_val = self.params[param]
-                if not isinstance(param_val, str):
+                if not isinstance(param_val, str):
                     param_val = str(param_val)
-                elif isinstance(param_val, unicode):
+                elif isinstance(param_val, str):
                     param_val = param_val.encode('utf-8')
                 log_args[param] = heuristic_log_sanitize(param_val)
 
@@ -1131,9 +1132,9 @@
         msg = []
         for arg in log_args:
             arg_val = log_args[arg]
-            if not isinstance(arg_val, str):
+            if not isinstance(arg_val, str):
                 arg_val = str(arg_val)
-            elif isinstance(arg_val, unicode):
+            elif isinstance(arg_val, str):
                 arg_val = arg_val.encode('utf-8')
             msg.append('%s=%s ' % (arg, arg_val))
         if msg:
@@ -1142,7 +1143,7 @@
             msg = 'Invoked'
 
         # 6655 - allow for accented characters
-        if isinstance(msg, unicode):
+        if isinstance(msg, str):
             # We should never get here as msg should be type str, not unicode
             msg = msg.encode('utf-8')
 
@@ -1212,7 +1213,7 @@
         ''' return a bool for the arg '''
         if arg is None or type(arg) == bool:
             return arg
-        if type(arg) in types.StringTypes:
+        if type(arg) in str:
             arg = arg.lower()
         if arg in BOOLEANS_TRUE:
             return True
@@ -1249,7 +1250,7 @@
         if not 'changed' in kwargs:
             kwargs['changed'] = False
         self.do_cleanup_files()
-        print(self.jsonify(kwargs))
+        print((self.jsonify(kwargs)))
         sys.exit(0)
 
     def fail_json(self, **kwargs):
@@ -1258,7 +1259,7 @@
         assert 'msg' in kwargs, "implementation error -- msg to explain the error is required"
         kwargs['failed'] = True
         self.do_cleanup_files()
-        print(self.jsonify(kwargs))
+        print((self.jsonify(kwargs)))
         sys.exit(1)
 
     def is_executable(self, path):
@@ -1438,9 +1439,9 @@
             if use_unsafe_shell:
                 args = " ".join([pipes.quote(x) for x in args])
                 shell = True
-        elif isinstance(args, str) and use_unsafe_shell:
+        elif isinstance(args, str) and use_unsafe_shell:
             shell = True
-        elif isinstance(args, str):
+        elif isinstance(args, str):
             args = shlex.split(args.encode('utf-8'))
         else:
             msg = "Argument 'args' to run_command must be list or string"
@@ -1469,8 +1470,8 @@
         # create a printable version of the command for use
         # in reporting later, which strips out things like
         # passwords from the args list
-        if isinstance(args, str):
-            if isinstance(args, unicode):
+        if isinstance(args, str):
+            if isinstance(args, str):
                 b_args = args.encode('utf-8')
             else:
                 b_args = args
--- ./lib/ansible/module_utils/ec2.py	(original)
+++ ./lib/ansible/module_utils/ec2.py	(refactored)
@@ -168,9 +168,9 @@
     conn = aws_module.connect_to_region(region, **params)
     if not conn:
         if region not in [aws_module_region.name for aws_module_region in aws_module.regions()]:
-            raise StandardError("Region %s does not seem to be available for aws module %s. If the region definitely exists, you may need to upgrade boto" % (region, aws_module.__name__))
-        else:
-            raise StandardError("Unknown problem connecting to region %s for aws module %s." % (region, aws_module.__name__))
+            raise Exception("Region %s does not seem to be available for aws module %s. If the region definitely exists, you may need to upgrade boto" % (region, aws_module.__name__))
+        else:
+            raise Exception("Unknown problem connecting to region %s for aws module %s." % (region, aws_module.__name__))
     if params.get('profile_name'):
         conn = boto_fix_security_token_in_profile(conn, params['profile_name'])
     return conn
@@ -186,13 +186,13 @@
     if region:
         try:
             ec2 = connect_to_aws(boto.ec2, region, **boto_params)
-        except (boto.exception.NoAuthHandlerFound, StandardError), e:
+        except (boto.exception.NoAuthHandlerFound, Exception) as e:
             module.fail_json(msg=str(e))
     # Otherwise, no region so we fallback to the old connection method
     elif ec2_url:
         try:
             ec2 = boto.connect_ec2_endpoint(ec2_url, **boto_params)
-        except (boto.exception.NoAuthHandlerFound, StandardError), e:
+        except (boto.exception.NoAuthHandlerFound, Exception) as e:
             module.fail_json(msg=str(e))
     else:
         module.fail_json(msg="Either region or ec2_url must be specified")
--- ./lib/ansible/module_utils/facts.py	(original)
+++ ./lib/ansible/module_utils/facts.py	(refactored)
@@ -31,10 +31,11 @@
 import datetime
 import getpass
 import pwd
-import ConfigParser
-import StringIO
+import configparser
+import io
 
 from string import maketrans
+from functools import reduce
 
 try:
     import selinux
@@ -214,12 +215,12 @@
             fact = 'loading %s' % fact_base
             try:
                 fact = json.loads(out)
-            except ValueError, e:
+            except ValueError as e:
                 # load raw ini
-                cp = ConfigParser.ConfigParser()
+                cp = configparser.ConfigParser()
                 try:
-                    cp.readfp(StringIO.StringIO(out))
-                except ConfigParser.Error, e:
+                    cp.readfp(io.StringIO(out))
+                except configparser.Error as e:
                     fact="error loading fact - please check content"
                 else:
                     fact = {}
@@ -456,7 +457,7 @@
                         self.facts['cmdline'][item[0]] = True
                     else:
                         self.facts['cmdline'][item[0]] = item[1]
-            except ValueError, e:
+            except ValueError as e:
                 pass
 
     def get_public_ssh_host_keys(self):
@@ -544,7 +545,7 @@
             self.facts['selinux']['status'] = 'enabled'
             try:
                 self.facts['selinux']['policyvers'] = selinux.security_policyvers()
-            except OSError, e:
+            except OSError as e:
                 self.facts['selinux']['policyvers'] = 'unknown'
             try:
                 (rc, configmode) = selinux.selinux_getenforcemode()
@@ -552,12 +553,12 @@
                     self.facts['selinux']['config_mode'] = Facts.SELINUX_MODE_DICT.get(configmode, 'unknown')
                 else:
                     self.facts['selinux']['config_mode'] = 'unknown'
-            except OSError, e:
+            except OSError as e:
                 self.facts['selinux']['config_mode'] = 'unknown'
             try:
                 mode = selinux.security_getenforce()
                 self.facts['selinux']['mode'] = Facts.SELINUX_MODE_DICT.get(mode, 'unknown')
-            except OSError, e:
+            except OSError as e:
                 self.facts['selinux']['mode'] = 'unknown'
             try:
                 (rc, policytype) = selinux.selinux_getpolicytype()
@@ -565,7 +566,7 @@
                     self.facts['selinux']['type'] = policytype
                 else:
                     self.facts['selinux']['type'] = 'unknown'
-            except OSError, e:
+            except OSError as e:
                 self.facts['selinux']['type'] = 'unknown'
 
 
@@ -610,7 +611,7 @@
 
     def get_env_facts(self):
         self.facts['env'] = {}
-        for k,v in os.environ.iteritems():
+        for k,v in os.environ.items():
             self.facts['env'][k] = v
 
 class Hardware(Facts):
@@ -688,11 +689,11 @@
             key = data[0]
             if key in self.ORIGINAL_MEMORY_FACTS:
                 val = data[1].strip().split(' ')[0]
-                self.facts["%s_mb" % key.lower()] = long(val) / 1024
+                self.facts["%s_mb" % key.lower()] = int(val) / 1024
 
             if key in self.MEMORY_FACTS:
                  val = data[1].strip().split(' ')[0]
-                 memstats[key.lower()] = long(val) / 1024
+                 memstats[key.lower()] = int(val) / 1024
 
         if None not in (memstats.get('memtotal'), memstats.get('memfree')):
             memstats['real:used'] = memstats['memtotal'] - memstats['memfree']
@@ -797,9 +798,9 @@
                 self.facts['processor_vcpus'] = i
             else:
                 self.facts['processor_count'] = sockets and len(sockets) or i
-                self.facts['processor_cores'] = sockets.values() and sockets.values()[0] or 1
-                self.facts['processor_threads_per_core'] = ((cores.values() and
-                    cores.values()[0] or 1) / self.facts['processor_cores'])
+                self.facts['processor_cores'] = list(sockets.values()) and list(sockets.values())[0] or 1
+                self.facts['processor_threads_per_core'] = ((list(cores.values()) and
+                    list(cores.values())[0] or 1) / self.facts['processor_cores'])
                 self.facts['processor_vcpus'] = (self.facts['processor_threads_per_core'] *
                     self.facts['processor_count'] * self.facts['processor_cores'])
 
@@ -833,13 +834,13 @@
                     'system_vendor': '/sys/devices/virtual/dmi/id/sys_vendor'
                     }
 
-            for (key,path) in DMI_DICT.items():
+            for (key,path) in list(DMI_DICT.items()):
                 data = get_file_content(path)
                 if data is not None:
                     if key == 'form_factor':
                         try:
                             self.facts['form_factor'] = FORM_FACTOR[int(data)]
-                        except IndexError, e:
+                        except IndexError as e:
                             self.facts['form_factor'] = 'unknown (%s)' % data
                     else:
                         self.facts[key] = data
@@ -859,7 +860,7 @@
                     'product_version': 'system-version',
                     'system_vendor': 'system-manufacturer'
                     }
-            for (k, v) in DMI_DICT.items():
+            for (k, v) in list(DMI_DICT.items()):
                 if dmi_bin is not None:
                     (rc, out, err) = module.run_command('%s -s %s' % (dmi_bin, v))
                     if rc == 0:
@@ -890,7 +891,7 @@
                         statvfs_result = os.statvfs(fields[1])
                         size_total = statvfs_result.f_bsize * statvfs_result.f_blocks
                         size_available = statvfs_result.f_bsize * (statvfs_result.f_bavail)
-                    except OSError, e:
+                    except OSError as e:
                         continue
 
                     uuid = 'NA'
@@ -930,7 +931,7 @@
             sysfs_no_links = 0
             try:
                 path = os.readlink(os.path.join("/sys/block/", block))
-            except OSError, e:
+            except OSError as e:
                 if e.errno == errno.EINVAL:
                     path = block
                     sysfs_no_links = 1
@@ -1069,7 +1070,7 @@
         # these processors have: sockets -> cores -> threads/virtual CPU.
         if len(sockets) > 0:
             self.facts['processor_count'] = len(sockets)
-            self.facts['processor_cores'] = reduce(lambda x, y: x + y, sockets.values())
+            self.facts['processor_cores'] = reduce(lambda x, y: x + y, list(sockets.values()))
         else:
             self.facts['processor_cores'] = 'NA'
             self.facts['processor_count'] = len(self.facts['processor'])
@@ -1080,10 +1081,10 @@
             if 'Memory size' in line:
                 self.facts['memtotal_mb'] = line.split()[2]
         rc, out, err = module.run_command("/usr/sbin/swap -s")
-        allocated = long(out.split()[1][:-1])
-        reserved = long(out.split()[5][:-1])
-        used = long(out.split()[8][:-1])
-        free = long(out.split()[10][:-1])
+        allocated = int(out.split()[1][:-1])
+        reserved = int(out.split()[5][:-1])
+        used = int(out.split()[8][:-1])
+        free = int(out.split()[10][:-1])
         self.facts['swapfree_mb'] = free / 1024
         self.facts['swaptotal_mb'] = (free + used) / 1024
         self.facts['swap_allocated_mb'] = allocated / 1024
@@ -1157,8 +1158,8 @@
         #  0 0 0  47512   28160   51   0   0   0   0   0   1   0  116    89   17  0  1 99
         rc, out, err = module.run_command("/usr/bin/vmstat")
         if rc == 0:
-            self.facts['memfree_mb'] = long(out.splitlines()[-1].split()[4]) / 1024
-            self.facts['memtotal_mb'] = long(self.sysctl['hw.usermem']) / 1024 / 1024
+            self.facts['memfree_mb'] = int(out.splitlines()[-1].split()[4]) / 1024
+            self.facts['memtotal_mb'] = int(self.sysctl['hw.usermem']) / 1024 / 1024
 
         # Get swapctl info. swapctl output looks like:
         # total: 69268 1K-blocks allocated, 0 used, 69268 available
@@ -1168,8 +1169,8 @@
         if rc == 0:
             swaptrans = maketrans(' ', ' ')
             data = out.split()
-            self.facts['swapfree_mb'] = long(data[-2].translate(swaptrans, "kmg")) / 1024
-            self.facts['swaptotal_mb'] = long(data[1].translate(swaptrans, "kmg")) / 1024
+            self.facts['swapfree_mb'] = int(data[-2].translate(swaptrans, "kmg")) / 1024
+            self.facts['swaptotal_mb'] = int(data[1].translate(swaptrans, "kmg")) / 1024
 
     def get_processor_facts(self):
         processor = []
@@ -1242,11 +1243,11 @@
         for line in out.split('\n'):
             data = line.split()
             if 'vm.stats.vm.v_page_size' in line:
-                pagesize = long(data[1])
+                pagesize = int(data[1])
             if 'vm.stats.vm.v_page_count' in line:
-                pagecount = long(data[1])
+                pagecount = int(data[1])
             if 'vm.stats.vm.v_free_count' in line:
-                freecount = long(data[1])
+                freecount = int(data[1])
         self.facts['memtotal_mb'] = pagesize * pagecount / 1024 / 1024
         self.facts['memfree_mb'] = pagesize * freecount / 1024 / 1024
         # Get swapinfo.  swapinfo output looks like:
@@ -1304,7 +1305,7 @@
             product_version='system-version',
             system_vendor='system-manufacturer'
         )
-        for (k, v) in DMI_DICT.items():
+        for (k, v) in list(DMI_DICT.items()):
             if dmi_bin is not None:
                 (rc, out, err) = module.run_command('%s -s %s' % (dmi_bin, v))
                 if rc == 0:
@@ -1373,7 +1374,7 @@
                 sockets[physid] = int(data[1].strip())
         if len(sockets) > 0:
             self.facts['processor_count'] = len(sockets)
-            self.facts['processor_cores'] = reduce(lambda x, y: x + y, sockets.values())
+            self.facts['processor_cores'] = reduce(lambda x, y: x + y, list(sockets.values()))
         else:
             self.facts['processor_count'] = i
             self.facts['processor_cores'] = 'NA'
@@ -1386,7 +1387,7 @@
             key = data[0]
             if key in NetBSDHardware.MEMORY_FACTS:
                 val = data[1].strip().split(' ')[0]
-                self.facts["%s_mb" % key.lower()] = long(val) / 1024
+                self.facts["%s_mb" % key.lower()] = int(val) / 1024
 
     @timeout(10)
     def get_mount_facts(self):
@@ -1454,9 +1455,9 @@
         for line in out.split('\n'):
             data = line.split()
             if 'memory pages' in line:
-                pagecount = long(data[0])
+                pagecount = int(data[0])
             if 'free pages' in line:
-                freecount = long(data[0])
+                freecount = int(data[0])
         self.facts['memtotal_mb'] = pagesize * pagecount / 1024 / 1024
         self.facts['memfree_mb'] = pagesize * freecount / 1024 / 1024
         # Get swapinfo.  swapinfo output looks like:
@@ -1467,10 +1468,10 @@
         if out:
             lines = out.split('\n')
             data = lines[1].split()
-            swaptotal_mb = long(data[0].rstrip('MB'))
+            swaptotal_mb = int(data[0].rstrip('MB'))
             percused = int(data[1].rstrip('%'))
             self.facts['swaptotal_mb'] = swaptotal_mb
-            self.facts['swapfree_mb'] = long(swaptotal_mb * ( 100 - percused ) / 100)
+            self.facts['swapfree_mb'] = int(swaptotal_mb * ( 100 - percused ) / 100)
 
     def get_dmi_facts(self):
         rc, out, err = module.run_command("/usr/sbin/lsattr -El sys0 -a fwversion")
@@ -1650,11 +1651,11 @@
             self.facts['processor_cores'] = self.sysctl['hw.physicalcpu']
 
     def get_memory_facts(self):
-        self.facts['memtotal_mb'] = long(self.sysctl['hw.memsize']) / 1024 / 1024
+        self.facts['memtotal_mb'] = int(self.sysctl['hw.memsize']) / 1024 / 1024
 
         rc, out, err = module.run_command("sysctl hw.usermem")
         if rc == 0:
-            self.facts['memfree_mb'] = long(out.splitlines()[-1].split()[1]) / 1024 / 1024
+            self.facts['memfree_mb'] = int(out.splitlines()[-1].split()[1]) / 1024 / 1024
 
 class Network(Facts):
     """
@@ -1708,7 +1709,7 @@
             return self.facts
         default_ipv4, default_ipv6 = self.get_default_interfaces(ip_path)
         interfaces, ips = self.get_interfaces_info(ip_path, default_ipv4, default_ipv6)
-        self.facts['interfaces'] = interfaces.keys()
+        self.facts['interfaces'] = list(interfaces.keys())
         for iface in interfaces:
             self.facts[iface] = interfaces[iface]
         self.facts['default_ipv4'] = default_ipv4
@@ -1937,7 +1938,7 @@
         interfaces, ips = self.get_interfaces_info(ifconfig_path)
         self.merge_default_interface(default_ipv4, interfaces, 'ipv4')
         self.merge_default_interface(default_ipv6, interfaces, 'ipv6')
-        self.facts['interfaces'] = interfaces.keys()
+        self.facts['interfaces'] = list(interfaces.keys())
 
         for iface in interfaces:
             self.facts[iface] = interfaces[iface]
@@ -2118,17 +2119,17 @@
             return []
 
     def merge_default_interface(self, defaults, interfaces, ip_type):
-        if not 'interface' in defaults.keys():
+        if not 'interface' in list(defaults.keys()):
             return
         if not defaults['interface'] in interfaces:
             return
         ifinfo = interfaces[defaults['interface']]
         # copy all the interface values across except addresses
-        for item in ifinfo.keys():
+        for item in list(ifinfo.keys()):
             if item != 'ipv4' and item != 'ipv6':
                 defaults[item] = ifinfo[item]
         if len(ifinfo[ip_type]) > 0:
-            for item in ifinfo[ip_type][0].keys():
+            for item in list(ifinfo[ip_type][0].keys()):
                 defaults[item] = ifinfo[ip_type][0][item]
 
 class DarwinNetwork(GenericBsdIfconfigNetwork, Network):
@@ -2317,14 +2318,14 @@
                 combined_facts = {}
                 for facts in interfaces[iface][v]:
                     combined_facts.update(facts)
-                if len(combined_facts.keys()) > 0:
+                if len(list(combined_facts.keys())) > 0:
                     interfaces[iface][v] = [combined_facts]
 
         return interfaces, ips
 
     def parse_interface_line(self, words, current_if, interfaces):
         device = words[0][0:-1]
-        if device not in interfaces.keys():
+        if device not in list(interfaces.keys()):
             current_if = {'device': device, 'ipv4': [], 'ipv6': [], 'type': 'unknown'}
         else:
             current_if = interfaces[device]
@@ -2645,7 +2646,7 @@
                                 hostfeatures.append(arg[0])
                         if( len(hostfeatures) > 0 ):
                             self.facts['virtualization_role'] = 'host (' + ','.join(hostfeatures) + ')'
-            except ValueError, e:
+            except ValueError as e:
                 pass
 
 def get_file_content(path, default=None, strip=True):
@@ -2685,7 +2686,7 @@
     setup_options = dict(module_setup=True)
     facts = ansible_facts(module)
 
-    for (k, v) in facts.items():
+    for (k, v) in list(facts.items()):
         setup_options["ansible_%s" % k.replace('-', '_')] = v
 
     # Look for the path to the facter and ohai binary and set
@@ -2705,7 +2706,7 @@
         except:
             facter = False
         if facter:
-            for (k,v) in facter_ds.items():
+            for (k,v) in list(facter_ds.items()):
                 setup_options["facter_%s" % k] = v
 
     # ditto for ohai
@@ -2718,13 +2719,13 @@
         except:
             ohai = False
         if ohai:
-            for (k,v) in ohai_ds.items():
+            for (k,v) in list(ohai_ds.items()):
                 k2 = "ohai_%s" % k.replace('-', '_')
                 setup_options[k2] = v
 
     setup_result = { 'ansible_facts': {} }
 
-    for (k,v) in setup_options.items():
+    for (k,v) in list(setup_options.items()):
         if module.params['filter'] == '*' or fnmatch.fnmatch(k, module.params['filter']):
             setup_result['ansible_facts'][k] = v
 
--- ./lib/ansible/module_utils/gce.py	(original)
+++ ./lib/ansible/module_utils/gce.py	(refactored)
@@ -81,9 +81,9 @@
                 project=project_id)
         gce.connection.user_agent_append("%s/%s" % (
             USER_AGENT_PRODUCT, USER_AGENT_VERSION))
-    except (RuntimeError, ValueError), e:
+    except (RuntimeError, ValueError) as e:
         module.fail_json(msg=str(e), changed=False)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
     return gce
--- ./lib/ansible/module_utils/known_hosts.py	(original)
+++ ./lib/ansible/module_utils/known_hosts.py	(refactored)
@@ -27,7 +27,7 @@
 # USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 import hmac
-import urlparse
+import urllib.parse
 
 try:
     from hashlib import sha1
@@ -68,7 +68,7 @@
             result = repo_url
     elif "://" in repo_url:
         # this should be something we can parse with urlparse
-        parts = urlparse.urlparse(repo_url)
+        parts = urllib.parse.urlparse(repo_url)
         if 'ssh' not in parts[0] and 'git' not in parts[0]:
             # don't try and scan a hostname that's not ssh
             return None
@@ -111,7 +111,7 @@
 
         try:
             host_fh = open(hf)
-        except IOError, e:
+        except IOError as e:
             hfiles_not_found += 1
             continue
         else:
@@ -159,7 +159,7 @@
     if not os.path.exists(user_ssh_dir):
         if create_dir:
             try:
-                os.makedirs(user_ssh_dir, 0700)
+                os.makedirs(user_ssh_dir, 0o700)
             except:
                 module.fail_json(msg="failed to create host key directory: %s" % user_ssh_dir)
         else:
--- ./lib/ansible/module_utils/openstack.py	(original)
+++ ./lib/ansible/module_utils/openstack.py	(refactored)
@@ -61,7 +61,7 @@
 def openstack_find_nova_addresses(addresses, ext_tag, key_name=None):
 
     ret = []
-    for (k, v) in addresses.iteritems():
+    for (k, v) in addresses.items():
         if key_name and k == key_name:
             ret.extend([addrs['addr'] for addrs in v])
         else:
--- ./lib/ansible/module_utils/rax.py	(original)
+++ ./lib/ansible/module_utils/rax.py	(refactored)
@@ -41,7 +41,7 @@
                  'IMAPv4', 'LDAP', 'LDAPS', 'MYSQL', 'POP3', 'POP3S', 'SMTP',
                  'TCP', 'TCP_CLIENT_FIRST', 'UDP', 'UDP_STREAM', 'SFTP']
 
-NON_CALLABLES = (str, bool, dict, int, list, type(None))
+NON_CALLABLES = (str, bool, dict, int, list, type(None))
 PUBLIC_NET_ID = "00000000-0000-0000-0000-000000000000"
 SERVICE_NET_ID = "11111111-1111-1111-1111-111111111111"
 
@@ -160,7 +160,7 @@
             volume = cbs.find(name=name)
         except rax_module.exc.NotFound:
             volume = None
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e)
     return volume
 
@@ -299,7 +299,7 @@
                        os.environ.get('RAX_CREDS_FILE'))
         region = (region or os.environ.get('RAX_REGION') or
                   rax_module.get_setting('region'))
-    except KeyError, e:
+    except KeyError as e:
         module.fail_json(msg='Unable to load %s' % e.message)
 
     try:
@@ -314,7 +314,7 @@
             rax_module.set_credential_file(credentials, region=region)
         else:
             raise Exception('No credentials supplied!')
-    except Exception, e:
+    except Exception as e:
         if e.message:
             msg = str(e.message)
         else:
--- ./lib/ansible/module_utils/redhat.py	(original)
+++ ./lib/ansible/module_utils/redhat.py	(refactored)
@@ -29,7 +29,7 @@
 import os
 import re
 import types
-import ConfigParser
+import configparser
 import shlex
 
 
@@ -60,7 +60,7 @@
     def update_plugin_conf(self, plugin, enabled=True):
         plugin_conf = '/etc/yum/pluginconf.d/%s.conf' % plugin
         if os.path.isfile(plugin_conf):
-            cfg = ConfigParser.ConfigParser()
+            cfg = configparser.ConfigParser()
             cfg.read([plugin_conf])
             if enabled:
                 cfg.set('main', 'enabled', 1)
@@ -88,7 +88,7 @@
         '''
 
         # Read RHSM defaults ...
-        cp = ConfigParser.ConfigParser()
+        cp = configparser.ConfigParser()
         cp.read(rhsm_conf)
 
         # Add support for specifying a default value w/o having to standup some configuration
@@ -100,7 +100,7 @@
             else:
                 return default
 
-        cp.get_option = types.MethodType(get_option_default, cp, ConfigParser.ConfigParser)
+        cp.get_option = types.MethodType(get_option_default, cp, configparser.ConfigParser)
 
         return cp
 
@@ -125,7 +125,7 @@
         # Pass supplied **kwargs as parameters to subscription-manager.  Ignore
         # non-configuration parameters and replace '_' with '.'.  For example,
         # 'server_hostname' becomes '--system.hostname'.
-        for k,v in kwargs.items():
+        for k,v in list(kwargs.items()):
             if re.search(r'^(system|rhsm)_', k):
                 args.append('--%s=%s' % (k.replace('_','.'), v))
         
@@ -213,7 +213,7 @@
 
     def __init__(self, module, **kwargs):
         self.module = module
-        for k,v in kwargs.items():
+        for k,v in list(kwargs.items()):
             setattr(self, k, v)
 
     def __str__(self):
--- ./lib/ansible/module_utils/urls.py	(original)
+++ ./lib/ansible/module_utils/urls.py	(refactored)
@@ -82,13 +82,13 @@
 # Agreement.
 
 try:
-    import urllib2
+    import urllib.request, urllib.error, urllib.parse
     HAS_URLLIB2 = True
 except:
     HAS_URLLIB2 = False
 
 try:
-    import urlparse
+    import urllib.parse
     HAS_URLPARSE = True
 except:
     HAS_URLPARSE = False
@@ -257,7 +257,7 @@
     HAS_MATCH_HOSTNAME = True
 
 
-import httplib
+import http.client
 import os
 import re
 import sys
@@ -310,9 +310,9 @@
     pass
 
 
-class CustomHTTPSConnection(httplib.HTTPSConnection):
+class CustomHTTPSConnection(http.client.HTTPSConnection):
     def __init__(self, *args, **kwargs):
-        httplib.HTTPSConnection.__init__(self, *args, **kwargs)
+        http.client.HTTPSConnection.__init__(self, *args, **kwargs)
         if HAS_SSLCONTEXT:
             self.context = create_default_context()
             if self.cert_file:
@@ -333,7 +333,7 @@
         else:
             self.sock = ssl.wrap_socket(sock, keyfile=self.key_file, certfile=self.cert_file, ssl_version=PROTOCOL)
 
-class CustomHTTPSHandler(urllib2.HTTPSHandler):
+class CustomHTTPSHandler(urllib.request.HTTPSHandler):
 
     def https_open(self, req):
         return self.do_open(CustomHTTPSConnection, req)
@@ -393,7 +393,7 @@
             generic_parts['port']     = None
     return generic_parts
 
-class RequestWithMethod(urllib2.Request):
+class RequestWithMethod(urllib.request.Request):
     '''
     Workaround for using DELETE/PUT/etc with urllib2
     Originally contained in library/net_infrastructure/dnsmadeeasy
@@ -401,16 +401,16 @@
 
     def __init__(self, url, method, data=None, headers={}):
         self._method = method
-        urllib2.Request.__init__(self, url, data, headers)
+        urllib.request.Request.__init__(self, url, data, headers)
 
     def get_method(self):
         if self._method:
             return self._method
         else:
-            return urllib2.Request.get_method(self)
-
-
-class SSLValidationHandler(urllib2.BaseHandler):
+            return urllib.request.Request.get_method(self)
+
+
+class SSLValidationHandler(urllib.request.BaseHandler):
     '''
     A custom handler class for SSL validation.
 
@@ -497,7 +497,7 @@
         env_no_proxy = os.environ.get('no_proxy')
         if env_no_proxy:
             env_no_proxy = env_no_proxy.split(',')
-            netloc = urlparse.urlparse(url).netloc
+            netloc = urllib.parse.urlparse(url).netloc
 
             for host in env_no_proxy:
                 if netloc.endswith(host) or netloc.split(':')[0].endswith(host):
@@ -528,7 +528,7 @@
         try:
             s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
             if https_proxy:
-                proxy_parts = generic_urlparse(urlparse.urlparse(https_proxy))
+                proxy_parts = generic_urlparse(urllib.parse.urlparse(https_proxy))
                 s.connect((proxy_parts.get('hostname'), proxy_parts.get('port')))
                 if proxy_parts.get('scheme') == 'http':
                     s.sendall(self.CONNECT_COMMAND % (self.hostname, self.port))
@@ -555,7 +555,7 @@
             # close the ssl connection
             #ssl_s.unwrap()
             s.close()
-        except (ssl.SSLError, socket.error), e:
+        except (ssl.SSLError, socket.error) as e:
             # fail if we tried all of the certs but none worked
             if 'connection refused' in str(e).lower():
                 raise ConnectionError('Failed to connect to %s:%s.' % (self.hostname, self.port))
@@ -594,7 +594,7 @@
 
     # FIXME: change the following to use the generic_urlparse function
     #        to remove the indexed references for 'parsed'
-    parsed = urlparse.urlparse(url)
+    parsed = urllib.parse.urlparse(url)
     if parsed[0] == 'https' and validate_certs:
         if not HAS_SSL:
             raise NoSSLError('SSL validation is not available in your version of python. You can use validate_certs=False, however this is unsafe and not recommended')
@@ -632,10 +632,10 @@
             parsed[1] = netloc
 
             # reconstruct url without credentials
-            url = urlparse.urlunparse(parsed)
+            url = urllib.parse.urlunparse(parsed)
 
         if username:
-            passman = urllib2.HTTPPasswordMgrWithDefaultRealm()
+            passman = urllib.request.HTTPPasswordMgrWithDefaultRealm()
 
             # this creates a password manager
             passman.add_password(None, netloc, username, password)
@@ -643,13 +643,13 @@
             # because we have put None at the start it will always
             # use this username/password combination for  urls
             # for which `theurl` is a super-url
-            authhandler = urllib2.HTTPBasicAuthHandler(passman)
+            authhandler = urllib.request.HTTPBasicAuthHandler(passman)
 
             # create the AuthHandler
             handlers.append(authhandler)
 
     if not use_proxy:
-        proxyhandler = urllib2.ProxyHandler({})
+        proxyhandler = urllib.request.ProxyHandler({})
         handlers.append(proxyhandler)
 
     # pre-2.6 versions of python cannot use the custom https
@@ -657,15 +657,15 @@
     if hasattr(socket, 'create_connection'):
         handlers.append(CustomHTTPSHandler)
 
-    opener = urllib2.build_opener(*handlers)
-    urllib2.install_opener(opener)
+    opener = urllib.request.build_opener(*handlers)
+    urllib.request.install_opener(opener)
 
     if method:
         if method.upper() not in ('OPTIONS','GET','HEAD','POST','PUT','DELETE','TRACE','CONNECT'):
             raise ConnectionError('invalid HTTP request method; %s' % method.upper())
         request = RequestWithMethod(url, method.upper(), data)
     else:
-        request = urllib2.Request(url, data)
+        request = urllib.request.Request(url, data)
 
     # add the custom agent header, to help prevent issues 
     # with sites that block the default urllib agent string 
@@ -701,7 +701,7 @@
         context.check_hostname = False
         urlopen_args += (None, None, None, context)
 
-    r = urllib2.urlopen(*urlopen_args)
+    r = urllib.request.urlopen(*urlopen_args)
     return r
 
 #
@@ -751,20 +751,20 @@
         info.update(r.info())
         info['url'] = r.geturl()  # The URL goes in too, because of redirects.
         info.update(dict(msg="OK (%s bytes)" % r.headers.get('Content-Length', 'unknown'), status=200))
-    except NoSSLError, e:
+    except NoSSLError as e:
         distribution = get_distribution()
         if distribution.lower() == 'redhat':
             module.fail_json(msg='%s. You can also install python-ssl from EPEL' % str(e))
-    except (ConnectionError, ValueError), e:
+    except (ConnectionError, ValueError) as e:
         module.fail_json(msg=str(e))
-    except urllib2.HTTPError, e:
+    except urllib.error.HTTPError as e:
         info.update(dict(msg=str(e), status=e.code))
-    except urllib2.URLError, e:
+    except urllib.error.URLError as e:
         code = int(getattr(e, 'code', -1))
         info.update(dict(msg="Request failed: %s" % str(e), status=code))
-    except socket.error, e:
+    except socket.error as e:
         info.update(dict(msg="Connection failure: %s" % str(e), status=-1))
-    except Exception, e:
+    except Exception as e:
         info.update(dict(msg="An unknown error occurred: %s" % str(e), status=-1))
 
     return r, info
--- ./lib/ansible/modules/core/cloud/amazon/cloudformation.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/cloudformation.py	(refactored)
@@ -166,23 +166,23 @@
             if 'yes' in existed:
                 result = dict(changed=True,
                               output='Stack Deleted',
-                              events=map(str, list(stack.describe_events())))
+                              events=list(map(str, list(stack.describe_events()))))
             else:
                 result = dict(changed= True, output='Stack Not Found')
             break
         if '%s_COMPLETE' % operation == stack.stack_status:
             result = dict(changed=True,
-                          events = map(str, list(stack.describe_events())),
+                          events = list(map(str, list(stack.describe_events()))),
                           output = 'Stack %s complete' % operation)
             break
         if  'ROLLBACK_COMPLETE' == stack.stack_status or '%s_ROLLBACK_COMPLETE' % operation == stack.stack_status:
             result = dict(changed=True, failed=True,
-                          events = map(str, list(stack.describe_events())),
+                          events = list(map(str, list(stack.describe_events()))),
                           output = 'Problem with %s. Rollback complete' % operation)
             break
         elif '%s_FAILED' % operation == stack.stack_status:
             result = dict(changed=True, failed=True,
-                          events = map(str, list(stack.describe_events())),
+                          events = list(map(str, list(stack.describe_events()))),
                           output = 'Stack %s failed' % operation)
             break
         else:
@@ -230,7 +230,7 @@
 
 
     # convert the template parameters ansible passes into a tuple for boto
-    template_parameters_tup = [(k, v) for k, v in template_parameters.items()]
+    template_parameters_tup = [(k, v) for k, v in list(template_parameters.items())]
     stack_outputs = {}
 
     try:
@@ -239,7 +239,7 @@
                   aws_access_key_id=aws_access_key,
                   aws_secret_access_key=aws_secret_key,
               )
-    except boto.exception.NoAuthHandlerFound, e:
+    except boto.exception.NoAuthHandlerFound as e:
         module.fail_json(msg=str(e))
     update = False
     result = {}
@@ -276,7 +276,7 @@
                              disable_rollback=disable_rollback,
                              capabilities=['CAPABILITY_IAM'])
             operation = 'UPDATE'
-        except Exception, err:
+        except Exception as err:
             error_msg = boto_exception(err)
             if 'No updates are to be performed.' in error_msg:
                 result = dict(changed=False, output='Stack is already up-to-date.')
@@ -303,7 +303,7 @@
         try:
             cfn.describe_stacks(stack_name)
             operation = 'DELETE'
-        except Exception, err:
+        except Exception as err:
             error_msg = boto_exception(err)
             if 'Stack:%s does not exist' % stack_name in error_msg:
                 result = dict(changed=False, output='Stack not found.')
--- ./lib/ansible/modules/core/cloud/amazon/ec2.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2.py	(refactored)
@@ -497,7 +497,7 @@
     from boto.exception import EC2ResponseError
     from boto.vpc import VPCConnection
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def find_running_instances_by_count_tag(module, ec2, count_tag, zone=None):
@@ -516,7 +516,7 @@
 
 def _set_none_to_blank(dictionary):
     result = dictionary
-    for k in result.iterkeys():
+    for k in result.keys():
         if type(result[k]) == dict:
             result[k] = _set_none_to_blank(result[k])
         elif not result[k]:
@@ -546,14 +546,14 @@
             for x in tags:
                 if type(x) is dict:
                     x = _set_none_to_blank(x)
-                    filters.update(dict(("tag:"+tn, tv) for (tn,tv) in x.iteritems()))
+                    filters.update(dict(("tag:"+tn, tv) for (tn,tv) in x.items()))
                 else:
                     filters.update({"tag-key": x})
 
         # if dict, add the key and value to the filter
         if type(tags) is dict:
             tags = _set_none_to_blank(tags)
-            filters.update(dict(("tag:"+tn, tv) for (tn,tv) in tags.iteritems()))
+            filters.update(dict(("tag:"+tn, tv) for (tn,tv) in tags.items()))
 
     if state:
         # http://stackoverflow.com/questions/437511/what-are-the-valid-instancestates-for-the-amazon-ec2-api
@@ -640,7 +640,7 @@
         True if Boto library accept instance_profile_name argument, else false
     """
     run_instances_method = getattr(ec2, 'run_instances')
-    return 'instance_profile_name' in run_instances_method.func_code.co_varnames
+    return 'instance_profile_name' in run_instances_method.__code__.co_varnames
 
 def create_block_device(module, ec2, volume):
     # Not aware of a way to determine this programatically
@@ -677,7 +677,7 @@
         True if boto library has the named param as an argument on the request_spot_instances method, else False
     """
     method = getattr(ec2, 'request_spot_instances')
-    return param in method.func_code.co_varnames
+    return param in method.__code__.co_varnames
 
 def enforce_count(module, ec2, vpc):
 
@@ -800,17 +800,17 @@
                 grp_details = ec2.get_all_security_groups(filters={'vpc_id': vpc_id})
             else:
                 grp_details = ec2.get_all_security_groups()
-            if isinstance(group_name, str):
+            if isinstance(group_name, str):
                 group_name = [group_name]
             group_id = [ str(grp.id) for grp in grp_details if str(grp.name) in group_name ]
         # Now we try to lookup the group id testing if group exists.
         elif group_id:
             #wrap the group_id in a list if it's not one already
-            if isinstance(group_id, str):
+            if isinstance(group_id, str):
                 group_id = [group_id]
             grp_details = ec2.get_all_security_groups(group_ids=group_id)
             group_name = [grp_item.name for grp_item in grp_details]
-    except boto.exception.NoAuthHandlerFound, e:
+    except boto.exception.NoAuthHandlerFound as e:
             module.fail_json(msg = str(e))
 
     # Lookup any instances that much our run id.
@@ -972,8 +972,8 @@
                             break
                     if spot_wait_timeout <= time.time():
                         module.fail_json(msg = "wait for spot requests timeout on %s" % time.asctime())
-                    instids = spot_req_inst_ids.values()
-        except boto.exception.BotoServerError, e:
+                    instids = list(spot_req_inst_ids.values())
+        except boto.exception.BotoServerError as e:
             module.fail_json(msg = "Instance creation failed => %s: %s" % (e.error_code, e.error_message))
 
         # wait here until the instances are up
@@ -982,7 +982,7 @@
         while wait_timeout > time.time() and num_running < len(instids):
             try: 
                 res_list = ec2.get_all_instances(instids)
-            except boto.exception.BotoServerError, e:
+            except boto.exception.BotoServerError as e:
                 if e.error_code == 'InvalidInstanceID.NotFound':
                     time.sleep(1)
                     continue
@@ -1019,7 +1019,7 @@
         if instance_tags:
             try:
                 ec2.create_tags(instids, instance_tags)
-            except boto.exception.EC2ResponseError, e:
+            except boto.exception.EC2ResponseError as e:
                 module.fail_json(msg = "Instance tagging failed => %s: %s" % (e.error_code, e.error_message))
 
     instance_dict_array = []
@@ -1067,7 +1067,7 @@
                 instance_dict_array.append(get_instance_info(inst))
                 try:
                     ec2.terminate_instances([inst.id])
-                except EC2ResponseError, e:
+                except EC2ResponseError as e:
                     module.fail_json(msg='Unable to terminate instance {0}, error: {1}'.format(inst.id, e))
                 changed = True
 
@@ -1081,7 +1081,7 @@
                 filters={'instance-state-name':'terminated'})
             try:
                 num_terminated = len(response.pop().instances)
-            except Exception, e:
+            except Exception as e:
                 # got a bad response of some sort, possibly due to
                 # stale/cached data. Wait a second and then try again
                 time.sleep(1)
@@ -1135,7 +1135,7 @@
                        inst.start()
                    else:
                        inst.stop()
-               except EC2ResponseError, e:
+               except EC2ResponseError as e:
                    module.fail_json(msg='Unable to change state for instance {0}, error: {1}'.format(inst.id, e))
                changed = True
 
@@ -1217,7 +1217,7 @@
                 aws_access_key_id=aws_access_key,
                 aws_secret_access_key=aws_secret_key
             )
-        except boto.exception.NoAuthHandlerFound, e:
+        except boto.exception.NoAuthHandlerFound as e:
             module.fail_json(msg = str(e))
     else:
         vpc = None
--- ./lib/ansible/modules/core/cloud/amazon/ec2_ami.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_ami.py	(refactored)
@@ -136,7 +136,7 @@
     import boto
     import boto.ec2
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def create_image(module, ec2):
@@ -161,7 +161,7 @@
                   'no_reboot': no_reboot}
 
         image_id = ec2.create_image(**params)
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
 
     # Wait until the image is recognized. EC2 API has eventual consistency,
@@ -171,7 +171,7 @@
         try:
             img = ec2.get_image(image_id)
             break
-        except boto.exception.EC2ResponseError, e:
+        except boto.exception.EC2ResponseError as e:
             if 'InvalidAMIID.NotFound' in e.error_code and wait:
                 time.sleep(1)
             else:
@@ -210,7 +210,7 @@
                   'delete_snapshot': delete_snapshot}
 
         res = ec2.deregister_image(**params)
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
 
     # wait here until the image is gone
@@ -244,7 +244,7 @@
 
     try:
         ec2 = ec2_connect(module)
-    except Exception, e:
+    except Exception as e:
         module.json_fail(msg="Error while connecting to aws: %s" % str(e))
 
     if module.params.get('state') == 'absent':
--- ./lib/ansible/modules/core/cloud/amazon/ec2_ami_search.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_ami_search.py	(refactored)
@@ -82,8 +82,8 @@
 
 import csv
 import json
-import urllib2
-import urlparse
+import urllib.request, urllib.error, urllib.parse
+import urllib.parse
 
 SUPPORTED_DISTROS = ['ubuntu']
 
--- ./lib/ansible/modules/core/cloud/amazon/ec2_asg.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_asg.py	(refactored)
@@ -200,7 +200,7 @@
     from boto.ec2.autoscale import AutoScaleConnection, AutoScalingGroup, Tag
     from boto.exception import BotoServerError
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 ASG_ATTRIBUTES = ('availability_zones', 'default_cooldown', 'desired_capacity',
@@ -280,18 +280,18 @@
     if as_group.load_balancers and as_group.health_check_type == 'ELB':
         try:
             elb_connection = connect_to_aws(boto.ec2.elb, region, **aws_connect_params)
-        except boto.exception.NoAuthHandlerFound, e:
+        except boto.exception.NoAuthHandlerFound as e:
             module.fail_json(msg=str(e))
 
         wait_timeout = time.time() + wait_timeout
         healthy_instances = {}
 
-        while len(healthy_instances.keys()) < as_group.min_size and wait_timeout > time.time():
+        while len(list(healthy_instances.keys())) < as_group.min_size and wait_timeout > time.time():
             as_group = asg_connection.get_all_groups(names=[group_name])[0]
             props = get_properties(as_group)
             # get healthy, inservice instances from ASG
             instances = []
-            for instance, settings in props['instance_facts'].items():
+            for instance, settings in list(props['instance_facts'].items()):
                 if settings['lifecycle_state'] == 'InService' and settings['health_status'] == 'Healthy':
                     instances.append(instance)
             for lb in as_group.load_balancers:
@@ -299,7 +299,7 @@
                 # but has not yet show up in the ELB
                 try:
                     lb_instances = elb_connection.describe_instance_health(lb, instances=instances)
-                except boto.exception.InvalidInstance, e:
+                except boto.exception.InvalidInstance as e:
                     pass
                 for i in lb_instances:
                     if i.state == "InService":
@@ -329,14 +329,14 @@
         region, ec2_url, aws_connect_params = get_aws_connection_info(module)
         try:
             ec2_connection = connect_to_aws(boto.ec2, region, **aws_connect_params)
-        except (boto.exception.NoAuthHandlerFound, StandardError), e:
+        except (boto.exception.NoAuthHandlerFound, Exception) as e:
             module.fail_json(msg=str(e))
     elif vpc_zone_identifier:
         vpc_zone_identifier = ','.join(vpc_zone_identifier)
 
     asg_tags = []
     for tag in set_tags:
-        for k,v in tag.iteritems():
+        for k,v in tag.items():
             if k !='propagate_at_launch':
                 asg_tags.append(Tag(key=k,
                      value=v,
@@ -371,7 +371,7 @@
             asg_properties = get_properties(as_group)
             changed = True
             return(changed, asg_properties)
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.fail_json(msg=str(e))
     else:
         as_group = as_groups[0]
@@ -427,7 +427,7 @@
         if changed:
             try:
                 as_group.update()
-            except BotoServerError, e:
+            except BotoServerError as e:
                 module.fail_json(msg=str(e))
 
         if wait_for_instances == True:
@@ -436,7 +436,7 @@
         try:
             as_group = connection.get_all_groups(names=[group_name])[0]
             asg_properties = get_properties(as_group)
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.fail_json(msg=str(e))
         return(changed, asg_properties)
 
@@ -469,7 +469,7 @@
         return changed
 
 def get_chunks(l, n):
-    for i in xrange(0, len(l), n):
+    for i in range(0, len(l), n):
         yield l[i:i+n]
 
 def replace(connection, module):
@@ -490,7 +490,7 @@
     replaceable = 0
     if replace_instances:
         instances = replace_instances
-    for k in props['instance_facts'].keys():
+    for k in list(props['instance_facts'].keys()):
         if k in instances:
           if  props['instance_facts'][k]['launch_config_name'] != props['launch_config_name']:
               replaceable += 1
@@ -625,7 +625,7 @@
         connection = connect_to_aws(boto.ec2.autoscale, region, **aws_connect_params)
         if not connection:
             module.fail_json(msg="failed to connect to AWS for the given region: %s" % str(region))
-    except boto.exception.NoAuthHandlerFound, e:
+    except boto.exception.NoAuthHandlerFound as e:
         module.fail_json(msg=str(e))
     changed = create_changed = replace_changed = False
 
--- ./lib/ansible/modules/core/cloud/amazon/ec2_eip.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_eip.py	(refactored)
@@ -111,7 +111,7 @@
             res = ec2.associate_address(instance_id, allocation_id=address.allocation_id)
         else:
             res = ec2.associate_address(instance_id, public_ip=address.public_ip)
-    except boto.exception.EC2ResponseError, e:
+    except boto.exception.EC2ResponseError as e:
         module.fail_json(msg=str(e))
     
     if res:
@@ -133,7 +133,7 @@
             res = ec2.disassociate_address(association_id=address.association_id)
         else:
             res = ec2.disassociate_address(public_ip=address.public_ip)
-    except boto.exception.EC2ResponseError, e:
+    except boto.exception.EC2ResponseError as e:
         module.fail_json(msg=str(e))
 
     if res:
@@ -150,7 +150,7 @@
             try:
                 addresses = ec2.get_all_addresses([public_ip])
                 break
-            except boto.exception.EC2ResponseError, e:
+            except boto.exception.EC2ResponseError as e:
                 if "Address '%s' not found." % public_ip in e.message :
                     pass
                 else:
@@ -162,7 +162,7 @@
     else:
         try:
             addresses = ec2.get_all_addresses([public_ip])
-        except boto.exception.EC2ResponseError, e:
+        except boto.exception.EC2ResponseError as e:
             module.fail_json(msg=str(e.message))
 
     return addresses[0]
@@ -190,7 +190,7 @@
         domain_filter = { 'domain' : 'standard' }
       all_addresses = ec2.get_all_addresses(filters=domain_filter)
 
-      unassociated_addresses = filter(lambda a: a.instance_id == "", all_addresses)
+      unassociated_addresses = [a for a in all_addresses if a.instance_id == ""]
       if unassociated_addresses:
         address = unassociated_addresses[0];
       else:
@@ -222,7 +222,7 @@
     
     try:
         reservations = ec2.get_all_reservations(instance_ids=[instance_id])
-    except boto.exception.EC2ResponseError, e:
+    except boto.exception.EC2ResponseError as e:
         module.fail_json(msg=str(e))
     
     if len(reservations) == 1:
--- ./lib/ansible/modules/core/cloud/amazon/ec2_elb.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_elb.py	(refactored)
@@ -108,7 +108,7 @@
     import boto.ec2.elb
     from boto.regioninfo import RegionInfo
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 class ElbManager:
@@ -242,7 +242,7 @@
         """
         try:
             status = lb.get_instance_health([self.instance_id])[0]
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             if e.error_code == 'InvalidInstance':
                 return None
             else:
@@ -258,7 +258,7 @@
         try:
             elb = connect_to_aws(boto.ec2.elb, self.region, 
                                  **self.aws_connect_params)
-        except (boto.exception.NoAuthHandlerFound, StandardError), e:
+        except (boto.exception.NoAuthHandlerFound, Exception) as e:
             self.module.fail_json(msg=str(e))
 
         elbs = elb.get_all_load_balancers()
@@ -278,7 +278,7 @@
         try:
             ec2 = connect_to_aws(boto.ec2, self.region, 
                                  **self.aws_connect_params)
-        except (boto.exception.NoAuthHandlerFound, StandardError), e:
+        except (boto.exception.NoAuthHandlerFound, Exception) as e:
             self.module.fail_json(msg=str(e))
         return ec2.get_only_instances(instance_ids=[self.instance_id])[0]
 
--- ./lib/ansible/modules/core/cloud/amazon/ec2_elb_lb.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_elb_lb.py	(refactored)
@@ -250,7 +250,7 @@
     from boto.ec2.elb.healthcheck import HealthCheck
     from boto.regioninfo import RegionInfo
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 
@@ -377,7 +377,7 @@
         try:
             return connect_to_aws(boto.ec2.elb, self.region,
                                   **self.aws_connect_params)
-        except (boto.exception.NoAuthHandlerFound, StandardError), e:
+        except (boto.exception.NoAuthHandlerFound, Exception) as e:
             self.module.fail_json(msg=str(e))
 
     def _delete_elb(self):
@@ -503,7 +503,7 @@
     def _enable_zones(self, zones):
         try:
             self.elb.enable_zones(zones)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             if "Invalid Availability Zone" in e.error_message:
                 self.module.fail_json(msg=e.error_message)
             else:
@@ -513,7 +513,7 @@
     def _disable_zones(self, zones):
         try:
             self.elb.disable_zones(zones)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             if "Invalid Availability Zone" in e.error_message:
                 self.module.fail_json(msg=e.error_message)
             else:
@@ -587,7 +587,7 @@
             if not self.elb.health_check:
                 self.elb.health_check = HealthCheck()
 
-            for attr, desired_value in health_check_config.iteritems():
+            for attr, desired_value in health_check_config.items():
                 if getattr(self.elb.health_check, attr) != desired_value:
                     setattr(self.elb.health_check, attr, desired_value)
                     update_health_check = True
--- ./lib/ansible/modules/core/cloud/amazon/ec2_facts.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_facts.py	(refactored)
@@ -90,7 +90,7 @@
 
     def _mangle_fields(self, fields, uri, filter_patterns=['public-keys-0']):
         new_fields = {}
-        for key, value in fields.iteritems():
+        for key, value in fields.items():
             split_fields = key[len(uri):].split('/')
             if len(split_fields) > 1 and split_fields[1]:
                 new_key = "-".join(split_fields)
@@ -99,7 +99,7 @@
                 new_key = "".join(split_fields)
                 new_fields[self._prefix % new_key] = value
         for pattern in filter_patterns:
-            for key in new_fields.keys():
+            for key in list(new_fields.keys()):
                 match = re.search(pattern, key)
                 if match: 
                     new_fields.pop(key)
@@ -127,7 +127,7 @@
 
     def fix_invalid_varnames(self, data):
         """Change ':'' and '-' to '_' to ensure valid template variable names"""
-        for (key, value) in data.items():
+        for (key, value) in list(data.items()):
             if ':' in key or '-' in key:
                 newkey = key.replace(':','_').replace('-','_')
                 del data[key]
--- ./lib/ansible/modules/core/cloud/amazon/ec2_group.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_group.py	(refactored)
@@ -110,7 +110,7 @@
 try:
     import boto.ec2
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 
@@ -227,7 +227,7 @@
             '''found a match, delete it'''
             try:
                 group.delete()
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="Unable to delete security group '%s' - %s" % (group, e))
             else:
                 group = None
@@ -304,7 +304,7 @@
 
         # Finally, remove anything left in the groupRules -- these will be defunct rules
         if purge_rules:
-            for (rule, grant) in groupRules.itervalues() :
+            for (rule, grant) in groupRules.values() :
                 grantGroup = None
                 if grant.group_id:
                     grantGroup = groups[grant.group_id]
@@ -368,7 +368,7 @@
 
         # Finally, remove anything left in the groupRules -- these will be defunct rules
         if purge_rules_egress:
-            for (rule, grant) in groupRules.itervalues():
+            for (rule, grant) in groupRules.values():
                 grantGroup = None
                 if grant.group_id:
                     grantGroup = groups[grant.group_id].id
@@ -390,5 +390,6 @@
 # import module snippets
 from ansible.module_utils.basic import *
 from ansible.module_utils.ec2 import *
+from functools import reduce
 
 main()
--- ./lib/ansible/modules/core/cloud/amazon/ec2_key.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_key.py	(refactored)
@@ -85,7 +85,7 @@
 try:
     import boto.ec2
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 import random
@@ -136,7 +136,7 @@
                         time.sleep(1)
                     if not action_complete:
                         module.fail_json(msg="timed out while waiting for the key to be removed")
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="Unable to delete key pair '%s' - %s" % (key, e))
             else:
                 key = None
--- ./lib/ansible/modules/core/cloud/amazon/ec2_lc.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_lc.py	(refactored)
@@ -141,7 +141,7 @@
     from boto.ec2.autoscale import LaunchConfiguration
     from boto.exception import BotoServerError
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 
@@ -216,7 +216,7 @@
             connection.create_launch_configuration(lc)
             launch_configs = connection.get_all_launch_configurations(names=[name])
             changed = True
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.fail_json(msg=str(e))
     result = launch_configs[0]
 
@@ -264,7 +264,7 @@
 
     try:
         connection = connect_to_aws(boto.ec2.autoscale, region, **aws_connect_params)
-    except (boto.exception.NoAuthHandlerFound, StandardError), e:
+    except (boto.exception.NoAuthHandlerFound, Exception) as e:
         module.fail_json(msg=str(e))
 
     state = module.params.get('state')
--- ./lib/ansible/modules/core/cloud/amazon/ec2_metric_alarm.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_metric_alarm.py	(refactored)
@@ -123,7 +123,7 @@
     from boto.ec2.cloudwatch import CloudWatchConnection, MetricAlarm
     from boto.exception import BotoServerError
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 
@@ -168,7 +168,7 @@
             connection.create_alarm(alm)
             changed = True
             alarms = connection.describe_alarms(alarm_names=[name])
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.fail_json(msg=str(e))
 
     else:
@@ -203,7 +203,7 @@
         try:
             if changed:
                 connection.create_alarm(alarm)
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.fail_json(msg=str(e))
     result = alarms[0]
     module.exit_json(changed=changed, name=result.name,
@@ -235,7 +235,7 @@
         try:
             connection.delete_alarms([name])
             module.exit_json(changed=True)
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.fail_json(msg=str(e))
     else:
         module.exit_json(changed=False)
@@ -271,7 +271,7 @@
     region, ec2_url, aws_connect_params = get_aws_connection_info(module)
     try:
         connection = connect_to_aws(boto.ec2.cloudwatch, region, **aws_connect_params)
-    except (boto.exception.NoAuthHandlerFound, StandardError), e:
+    except (boto.exception.NoAuthHandlerFound, Exception) as e:
         module.fail_json(msg=str(e))
 
     if state == 'present':
--- ./lib/ansible/modules/core/cloud/amazon/ec2_scaling_policy.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_scaling_policy.py	(refactored)
@@ -66,7 +66,7 @@
     from boto.exception import BotoServerError
 
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 
@@ -93,7 +93,7 @@
             connection.create_scaling_policy(sp)
             policy = connection.get_all_policies(policy_names=[sp_name])[0]
             module.exit_json(changed=True, name=policy.name, arn=policy.policy_arn, as_name=policy.as_name, scaling_adjustment=policy.scaling_adjustment, cooldown=policy.cooldown, adjustment_type=policy.adjustment_type, min_adjustment_step=policy.min_adjustment_step)
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.fail_json(msg=str(e))
     else:
         policy = scalingPolicies[0]
@@ -120,7 +120,7 @@
                 connection.create_scaling_policy(policy)
                 policy = connection.get_all_policies(policy_names=[sp_name])[0]
             module.exit_json(changed=changed, name=policy.name, arn=policy.policy_arn, as_name=policy.as_name, scaling_adjustment=policy.scaling_adjustment, cooldown=policy.cooldown, adjustment_type=policy.adjustment_type, min_adjustment_step=policy.min_adjustment_step)
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.fail_json(msg=str(e))
 
 
@@ -134,7 +134,7 @@
         try:
             connection.delete_policy(sp_name, asg_name)
             module.exit_json(changed=True)
-        except BotoServerError, e:
+        except BotoServerError as e:
             module.exit_json(changed=False, msg=str(e))
     else:
         module.exit_json(changed=False)
@@ -162,7 +162,7 @@
 
     try:
         connection = connect_to_aws(boto.ec2.autoscale, region, **aws_connect_params)
-    except (boto.exception.NoAuthHandlerFound, StandardError), e:
+    except (boto.exception.NoAuthHandlerFound, Exception) as e:
         module.fail_json(msg = str(e))
 
     if state == 'present':
--- ./lib/ansible/modules/core/cloud/amazon/ec2_snapshot.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_snapshot.py	(refactored)
@@ -112,7 +112,7 @@
 try:
     import boto.ec2
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def main():
@@ -155,7 +155,7 @@
             if not volumes:
                 module.fail_json(msg="Could not find volume with name %s attached to instance %s" % (device_name, instance_id))
             volume_id = volumes[0].id
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
 
     if state == 'absent':
@@ -165,7 +165,7 @@
             snapshots = ec2.get_all_snapshots([snapshot_id])
             ec2.delete_snapshot(snapshot_id)
             module.exit_json(changed=True)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             # exception is raised if snapshot does not exist
             if e.error_code == 'InvalidSnapshot.NotFound':
                 module.exit_json(changed=False)
@@ -183,9 +183,9 @@
                 time_waited += 3
                 if wait_timeout and time_waited > wait_timeout:
                     module.fail_json('Timed out while creating snapshot.')
-        for k, v in snapshot_tags.items():
+        for k, v in list(snapshot_tags.items()):
             snapshot.add_tag(k, v)
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
 
     module.exit_json(changed=True, snapshot_id=snapshot.id, volume_id=snapshot.volume_id,
--- ./lib/ansible/modules/core/cloud/amazon/ec2_tag.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_tag.py	(refactored)
@@ -77,7 +77,7 @@
 try:
     import boto.ec2
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def main():
--- ./lib/ansible/modules/core/cloud/amazon/ec2_vol.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_vol.py	(refactored)
@@ -194,7 +194,7 @@
 try:
     import boto.ec2
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def get_volume(module, ec2):
@@ -211,7 +211,7 @@
         volume_ids = [id]
     try:
         vols = ec2.get_all_volumes(volume_ids=volume_ids, filters=filters)
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
 
     if not vols:
@@ -228,7 +228,7 @@
 
     try:
         vols = ec2.get_all_volumes(filters={'attachment.instance-id': instance})
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
     return vols
 
@@ -297,7 +297,7 @@
             while volume.status != 'available':
                 time.sleep(3)
                 volume.update()
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
     return volume
 
@@ -311,7 +311,7 @@
             while volume.attachment_state() != 'attached':
                 time.sleep(3)
                 volume.update()
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
 
     # If device_name isn't set, make a choice based on best practices here:
@@ -335,7 +335,7 @@
                 while volume.attachment_state() != 'attached':
                     time.sleep(3)
                     volume.update()
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
 
 def detach_volume(module, ec2):
--- ./lib/ansible/modules/core/cloud/amazon/ec2_vpc.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/ec2_vpc.py	(refactored)
@@ -185,7 +185,7 @@
     import boto.vpc
     from boto.exception import EC2ResponseError
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def get_vpc_info(vpc):
@@ -296,7 +296,7 @@
                             pending = False
                 # sometimes vpc_conn.create_vpc() will return a vpc that can't be found yet by vpc_conn.get_all_vpcs()
                 # when that happens, just wait a bit longer and try again
-                except boto.exception.BotoServerError, e:
+                except boto.exception.BotoServerError as e:
                     if e.error_code != 'InvalidVpcID.NotFound':
                         raise
                 if pending:
@@ -305,7 +305,7 @@
                 # waiting took too long
                 module.fail_json(msg = "wait for vpc availability timeout on %s" % time.asctime())
 
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             module.fail_json(msg = "%s: %s" % (e.error_code, e.error_message))
 
     # Done with base VPC, now change to attributes and features.
@@ -359,7 +359,7 @@
                         vpc_conn.create_tags(new_subnet.id, new_subnet_tags)
 
                     changed = True
-                except EC2ResponseError, e:
+                except EC2ResponseError as e:
                     module.fail_json(msg='Unable to create subnet {0}, error: {1}'.format(subnet['cidr'], e))
 
         # Now delete all absent subnets
@@ -372,7 +372,7 @@
                 try:
                     vpc_conn.delete_subnet(csubnet.id)
                     changed = True
-                except EC2ResponseError, e:
+                except EC2ResponseError as e:
                     module.fail_json(msg='Unable to delete subnet {0}, error: {1}'.format(csubnet.cidr_block, e))
 
     # Handle Internet gateway (create/delete igw)
@@ -386,7 +386,7 @@
                 igw = vpc_conn.create_internet_gateway()
                 vpc_conn.attach_internet_gateway(igw.id, vpc.id)
                 changed = True
-            except EC2ResponseError, e:
+            except EC2ResponseError as e:
                 module.fail_json(msg='Unable to create Internet Gateway, error: {0}'.format(e))
         else:
             # Set igw variable to the current igw instance for use in route tables.
@@ -397,7 +397,7 @@
                 vpc_conn.detach_internet_gateway(igws[0].id, vpc.id)
                 vpc_conn.delete_internet_gateway(igws[0].id)
                 changed = True
-            except EC2ResponseError, e:
+            except EC2ResponseError as e:
                 module.fail_json(msg='Unable to delete Internet Gateway, error: {0}'.format(e))
 
     # Handle route tables - this may be worth splitting into a
@@ -461,7 +461,7 @@
 
                 all_route_tables.append(new_rt)
                 changed = True
-            except EC2ResponseError, e:
+            except EC2ResponseError as e:
                 module.fail_json(
                     msg='Unable to create and associate route table {0}, error: ' \
                     '{1}'.format(rt, e)
@@ -490,7 +490,7 @@
                     if not is_main:
                         vpc_conn.delete_route_table(rt.id)
                         changed = True
-                except EC2ResponseError, e:
+                except EC2ResponseError as e:
                     module.fail_json(msg='Unable to delete old route table {0}, error: {1}'.format(rt.id, e))
 
     vpc_dict = get_vpc_info(vpc)
@@ -567,7 +567,7 @@
                         vpc_conn.delete_route_table(rt.id)
 
                 vpc_conn.delete_vpc(vpc.id)
-            except EC2ResponseError, e:
+            except EC2ResponseError as e:
                 module.fail_json(
                     msg='Unable to delete VPC {0}, error: {1}'.format(vpc.id, e)
                 )
@@ -610,7 +610,7 @@
                 aws_access_key_id=aws_access_key,
                 aws_secret_access_key=aws_secret_key
             )
-        except boto.exception.NoAuthHandlerFound, e:
+        except boto.exception.NoAuthHandlerFound as e:
             module.fail_json(msg = str(e))
     else:
         module.fail_json(msg="region must be specified")
--- ./lib/ansible/modules/core/cloud/amazon/elasticache.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/elasticache.py	(refactored)
@@ -145,7 +145,7 @@
     from boto.elasticache.layer1 import ElastiCacheConnection
     from boto.regioninfo import RegionInfo
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 
@@ -224,7 +224,7 @@
                                                       security_group_ids=self.security_group_ids,
                                                       preferred_availability_zone=self.zone,
                                                       port=self.cache_port)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             self.module.fail_json(msg=e.message)
         cache_cluster_data = response['CreateCacheClusterResponse']['CreateCacheClusterResult']['CacheCluster']
         self._refresh_data(cache_cluster_data)
@@ -251,7 +251,7 @@
 
         try:
             response = self.conn.delete_cache_cluster(cache_cluster_id=self.name)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             self.module.fail_json(msg=e.message)
         cache_cluster_data = response['DeleteCacheClusterResponse']['DeleteCacheClusterResult']['CacheCluster']
         self._refresh_data(cache_cluster_data)
@@ -299,7 +299,7 @@
                                                   security_group_ids=self.security_group_ids,
                                                   apply_immediately=True,
                                                   engine_version=self.cache_engine_version)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             self.module.fail_json(msg=e.message)
 
         cache_cluster_data = response['ModifyCacheClusterResponse']['ModifyCacheClusterResult']['CacheCluster']
@@ -328,7 +328,7 @@
         try:
             response = self.conn.reboot_cache_cluster(cache_cluster_id=self.name,
                                                       cache_node_ids_to_reboot=cache_node_ids)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             self.module.fail_json(msg=e.message)
 
         cache_cluster_data = response['RebootCacheClusterResponse']['RebootCacheClusterResult']['CacheCluster']
@@ -381,7 +381,7 @@
             'NumCacheNodes': self.num_nodes,
             'EngineVersion': self.cache_engine_version
         }
-        for key, value in modifiable_data.iteritems():
+        for key, value in modifiable_data.items():
             if self.data[key] != value:
                 return True
 
@@ -414,7 +414,7 @@
         # Only check for modifications if zone is specified
         if self.zone is not None:
             unmodifiable_data['zone'] = self.data['PreferredAvailabilityZone']
-        for key, value in unmodifiable_data.iteritems():
+        for key, value in unmodifiable_data.items():
             if getattr(self, key) != value:
                 return True
         return False
@@ -427,7 +427,7 @@
             return ElastiCacheConnection(aws_access_key_id=self.aws_access_key,
                                          aws_secret_access_key=self.aws_secret_key,
                                          region=connect_region)
-        except boto.exception.NoAuthHandlerFound, e:
+        except boto.exception.NoAuthHandlerFound as e:
             self.module.fail_json(msg=e.message)
 
     def _get_port(self):
--- ./lib/ansible/modules/core/cloud/amazon/rds.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/rds.py	(refactored)
@@ -295,7 +295,7 @@
 try:
     import boto.rds
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 try:
@@ -322,19 +322,19 @@
     def __init__(self, module, region, **aws_connect_params):
         try:
             self.connection  = connect_to_aws(boto.rds, region, **aws_connect_params)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
              module.fail_json(msg=e.error_message)
 
     def get_db_instance(self, instancename):
         try:
             return RDSDBInstance(self.connection.get_all_dbinstances(instancename)[0])
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             return None
 
     def get_db_snapshot(self, snapshotid):
         try: 
             return RDSSnapshot(self.connection.get_all_dbsnapshots(snapshot_id=snapshotid)[0])
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             return None
 
     def create_db_instance(self, instance_name, size, instance_class, db_engine,
@@ -344,56 +344,56 @@
             result = self.connection.create_dbinstance(instance_name, size, instance_class,
                     username, password, **params)
             return RDSDBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def create_db_instance_read_replica(self, instance_name, source_instance, **params):
         try:
             result = self.connection.createdb_instance_read_replica(instance_name, source_instance, **params)
             return RDSDBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def delete_db_instance(self, instance_name, **params):
         try:
             result = self.connection.delete_dbinstance(instance_name, **params)
             return RDSDBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def delete_db_snapshot(self, snapshot):
         try:
             result = self.connection.delete_dbsnapshot(snapshot)
             return RDSSnapshot(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def modify_db_instance(self, instance_name, **params):
         try:
             result = self.connection.modify_dbinstance(instance_name, **params)
             return RDSDBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def restore_db_instance_from_db_snapshot(self, instance_name, snapshot, instance_type, **params):
         try:
             result = self.connection.restore_dbinstance_from_dbsnapshot(snapshot, instance_name, instance_type, **params)
             return RDSDBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def create_db_snapshot(self, snapshot, instance_name, **params):
         try:
             result = self.connection.create_dbsnapshot(snapshot, instance_name)
             return RDSSnapshot(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def promote_read_replica(self, instance_name, **params):
         try:
             result = self.connection.promote_read_replica(instance_name, **params)
             return RDSDBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
 
@@ -401,7 +401,7 @@
     def __init__(self, module, region, **aws_connect_params):
         try:
             self.connection  = connect_to_aws(boto.rds2, region, **aws_connect_params)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
              module.fail_json(msg=e.error_message)
 
     def get_db_instance(self, instancename):
@@ -409,9 +409,9 @@
             dbinstances = self.connection.describe_db_instances(db_instance_identifier=instancename)['DescribeDBInstancesResponse']['DescribeDBInstancesResult']['DBInstances']
             result =  RDS2DBInstance(dbinstances[0])
             return result
-        except boto.rds2.exceptions.DBInstanceNotFound, e:
+        except boto.rds2.exceptions.DBInstanceNotFound as e:
             return None
-        except Exception, e:
+        except Exception as e:
             raise e
 
     def get_db_snapshot(self, snapshotid):
@@ -419,7 +419,7 @@
             snapshots = self.connection.describe_db_snapshots(db_snapshot_identifier=snapshotid, snapshot_type='manual')['DescribeDBSnapshotsResponse']['DescribeDBSnapshotsResult']['DBSnapshots']
             result = RDS2Snapshot(snapshots[0])
             return result
-        except boto.rds2.exceptions.DBSnapshotNotFound, e:
+        except boto.rds2.exceptions.DBSnapshotNotFound as e:
             return None
 
     def create_db_instance(self, instance_name, size, instance_class, db_engine,
@@ -428,56 +428,56 @@
             result = self.connection.create_db_instance(instance_name, size, instance_class,
                 db_engine, username, password, **params)['CreateDBInstanceResponse']['CreateDBInstanceResult']['DBInstance']
             return RDS2DBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def create_db_instance_read_replica(self, instance_name, source_instance, **params):
         try:
             result = self.connection.create_db_instance_read_replica(instance_name, source_instance, **params)['CreateDBInstanceReadReplicaResponse']['CreateDBInstanceReadReplicaResult']['DBInstance']
             return RDS2DBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def delete_db_instance(self, instance_name, **params):
         try:
             result = self.connection.delete_db_instance(instance_name, **params)['DeleteDBInstanceResponse']['DeleteDBInstanceResult']['DBInstance']
             return RDS2DBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def delete_db_snapshot(self, snapshot):
         try:
             result = self.connection.delete_db_snapshot(snapshot)['DeleteDBSnapshotResponse']['DeleteDBSnapshotResult']['DBSnapshot']
             return RDS2Snapshot(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def modify_db_instance(self, instance_name, **params):
         try:
             result = self.connection.modify_db_instance(instance_name, **params)['ModifyDBInstanceResponse']['ModifyDBInstanceResult']['DBInstance']
             return RDS2DBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def restore_db_instance_from_db_snapshot(self, instance_name, snapshot, instance_type, **params):
         try:
             result = self.connection.restore_db_instance_from_db_snapshot(instance_name, snapshot, **params)['RestoreDBInstanceFromDBSnapshotResponse']['RestoreDBInstanceFromDBSnapshotResult']['DBInstance']
             return RDS2DBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def create_db_snapshot(self, snapshot, instance_name, **params):
         try:
             result = self.connection.create_db_snapshot(snapshot, instance_name, **params)['CreateDBSnapshotResponse']['CreateDBSnapshotResult']['DBSnapshot']
             return RDS2Snapshot(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
     def promote_read_replica(self, instance_name, **params):
         try:
             result = self.connection.promote_read_replica(instance_name, **params)['PromoteReadReplicaResponse']['PromoteReadReplicaResult']['DBInstance']
             return RDS2DBInstance(result)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             raise RDSException(e)
 
 
@@ -518,7 +518,7 @@
         # ReadReplicaSourceDBInstanceIdentifier may or may not exist
         try:
             d["replication_source"] = self.instance.ReadReplicaSourceDBInstanceIdentifier
-        except Exception, e:
+        except Exception as e:
             d["replication_source"] = None
         return d
 
@@ -651,7 +651,7 @@
                     module.params.get('instance_type'), module.params.get('db_engine'),
                     module.params.get('username'), module.params.get('password'), **params)
             changed = True
-        except RDSException, e:
+        except RDSException as e:
             module.fail_json(msg="failed to create instance: %s" % e.message)
 
     if module.params.get('wait'):
@@ -678,7 +678,7 @@
         try:
             result = conn.create_db_instance_read_replica(instance_name, source_instance, **params)
             changed = True
-        except RDSException, e:
+        except RDSException as e:
             module.fail_json(msg="failed to create replica instance: %s " % e.message)
 
     if module.params.get('wait'):
@@ -714,7 +714,7 @@
             result = conn.delete_db_instance(instance_name, **params)
         else:
             result = conn.delete_db_snapshot(snapshot)
-    except RDSException, e:
+    except RDSException as e:
         module.fail_json(msg="failed to delete instance: %s" % e.message)
 
     # If we're not waiting for a delete to complete then we're all done
@@ -724,12 +724,12 @@
     try:
         resource = await_resource(conn, result, 'deleted', module)
         module.exit_json(changed=True)
-    except RDSException, e:
+    except RDSException as e:
         if e.code == 'DBInstanceNotFound':
             module.exit_json(changed=True)
         else:
             module.fail_json(msg=e.message)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=str(e))
 
 
@@ -767,7 +767,7 @@
 
     try:
         result = conn.modify_db_instance(instance_name, **params)
-    except RDSException, e:
+    except RDSException as e:
         module.fail_json(msg=e.message)
     if params.get('apply_immediately'):
         if new_instance_name:
@@ -803,7 +803,7 @@
     else:
         try:
             result = conn.promote_read_replica(instance_name, **params)
-        except RDSException, e:
+        except RDSException as e:
             module.fail_json(msg=e.message)
 
     if module.params.get('wait'):
@@ -826,7 +826,7 @@
         try:
             result = conn.create_db_snapshot(snapshot, instance_name, **params)
             changed = True
-        except RDSException, e:
+        except RDSException as e:
             module.fail_json(msg=e.message)
 
     if module.params.get('wait'):
@@ -857,7 +857,7 @@
         try:
             result = conn.restore_db_instance_from_db_snapshot(instance_name, snapshot, instance_type, **params)
             changed = True
-        except RDSException, e:
+        except RDSException as e:
             module.fail_json(msg=e.message)
 
     if module.params.get('wait'):
@@ -921,7 +921,7 @@
                 module.fail_json(msg="Parameter %s requires boto.rds (boto >= 2.26.0)" % k)
 
     params = {}
-    for (k, v) in optional_params.items():
+    for (k, v) in list(optional_params.items()):
         if module.params.get(k) and k not in required_vars:
             if k in valid_vars:
                 params[v] = module.params[k]
@@ -943,7 +943,7 @@
 
     # Convert tags dict to list of tuples that rds2 expects
     if 'tags' in params:
-        params['tags'] = module.params['tags'].items()
+        params['tags'] = list(module.params['tags'].items())
     return params
 
 
--- ./lib/ansible/modules/core/cloud/amazon/rds_param_group.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/rds_param_group.py	(refactored)
@@ -125,12 +125,12 @@
     import boto.rds
     from boto.exception import BotoServerError
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 # returns a tuple: (whether or not a parameter was changed, the remaining parameters that weren't found in this parameter group)
 
-class NotModifiableError(StandardError):
+class NotModifiableError(Exception):
     def __init__(self, error_message, *args):
         super(NotModifiableError, self).__init__(error_message, *args)
         self.error_message = error_message
@@ -160,9 +160,9 @@
         converted_value = str(value)
 
     elif param.type == 'integer':
-        if isinstance(value, str):
+        if isinstance(value, str):
             try:
-                for modifier in INT_MODIFIERS.keys():
+                for modifier in list(INT_MODIFIERS.keys()):
                     if value.endswith(modifier):
                         converted_value = int(value[:-1]) * INT_MODIFIERS[modifier]
                 converted_value = int(converted_value)
@@ -176,7 +176,7 @@
             converted_value = int(value)
 
     elif param.type == 'boolean':
-        if isinstance(value, str):
+        if isinstance(value, str):
             converted_value = value in TRUE_VALUES
         else:
             converted_value = bool(value)
@@ -192,8 +192,8 @@
 
     new_params = dict(params)
 
-    for key in new_params.keys():
-        if group.has_key(key):
+    for key in list(new_params.keys()):
+        if key in group:
             param = group[key]
             new_value = new_params[key]
 
@@ -256,7 +256,7 @@
 
     try:
         conn = boto.rds.connect_to_region(region, aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key)
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg = e.error_message)
 
     group_was_added = False
@@ -267,7 +267,7 @@
         try:
             all_groups = conn.get_all_dbparameter_groups(group_name, max_records=100)
             exists = len(all_groups) > 0
-        except BotoServerError, e:
+        except BotoServerError as e:
             if e.error_code != 'DBParameterGroupNotFound':
                 module.fail_json(msg = e.error_message)
             exists = False
@@ -297,10 +297,10 @@
                     break
 
 
-    except BotoServerError, e:
+    except BotoServerError as e:
         module.fail_json(msg = e.error_message)
 
-    except NotModifiableError, e:
+    except NotModifiableError as e:
         msg = e.error_message
         if group_was_added:
             msg = '%s The group "%s" was added first.' % (msg, group_name)
--- ./lib/ansible/modules/core/cloud/amazon/rds_subnet_group.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/rds_subnet_group.py	(refactored)
@@ -92,7 +92,7 @@
     import boto.rds
     from boto.exception import BotoServerError
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def main():
@@ -128,7 +128,7 @@
 
     try:
         conn = boto.rds.connect_to_region(region, aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key)
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg = e.error_message)
 
     try:
@@ -138,7 +138,7 @@
         try:
             matching_groups = conn.get_all_db_subnet_groups(group_name, max_records=100)
             exists = len(matching_groups) > 0
-        except BotoServerError, e:
+        except BotoServerError as e:
             if e.error_code != 'DBSubnetGroupNotFoundFault':
                 module.fail_json(msg = e.error_message)
         
@@ -153,7 +153,7 @@
             else:
                 changed_group = conn.modify_db_subnet_group(group_name, description=group_description, subnet_ids=group_subnets)
 
-    except BotoServerError, e:
+    except BotoServerError as e:
         module.fail_json(msg = e.error_message)
 
     module.exit_json(changed=changed)
--- ./lib/ansible/modules/core/cloud/amazon/route53.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/route53.py	(refactored)
@@ -178,7 +178,7 @@
     from boto import route53
     from boto.route53.record import ResourceRecordSets
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def commit(changes, retry_interval):
@@ -188,7 +188,7 @@
         try:
             retry -= 1
             return changes.commit()
-        except boto.route53.exception.DNSServerError, e:
+        except boto.route53.exception.DNSServerError as e:
             code = e.body.split("<Code>")[1]
             code = code.split("</Code>")[0]
             if code != 'PriorRequestNotComplete' or retry < 0:
@@ -252,7 +252,7 @@
     # connect to the route53 endpoint 
     try:
         conn = boto.route53.connection.Route53Connection(aws_access_key, aws_secret_key)
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg = e.error_message)
 
     # Get all the existing hosted zones and save their ID's
@@ -329,7 +329,7 @@
 
     try:
         result = commit(changes, retry_interval_in)
-    except boto.route53.exception.DNSServerError, e:
+    except boto.route53.exception.DNSServerError as e:
         txt = e.body.split("<Message>")[1]
         txt = txt.split("</Message>")[0]
         module.fail_json(msg = txt)
--- ./lib/ansible/modules/core/cloud/amazon/s3.py	(original)
+++ ./lib/ansible/modules/core/cloud/amazon/s3.py	(refactored)
@@ -122,7 +122,7 @@
 
 import sys
 import os
-import urlparse
+import urllib.parse
 import hashlib
 
 from boto.s3.connection import OrdinaryCallingFormat
@@ -131,14 +131,14 @@
     import boto
     from boto.s3.connection import Location
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 def key_check(module, s3, bucket, obj):
     try:
         bucket = s3.lookup(bucket)
         key_check = bucket.get_key(obj)
-    except s3.provider.storage_response_error, e:
+    except s3.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
     if key_check:
         return True
@@ -159,7 +159,7 @@
 def bucket_check(module, s3, bucket):
     try:
         result = s3.lookup(bucket)
-    except s3.provider.storage_response_error, e:
+    except s3.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
     if result:
         return True
@@ -169,7 +169,7 @@
 def create_bucket(module, s3, bucket, location=Location.DEFAULT):
     try:
         bucket = s3.create_bucket(bucket, location=location)
-    except s3.provider.storage_response_error, e:
+    except s3.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
     if bucket:
         return True
@@ -181,7 +181,7 @@
         bucket.delete_keys([key.name for key in bucket_contents])
         bucket.delete()
         return True
-    except s3.provider.storage_response_error, e:
+    except s3.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
 
 def delete_key(module, s3, bucket, obj):
@@ -189,7 +189,7 @@
         bucket = s3.lookup(bucket)
         bucket.delete_key(obj)
         module.exit_json(msg="Object deleted from bucket %s"%bucket, changed=True)
-    except s3.provider.storage_response_error, e:
+    except s3.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
  
 def create_dirkey(module, s3, bucket, obj):
@@ -198,7 +198,7 @@
         key = bucket.new_key(obj)
         key.set_contents_from_string('')
         module.exit_json(msg="Virtual directory %s created in bucket %s" % (obj, bucket.name), changed=True)
-    except s3.provider.storage_response_error, e:
+    except s3.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
 
 def upload_file_check(src):
@@ -221,13 +221,13 @@
         bucket = s3.lookup(bucket)
         key = bucket.new_key(obj)
         if metadata:
-            for meta_key in metadata.keys():
+            for meta_key in list(metadata.keys()):
                 key.set_metadata(meta_key, metadata[meta_key])
 
         key.set_contents_from_filename(src)
         url = key.generate_url(expiry)
         module.exit_json(msg="PUT operation complete", url=url, changed=True)
-    except s3.provider.storage_copy_error, e:
+    except s3.provider.storage_copy_error as e:
         module.fail_json(msg= str(e))
 
 def download_s3file(module, s3, bucket, obj, dest):
@@ -236,7 +236,7 @@
         key = bucket.lookup(obj)
         key.get_contents_to_filename(dest)
         module.exit_json(msg="GET operation complete", changed=True)
-    except s3.provider.storage_copy_error, e:
+    except s3.provider.storage_copy_error as e:
         module.fail_json(msg= str(e))
 
 def download_s3str(module, s3, bucket, obj):
@@ -245,7 +245,7 @@
         key = bucket.lookup(obj)
         contents = key.get_contents_as_string()
         module.exit_json(msg="GET operation complete", contents=contents, changed=True)
-    except s3.provider.storage_copy_error, e:
+    except s3.provider.storage_copy_error as e:
         module.fail_json(msg= str(e))
 
 def get_download_url(module, s3, bucket, obj, expiry, changed=True):
@@ -254,13 +254,13 @@
         key = bucket.lookup(obj)
         url = key.generate_url(expiry)
         module.exit_json(msg="Download url:", url=url, expiry=expiry, changed=changed)
-    except s3.provider.storage_response_error, e:
+    except s3.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
 
 def is_fakes3(s3_url):
     """ Return True if s3_url has scheme fakes3:// """
     if s3_url is not None:
-        return urlparse.urlparse(s3_url).scheme == 'fakes3'
+        return urllib.parse.urlparse(s3_url).scheme == 'fakes3'
     else:
         return False
 
@@ -269,7 +269,7 @@
 
     We assume anything other than *.amazonaws.com is Walrus"""
     if s3_url is not None:
-        o = urlparse.urlparse(s3_url)
+        o = urllib.parse.urlparse(s3_url)
         return not o.hostname.endswith('amazonaws.com')
     else:
         return False
@@ -322,7 +322,7 @@
     # if connecting to Walrus or fakes3
     try:
         if is_fakes3(s3_url):
-            fakes3 = urlparse.urlparse(s3_url)
+            fakes3 = urllib.parse.urlparse(s3_url)
             s3 = boto.connect_s3(
                 aws_access_key,
                 aws_secret_key,
@@ -331,7 +331,7 @@
                 port=fakes3.port,
                 calling_format=OrdinaryCallingFormat())
         elif is_walrus(s3_url):
-            walrus = urlparse.urlparse(s3_url).hostname
+            walrus = urllib.parse.urlparse(s3_url).hostname
             s3 = boto.connect_walrus(walrus, aws_access_key, aws_secret_key)
         else:
             s3 = boto.s3.connect_to_region(location, aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key, is_secure=True, calling_format=OrdinaryCallingFormat())
@@ -339,9 +339,9 @@
             if s3 is None:
                 s3 = boto.connect_s3(aws_access_key, aws_secret_key)
 
-    except boto.exception.NoAuthHandlerFound, e:
+    except boto.exception.NoAuthHandlerFound as e:
         module.fail_json(msg='No Authentication Handler found: %s ' % str(e))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg='Failed to connect to S3: %s' % str(e))
 
     if s3 is None: # this should never happen
--- ./lib/ansible/modules/core/cloud/azure/azure.py	(original)
+++ ./lib/ansible/modules/core/cloud/azure/azure.py	(refactored)
@@ -143,7 +143,7 @@
 import os
 import sys
 import time
-from urlparse import urlparse
+from urllib.parse import urlparse
 
 AZURE_LOCATIONS = ['South Central US',
                    'Central US',
@@ -189,14 +189,14 @@
                     'Standard_G5']
 
 try:
-    import azure as windows_azure
-
-    from azure import WindowsAzureError, WindowsAzureMissingResourceError
-    from azure.servicemanagement import (ServiceManagementService, OSVirtualHardDisk, SSH, PublicKeys,
+    from . import azure as windows_azure
+
+    from .azure import WindowsAzureError, WindowsAzureMissingResourceError
+    from .azure.servicemanagement import (ServiceManagementService, OSVirtualHardDisk, SSH, PublicKeys,
                                          PublicKey, LinuxConfigurationSet, ConfigurationSetInputEndpoints,
                                          ConfigurationSetInputEndpoint)
 except ImportError:
-    print "failed=True msg='azure required for this module'"
+    print("failed=True msg='azure required for this module'")
     sys.exit(1)
 
 from distutils.version import LooseVersion
@@ -285,7 +285,7 @@
             # Create ssh config
             ssh_config = SSH()
             ssh_config.public_keys = PublicKeys()
-            authorized_keys_path = u'/home/%s/.ssh/authorized_keys' % user
+            authorized_keys_path = '/home/%s/.ssh/authorized_keys' % user
             ssh_config.public_keys.public_keys.append(PublicKey(path=authorized_keys_path, fingerprint=fingerprint))
             # Append ssh config to linux machine config
             linux_config.ssh = ssh_config
@@ -303,8 +303,8 @@
 
         # First determine where to store disk
         today = datetime.date.today().strftime('%Y-%m-%d')
-        disk_prefix = u'%s-%s' % (name, name)
-        media_link = u'http://%s.blob.core.windows.net/vhds/%s-%s.vhd' % (storage_account, disk_prefix, today)
+        disk_prefix = '%s-%s' % (name, name)
+        media_link = 'http://%s.blob.core.windows.net/vhds/%s-%s.vhd' % (storage_account, disk_prefix, today)
         # Create system hard disk
         os_hd = OSVirtualHardDisk(image, media_link)
 
--- ./lib/ansible/modules/core/cloud/digital_ocean/digital_ocean.py	(original)
+++ ./lib/ansible/modules/core/cloud/digital_ocean/digital_ocean.py	(refactored)
@@ -169,12 +169,12 @@
 try:
     import dopy
     from dopy.manager import DoError, DoManager
-except ImportError, e:
-    print "failed=True msg='dopy >= 0.2.3 required for this module'"
+except ImportError as e:
+    print("failed=True msg='dopy >= 0.2.3 required for this module'")
     sys.exit(1)
 
 if dopy.__version__ < '0.2.3':
-    print "failed=True msg='dopy >= 0.2.3 required for this module'"
+    print("failed=True msg='dopy >= 0.2.3 required for this module'")
     sys.exit(1)
 
 class TimeoutError(DoError):
@@ -198,7 +198,7 @@
 
     def update_attr(self, attrs=None):
         if attrs:
-            for k, v in attrs.iteritems():
+            for k, v in attrs.items():
                 setattr(self, k, v)
         else:
             json = self.manager.show_droplet(self.id)
@@ -264,7 +264,7 @@
     @classmethod
     def list_all(cls):
         json = cls.manager.all_active_droplets()
-        return map(cls, json)
+        return list(map(cls, json))
 
 class SSH(JsonfyMixIn):
     manager = None
@@ -294,7 +294,7 @@
     @classmethod
     def list_all(cls):
         json = cls.manager.all_ssh_keys()
-        return map(cls, json)
+        return list(map(cls, json))
 
     @classmethod
     def add(cls, name, key_pub):
@@ -312,7 +312,7 @@
         # params['client_id'] will be None even if client_id is not passed in
         client_id = module.params['client_id'] or os.environ['DO_CLIENT_ID']
         api_key = module.params['api_key'] or os.environ['DO_API_KEY']
-    except KeyError, e:
+    except KeyError as e:
         module.fail_json(msg='Unable to load %s' % e.message)
 
     changed = True
@@ -425,9 +425,9 @@
 
     try:
         core(module)
-    except TimeoutError, e:
+    except TimeoutError as e:
         module.fail_json(msg=str(e), id=e.id)
-    except (DoError, Exception), e:
+    except (DoError, Exception) as e:
         module.fail_json(msg=str(e))
 
 # import module snippets
--- ./lib/ansible/modules/core/cloud/digital_ocean/digital_ocean_domain.py	(original)
+++ ./lib/ansible/modules/core/cloud/digital_ocean/digital_ocean_domain.py	(refactored)
@@ -80,7 +80,7 @@
 try:
     from dopy.manager import DoError, DoManager
 except ImportError as e:
-    print "failed=True msg='dopy required for this module'"
+    print("failed=True msg='dopy required for this module'")
     sys.exit(1)
 
 class TimeoutError(DoError):
@@ -122,7 +122,7 @@
 
     def records(self):
         json = self.manager.all_domain_records(self.id)
-        return map(DomainRecord, json)
+        return list(map(DomainRecord, json))
 
     @classmethod
     def add(cls, name, ip):
@@ -137,7 +137,7 @@
     @classmethod
     def list_all(cls):
         domains = cls.manager.all_domains()
-        return map(cls, domains)
+        return list(map(cls, domains))
 
     @classmethod
     def find(cls, name=None, id=None):
@@ -169,7 +169,7 @@
         # params['client_id'] will be None even if client_id is not passed in
         client_id = module.params['client_id'] or os.environ['DO_CLIENT_ID']
         api_key = module.params['api_key'] or os.environ['DO_API_KEY']
-    except KeyError, e:
+    except KeyError as e:
         module.fail_json(msg='Unable to load %s' % e.message)
 
     changed = True
--- ./lib/ansible/modules/core/cloud/digital_ocean/digital_ocean_sshkey.py	(original)
+++ ./lib/ansible/modules/core/cloud/digital_ocean/digital_ocean_sshkey.py	(refactored)
@@ -70,7 +70,7 @@
 try:
     from dopy.manager import DoError, DoManager
 except ImportError as e:
-    print "failed=True msg='dopy required for this module'"
+    print("failed=True msg='dopy required for this module'")
     sys.exit(1)
 
 class TimeoutError(DoError):
@@ -110,7 +110,7 @@
     @classmethod
     def list_all(cls):
         json = cls.manager.all_ssh_keys()
-        return map(cls, json)
+        return list(map(cls, json))
 
     @classmethod
     def add(cls, name, key_pub):
@@ -128,7 +128,7 @@
         # params['client_id'] will be None even if client_id is not passed in
         client_id = module.params['client_id'] or os.environ['DO_CLIENT_ID']
         api_key = module.params['api_key'] or os.environ['DO_API_KEY']
-    except KeyError, e:
+    except KeyError as e:
         module.fail_json(msg='Unable to load %s' % e.message)
 
     changed = True
--- ./lib/ansible/modules/core/cloud/docker/docker.py	(original)
+++ ./lib/ansible/modules/core/cloud/docker/docker.py	(refactored)
@@ -357,23 +357,23 @@
 import json
 import os
 import shlex
-from urlparse import urlparse
+from urllib.parse import urlparse
 try:
-    import docker.client
-    import docker.utils
-    import docker.errors
+    from . import docker.client
+    from . import docker.utils
+    from . import docker.errors
     from requests.exceptions import RequestException
 except ImportError:
     HAS_DOCKER_PY = False
 
 if HAS_DOCKER_PY:
     try:
-        from docker.errors import APIError as DockerAPIError
+        from .docker.errors import APIError as DockerAPIError
     except ImportError:
-        from docker.client import APIError as DockerAPIError
+        from .docker.client import APIError as DockerAPIError
     try:
         # docker-py 1.2+
-        import docker.constants
+        from . import docker.constants
         DEFAULT_DOCKER_API_VERSION = docker.constants.DEFAULT_DOCKER_API_VERSION
     except (ImportError, AttributeError):
         # docker-py less than 1.2
@@ -394,7 +394,7 @@
             return int(number[:-len(each)]) * (1024 ** i)
         i = i + 1
 
-    print "failed=True msg='Could not convert %s to integer'" % (number)
+    print("failed=True msg='Could not convert %s to integer'" % (number))
     sys.exit(1)
 
 
@@ -643,7 +643,7 @@
         Create a list of available capabilities
         """
         api_version = self.client.version()['ApiVersion']
-        for cap, req_vers in self._cap_ver_req.items():
+        for cap, req_vers in list(self._cap_ver_req.items()):
             if (self.docker_py_versioninfo >= req_vers[0] and
                     docker.utils.compare_version(req_vers[1], api_version) >= 0):
                 self._capabilities.add(cap)
@@ -805,7 +805,7 @@
         '''
 
         parts = []
-        for k, v in self.counters.iteritems():
+        for k, v in self.counters.items():
             if v == 0:
                 continue
 
@@ -832,7 +832,7 @@
 
     def get_summary_counters_msg(self):
         msg = ""
-        for k, v in self.counters.iteritems():
+        for k, v in self.counters.items():
             msg = msg + "%s %d " % (k, v)
 
         return msg
@@ -841,7 +841,7 @@
         self.counters[name] = self.counters[name] + 1
 
     def has_changed(self):
-        for k, v in self.counters.iteritems():
+        for k, v in self.counters.items():
             if v > 0:
                 return True
 
@@ -945,7 +945,7 @@
 
             expected_volume_keys = set((image['ContainerConfig']['Volumes'] or {}).keys())
             if self.volumes:
-                expected_volume_keys.update(self.volumes.keys())
+                expected_volume_keys.update(list(self.volumes.keys()))
 
             actual_volume_keys = set((container['Config']['Volumes'] or {}).keys())
 
@@ -980,7 +980,7 @@
                 expected_env[name] = value
 
             if self.env:
-                for name, value in self.env.iteritems():
+                for name, value in self.env.items():
                     expected_env[name] = str(value)
 
             actual_env = {}
@@ -1057,7 +1057,7 @@
 
             expected_binds = set()
             if self.binds:
-                for host_path, config in self.binds.iteritems():
+                for host_path, config in self.binds.items():
                     if isinstance(config, dict):
                         container_path = config['bind']
                         if config['ro']:
@@ -1085,7 +1085,7 @@
 
             expected_bound_ports = {}
             if self.port_bindings:
-                for container_port, config in self.port_bindings.iteritems():
+                for container_port, config in self.port_bindings.items():
                     if isinstance(container_port, int):
                         container_port = "{0}/tcp".format(container_port)
                     bind = {}
@@ -1122,7 +1122,7 @@
             # LINKS
 
             expected_links = set()
-            for link, alias in (self.links or {}).iteritems():
+            for link, alias in (self.links or {}).items():
                 expected_links.add("/{0}:{1}/{2}".format(link, container["Name"], alias))
 
             actual_links = set(container['HostConfig']['Links'] or [])
--- ./lib/ansible/modules/core/cloud/docker/docker_image.py	(original)
+++ ./lib/ansible/modules/core/cloud/docker/docker_image.py	(refactored)
@@ -106,17 +106,17 @@
     import sys
     import re
     import json
-    import docker.client
+    from . import docker.client
     from requests.exceptions import *
-    from urlparse import urlparse
-except ImportError, e:
-    print "failed=True msg='failed to import python module: %s'" % e
+    from urllib.parse import urlparse
+except ImportError as e:
+    print("failed=True msg='failed to import python module: %s'" % e)
     sys.exit(1)
 
 try:
-    from docker.errors import APIError as DockerAPIError
+    from .docker.errors import APIError as DockerAPIError
 except ImportError:
-    from docker.client import APIError as DockerAPIError
+    from .docker.client import APIError as DockerAPIError
 
 class DockerImageManager:
 
--- ./lib/ansible/modules/core/cloud/google/gc_storage.py	(original)
+++ ./lib/ansible/modules/core/cloud/google/gc_storage.py	(refactored)
@@ -109,13 +109,13 @@
 
 import sys
 import os
-import urlparse
+import urllib.parse
 import hashlib
 
 try:
     import boto
 except ImportError:
-    print "failed=True msg='boto 2.9+ required for this module'"
+    print("failed=True msg='boto 2.9+ required for this module'")
     sys.exit(1)
 
 def grant_check(module, gs, obj):
@@ -131,7 +131,7 @@
             if not grant:
                 obj.set_acl('authenticated-read')
                 module.exit_json(changed=True, result="The objects permission as been set to authenticated-read") 
-    except gs.provider.storage_response_error, e:
+    except gs.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
     return True
 
@@ -141,7 +141,7 @@
     try:
         bucket = gs.lookup(bucket)
         key_check = bucket.get_key(obj)
-    except gs.provider.storage_response_error, e:
+    except gs.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
     if key_check:
         grant_check(module, gs, key_check)
@@ -163,7 +163,7 @@
 def bucket_check(module, gs, bucket):
     try:
         result = gs.lookup(bucket)
-    except gs.provider.storage_response_error, e:
+    except gs.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
     if result:
         grant_check(module, gs, result)
@@ -175,7 +175,7 @@
     try:
         bucket = gs.create_bucket(bucket)
         bucket.set_acl(module.params.get('permission'))
-    except gs.provider.storage_response_error, e:
+    except gs.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
     if bucket:
         return True
@@ -188,7 +188,7 @@
             bucket.delete_key(key.name)
         bucket.delete()
         return True
-    except gs.provider.storage_response_error, e:
+    except gs.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
 
 def delete_key(module, gs, bucket, obj):
@@ -196,7 +196,7 @@
         bucket = gs.lookup(bucket)
         bucket.delete_key(obj)
         module.exit_json(msg="Object deleted from bucket ", changed=True)
-    except gs.provider.storage_response_error, e:
+    except gs.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
  
 def create_dirkey(module, gs, bucket, obj):
@@ -205,7 +205,7 @@
         key = bucket.new_key(obj)
         key.set_contents_from_string('')
         module.exit_json(msg="Virtual directory %s created in bucket %s" % (obj, bucket.name), changed=True)
-    except gs.provider.storage_response_error, e:
+    except gs.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
 
 def upload_file_check(src):
@@ -231,7 +231,7 @@
         key.set_acl(module.params.get('permission'))
         url = key.generate_url(expiry)
         module.exit_json(msg="PUT operation complete", url=url, changed=True)
-    except gs.provider.storage_copy_error, e:
+    except gs.provider.storage_copy_error as e:
         module.fail_json(msg= str(e))
 
 def download_gsfile(module, gs, bucket, obj, dest):
@@ -240,7 +240,7 @@
         key = bucket.lookup(obj)
         key.get_contents_to_filename(dest)
         module.exit_json(msg="GET operation complete", changed=True)
-    except gs.provider.storage_copy_error, e:
+    except gs.provider.storage_copy_error as e:
         module.fail_json(msg= str(e))
 
 def download_gsstr(module, gs, bucket, obj):
@@ -249,7 +249,7 @@
         key = bucket.lookup(obj)
         contents = key.get_contents_as_string()
         module.exit_json(msg="GET operation complete", contents=contents, changed=True)
-    except gs.provider.storage_copy_error, e:
+    except gs.provider.storage_copy_error as e:
         module.fail_json(msg= str(e))
 
 def get_download_url(module, gs, bucket, obj, expiry):
@@ -258,7 +258,7 @@
         key = bucket.lookup(obj)
         url = key.generate_url(expiry)
         module.exit_json(msg="Download url:", url=url, expiration=expiry, changed=True)
-    except gs.provider.storage_response_error, e:
+    except gs.provider.storage_response_error as e:
         module.fail_json(msg= str(e))
 
 def handle_get(module, gs, bucket, obj, overwrite, dest):
@@ -372,7 +372,7 @@
 
     try:
         gs = boto.connect_gs(gs_access_key, gs_secret_key)
-    except boto.exception.NoAuthHandlerFound, e:
+    except boto.exception.NoAuthHandlerFound as e:
         module.fail_json(msg = str(e))
  
     if mode == 'get':
--- ./lib/ansible/modules/core/cloud/google/gce.py	(original)
+++ ./lib/ansible/modules/core/cloud/google/gce.py	(refactored)
@@ -211,15 +211,15 @@
             ResourceExistsError, ResourceInUseError, ResourceNotFoundError
     _ = Provider.GCE
 except ImportError:
-    print("failed=True " + \
-        "msg='libcloud with GCE support (0.13.3+) required for this module'")
+    print(("failed=True " + \
+        "msg='libcloud with GCE support (0.13.3+) required for this module'"))
     sys.exit(1)
 
 try:
     from ast import literal_eval
 except ImportError:
-    print("failed=True " + \
-        "msg='GCE module requires python's 'ast' module, python v2.6+'")
+    print(("failed=True " + \
+        "msg='GCE module requires python's 'ast' module, python v2.6+'"))
     sys.exit(1)
 
 
@@ -322,15 +322,15 @@
             md = literal_eval(metadata)
             if not isinstance(md, dict):
                 raise ValueError('metadata must be a dict')
-        except ValueError, e:
-            print("failed=True msg='bad metadata: %s'" % str(e))
+        except ValueError as e:
+            print(("failed=True msg='bad metadata: %s'" % str(e)))
             sys.exit(1)
-        except SyntaxError, e:
+        except SyntaxError as e:
             print("failed=True msg='bad metadata syntax'")
             sys.exit(1)
 
         items = []
-        for k,v in md.items():
+        for k,v in list(md.items()):
             items.append({"key": k,"value": v})
         metadata = {'items': items}
 
@@ -357,7 +357,7 @@
             changed = True
         except ResourceExistsError:
             inst = gce.ex_get_node(name, lc_zone)
-        except GoogleBaseError, e:
+        except GoogleBaseError as e:
             module.fail_json(msg='Unexpected error attempting to create ' + \
                     'instance %s, error: %s' % (name, e.value))
 
@@ -415,7 +415,7 @@
             inst = gce.ex_get_node(name, zone_name)
         except ResourceNotFoundError:
             pass
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=unexpected_error_msg(e), changed=False)
         if inst:
             gce.destroy_node(inst)
@@ -503,7 +503,7 @@
 
 
     json_output['changed'] = changed
-    print json.dumps(json_output)
+    print(json.dumps(json_output))
     sys.exit(0)
 
 # import module snippets
--- ./lib/ansible/modules/core/cloud/google/gce_lb.py	(original)
+++ ./lib/ansible/modules/core/cloud/google/gce_lb.py	(refactored)
@@ -159,8 +159,8 @@
             ResourceExistsError, ResourceNotFoundError
     _ = Provider.GCE
 except ImportError:
-    print("failed=True " + \
-            "msg='libcloud with GCE support required for this module.'")
+    print(("failed=True " + \
+            "msg='libcloud with GCE support required for this module.'"))
     sys.exit(1)
 
 
@@ -212,7 +212,7 @@
         gcelb = get_driver_lb(Provider_lb.GCE)(gce_driver=gce)
         gcelb.connection.user_agent_append("%s/%s" % (
                 USER_AGENT_PRODUCT, USER_AGENT_VERSION))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
     changed = False
@@ -238,7 +238,7 @@
                 changed = True
             except ResourceExistsError:
                 hc = gce.ex_get_healthcheck(httphealthcheck_name)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
             if hc is not None:
@@ -282,7 +282,7 @@
                 changed = True
             except ResourceExistsError:
                 lb = gcelb.get_balancer(name)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
             if lb is not None:
@@ -308,7 +308,7 @@
                 changed = True
             except ResourceNotFoundError:
                 pass
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
         # destroy the health check if specified
@@ -320,12 +320,12 @@
                 changed = True
             except ResourceNotFoundError:
                 pass
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
 
     json_output['changed'] = changed
-    print json.dumps(json_output)
+    print(json.dumps(json_output))
     sys.exit(0)
 
 # import module snippets
--- ./lib/ansible/modules/core/cloud/google/gce_net.py	(original)
+++ ./lib/ansible/modules/core/cloud/google/gce_net.py	(refactored)
@@ -132,8 +132,8 @@
             ResourceExistsError, ResourceNotFoundError
     _ = Provider.GCE
 except ImportError:
-    print("failed=True " + \
-            "msg='libcloud with GCE support required for this module.'")
+    print(("failed=True " + \
+            "msg='libcloud with GCE support required for this module.'"))
     sys.exit(1)
 
 
@@ -195,7 +195,7 @@
             json_output['ipv4_range'] = network.cidr
         except ResourceNotFoundError:
             pass
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
         # user wants to create a new network that doesn't yet exist
@@ -209,7 +209,7 @@
                 json_output['name'] = name
                 json_output['ipv4_range'] = ipv4_range
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
         if fwname:
@@ -231,7 +231,7 @@
                 changed = True
             except ResourceExistsError:
                 pass
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
             json_output['fwname'] = fwname
@@ -248,7 +248,7 @@
                 fw = gce.ex_get_firewall(fwname)
             except ResourceNotFoundError:
                 pass
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
             if fw:
                 gce.ex_destroy_firewall(fw)
@@ -262,7 +262,7 @@
             except ResourceNotFoundError:
 #                json_output['d2'] = 'not found network name %s' % name
                 pass
-            except Exception, e:
+            except Exception as e:
 #                json_output['d3'] = 'error with %s' % name
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
             if network:
@@ -272,7 +272,7 @@
                 changed = True
 
     json_output['changed'] = changed
-    print json.dumps(json_output)
+    print(json.dumps(json_output))
     sys.exit(0)
 
 # import module snippets
--- ./lib/ansible/modules/core/cloud/google/gce_pd.py	(original)
+++ ./lib/ansible/modules/core/cloud/google/gce_pd.py	(refactored)
@@ -139,8 +139,8 @@
             ResourceExistsError, ResourceNotFoundError, ResourceInUseError
     _ = Provider.GCE
 except ImportError:
-    print("failed=True " + \
-        "msg='libcloud with GCE support is required for this module.'")
+    print(("failed=True " + \
+        "msg='libcloud with GCE support is required for this module.'"))
     sys.exit(1)
 
 
@@ -208,7 +208,7 @@
         json_output['size_gb'] = int(disk.size)
     except ResourceNotFoundError:
         pass
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=unexpected_error_msg(e), changed=False)
 
     # user wants a disk to exist.  If "instance_name" is supplied the user
@@ -249,7 +249,7 @@
             except QuotaExceededError:
                 module.fail_json(msg='Requested disk size exceeds quota',
                         changed=False)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
             json_output['size_gb'] = size_gb
             if image is not None:
@@ -260,7 +260,7 @@
         if inst and not is_attached:
             try:
                 gce.attach_volume(inst, disk, device=name, ex_mode=mode)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
             json_output['attached_to_instance'] = inst.name
             json_output['attached_mode'] = mode
@@ -272,20 +272,20 @@
         if inst and is_attached:
             try:
                 gce.detach_volume(disk, ex_node=inst)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
             changed = True
         if not detach_only:
             try:
                 gce.destroy_volume(disk)
-            except ResourceInUseError, e:
+            except ResourceInUseError as e:
                 module.fail_json(msg=str(e.value), changed=False)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=unexpected_error_msg(e), changed=False)
             changed = True
 
     json_output['changed'] = changed
-    print json.dumps(json_output)
+    print(json.dumps(json_output))
     sys.exit(0)
 
 # import module snippets
--- ./lib/ansible/modules/core/cloud/linode/linode.py	(original)
+++ ./lib/ansible/modules/core/cloud/linode/linode.py	(refactored)
@@ -163,7 +163,7 @@
 
 
 try:
-    from linode import api as linode_api
+    from .linode import api as linode_api
 except ImportError:
     print("failed=True msg='linode-python required for this module'")
     sys.exit(1)
@@ -257,7 +257,7 @@
                 api.linode_update(LinodeId=linode_id, Label='%s_%s' % (linode_id, name))
                 # Save server
                 servers = api.linode_list(LinodeId=linode_id)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg = '%s' % e.value[0]['ERRORMESSAGE'])
 
         if not disks:
@@ -289,7 +289,7 @@
                                              Label='%s swap disk (lid: %s)' % (name, linode_id), 
                                              Size=swap)
                 jobs.append(res['JobID'])
-            except Exception, e:
+            except Exception as e:
                 # TODO: destroy linode ?
                 module.fail_json(msg = '%s' % e.value[0]['ERRORMESSAGE'])
 
@@ -332,7 +332,7 @@
                 api.linode_config_create(LinodeId=linode_id, KernelId=kernel_id,
                                          Disklist=disks_list, Label='%s config' % name)
                 configs = api.linode_config_list(LinodeId=linode_id)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg = '%s' % e.value[0]['ERRORMESSAGE'])
 
         # Start / Ensure servers are running
@@ -393,7 +393,7 @@
             if server['STATUS'] != 2:
                 try:
                     res = api.linode_shutdown(LinodeId=linode_id)
-                except Exception, e:
+                except Exception as e:
                     module.fail_json(msg = '%s' % e.value[0]['ERRORMESSAGE'])
                 instance['status'] = 'Stopping'
                 changed = True
@@ -413,7 +413,7 @@
             instance = getInstanceDetails(api, server)
             try:
                 res = api.linode_reboot(LinodeId=server['LINODEID'])
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg = '%s' % e.value[0]['ERRORMESSAGE'])
             instance['status'] = 'Restarting'
             changed = True
@@ -424,7 +424,7 @@
             instance = getInstanceDetails(api, server)
             try:
                 api.linode_delete(LinodeId=server['LINODEID'], skipChecks=True)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg = '%s' % e.value[0]['ERRORMESSAGE'])
             instance['status'] = 'Deleting'
             changed = True
@@ -474,14 +474,14 @@
     if not api_key:
         try:
             api_key = os.environ['LINODE_API_KEY']
-        except KeyError, e:
+        except KeyError as e:
             module.fail_json(msg = 'Unable to load %s' % e.message)
 
     # setup the auth
     try:
         api = linode_api.Api(api_key)
         api.test_echo()
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = '%s' % e.value[0]['ERRORMESSAGE'])
 
     linodeServers(module, api, state, name, plan, distribution, datacenter, linode_id, 
--- ./lib/ansible/modules/core/cloud/openstack/glance_image.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/glance_image.py	(refactored)
@@ -141,7 +141,7 @@
                                  password=kwargs.get('login_password'),
                                  tenant_name=kwargs.get('login_tenant_name'),
                                  auth_url=kwargs.get('auth_url'))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Error authenticating to the keystone: %s " % e.message)
     return client 
 
@@ -149,7 +149,7 @@
 def _get_endpoint(module, client, endpoint_type):
     try:
         endpoint = client.service_catalog.url_for(service_type='image', endpoint_type=endpoint_type)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Error getting endpoint for glance: %s" % e.message)
     return endpoint
 
@@ -163,7 +163,7 @@
     }
     try:
         client = glanceclient.Client('1', endpoint, **kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Error in connecting to glance: %s" % e.message)
     return client
 
@@ -174,7 +174,7 @@
             if image.name == params['name']:
                 return image.id 
         return None
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Error in fetching image list: %s" % e.message)
 
 
@@ -198,7 +198,7 @@
             if image.status == 'active':
                 break
             time.sleep(5)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Error in creating image: %s" % e.message)
     if image.status == 'active':
         module.exit_json(changed=True, result=image.status, id=image.id)
@@ -211,7 +211,7 @@
         for image in client.images.list():
             if image.name == params['name']:
                 client.images.delete(image)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Error in deleting image: %s" % e.message)
     module.exit_json(changed=True, result="Deleted")
 
--- ./lib/ansible/modules/core/cloud/openstack/keystone_user.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/keystone_user.py	(refactored)
@@ -337,7 +337,7 @@
         d = dispatch(keystone, user, password, tenant, tenant_description,
                      email, role, state, endpoint, token, login_user,
                      login_password, check_mode)
-    except Exception, e:
+    except Exception as e:
         if check_mode:
             # If we have a failure in check mode
             module.exit_json(changed=True,
--- ./lib/ansible/modules/core/cloud/openstack/nova_compute.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/nova_compute.py	(refactored)
@@ -282,7 +282,7 @@
         if server_list:
             server = [x for x in server_list if x.name == module.params['name']]
             nova.servers.delete(server.pop())
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = "Error in deleting vm: %s" % e.message)
     if module.params['wait'] == 'no':
         module.exit_json(changed = True, result = "deleted")
@@ -329,7 +329,7 @@
         if not pool_ips:
             try:
                 new_ip = nova.floating_ips.create(pool)
-            except Exception, e: 
+            except Exception as e: 
                 module.fail_json(msg = "Unable to create floating ip: %s" % (e.message))
             pool_ips.append(new_ip.ip)
         # Add to the main list
@@ -344,7 +344,7 @@
                 # race condition and some other cloud operation may have
                 # stolen an available floating ip
                 break
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg = "Error attaching IP %s to instance %s: %s " % (ip, server.id, e.message))
 
 
@@ -353,7 +353,7 @@
     for ip in ips:
         try:
             server.add_floating_ip(ip)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg = "Error attaching IP %s to instance %s: %s " % (ip, server.id, e.message))
 
 
@@ -389,7 +389,7 @@
     # a recent server object if the above code path exec'd
     try:
         server = nova.servers.get(server.id)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in getting info from instance: %s " % e.message)
     return server
 
@@ -434,14 +434,14 @@
     try:
         server = nova.servers.create(*bootargs, **bootkwargs)
         server = nova.servers.get(server.id)
-    except Exception, e:
+    except Exception as e:
             module.fail_json( msg = "Error in creating instance: %s " % e.message)
     if module.params['wait'] == 'yes':
         expire = time.time() + int(module.params['wait_for'])
         while time.time() < expire:
             try:
                 server = nova.servers.get(server.id)
-            except Exception, e:
+            except Exception as e:
                     module.fail_json( msg = "Error in getting info from instance: %s" % e.message)
             if server.status == 'ACTIVE':
                 server = _add_floating_ip(module, nova, server)
@@ -510,7 +510,7 @@
             servers = [x for x in servers if x.name == module.params['name']]
             if servers:
                 server = servers[0]
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in getting the server list: %s" % e.message)
     if server and module.params['state'] == 'present':
         if server.status != 'ACTIVE':
@@ -570,9 +570,9 @@
                               service_type='compute')
     try:
         nova.authenticate()
-    except exceptions.Unauthorized, e:
+    except exceptions.Unauthorized as e:
         module.fail_json(msg = "Invalid OpenStack Nova credentials.: %s" % e.message)
-    except exceptions.AuthorizationFailure, e:
+    except exceptions.AuthorizationFailure as e:
         module.fail_json(msg = "Unable to authorize user: %s" % e.message)
 
     if module.params['state'] == 'present':
--- ./lib/ansible/modules/core/cloud/openstack/nova_keypair.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/nova_keypair.py	(refactored)
@@ -103,9 +103,9 @@
                               service_type='compute')
     try:
         nova.authenticate()
-    except exc.Unauthorized, e:
+    except exc.Unauthorized as e:
         module.fail_json(msg = "Invalid OpenStack Nova credentials.: %s" % e.message)
-    except exc.AuthorizationFailure, e:
+    except exc.AuthorizationFailure as e:
         module.fail_json(msg = "Unable to authorize user: %s" % e.message)
 
     if module.params['state'] == 'present':
@@ -117,7 +117,7 @@
                     module.exit_json(changed = False, result = "Key present")            
         try:
             key = nova.keypairs.create(module.params['name'], module.params['public_key'])
-        except Exception, e:
+        except Exception as e:
             module.exit_json(msg = "Error in creating the keypair: %s" % e.message)
         if not module.params['public_key']:
             module.exit_json(changed = True, key = key.private_key)
@@ -127,7 +127,7 @@
             if key.name == module.params['name']:
                 try:
                     nova.keypairs.delete(module.params['name'])
-                except Exception, e:
+                except Exception as e:
                     module.fail_json(msg = "The keypair deletion has failed: %s" % e.message)
                 module.exit_json( changed = True, result = "deleted")
         module.exit_json(changed = False, result = "not present")
--- ./lib/ansible/modules/core/cloud/openstack/quantum_floating_ip.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/quantum_floating_ip.py	(refactored)
@@ -97,7 +97,7 @@
                                  password=kwargs.get('login_password'),
                                  tenant_name=kwargs.get('login_tenant_name'),
                                  auth_url=kwargs.get('auth_url'))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error authenticating to the keystone: %s " % e.message)
     global _os_keystone
     _os_keystone = kclient
@@ -107,7 +107,7 @@
 def _get_endpoint(module, ksclient):
     try:
         endpoint = ksclient.service_catalog.url_for(service_type='network', endpoint_type='publicURL')
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error getting network endpoint: %s" % e.message)
     return endpoint
 
@@ -121,7 +121,7 @@
     }
     try:
         neutron = client.Client('2.0', **kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in connecting to neutron: %s " % e.message)
     return neutron
 
@@ -137,7 +137,7 @@
                         module.fail_json( msg="The VM is available but not Active. state:" + info['status'])
                     server_info = info
                     break
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in getting the server list: %s" % e.message)
     return server_info, server
 
@@ -158,7 +158,7 @@
     }
     try:
         ports = neutron.list_ports(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = "Error in listing ports: %s" % e.message)
     if subnet_id:
         port = next(port for port in ports['ports'] if port['fixed_ips'][0]['subnet_id'] == subnet_id)
@@ -177,7 +177,7 @@
     }
     try:
         ips = neutron.list_floatingips(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "error in fetching the floatingips's %s" % e.message)
     if not ips['floatingips']:
         return None, None
@@ -191,7 +191,7 @@
     }
     try:
         result = neutron.create_floatingip({'floatingip': kwargs})
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="There was an error in updating the floating ip address: %s" % e.message)
     module.exit_json(changed=True, result=result, public_ip=result['floatingip']['floating_ip_address'])
 
@@ -201,7 +201,7 @@
     }
     try:
         networks = neutron.list_networks(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json("Error in listing neutron networks: %s" % e.message)
     if not networks['networks']:
         return None
@@ -213,7 +213,7 @@
     }
     try:
         result = neutron.update_floatingip(floating_ip_id, {'floatingip': kwargs})
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="There was an error in updating the floating ip address: %s" % e.message)
     module.exit_json(changed=True, result=result)
 
@@ -233,7 +233,7 @@
         nova = nova_client.Client(module.params['login_username'], module.params['login_password'],
             module.params['login_tenant_name'], module.params['auth_url'], service_type='compute')
         neutron = _get_neutron_client(module, module.params)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Error in authenticating to nova: %s" % e.message)
 
     server_info, server_obj = _get_server_state(module, nova)
--- ./lib/ansible/modules/core/cloud/openstack/quantum_floating_ip_associate.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/quantum_floating_ip_associate.py	(refactored)
@@ -25,7 +25,7 @@
     from keystoneclient.v2_0 import client as ksclient
     import time
 except ImportError:
-    print "failed=True msg='novaclient, keystone, and quantumclient (or neutronclient) client are required'"
+    print("failed=True msg='novaclient, keystone, and quantumclient (or neutronclient) client are required'")
 
 DOCUMENTATION = '''
 ---
@@ -95,7 +95,7 @@
                                  password=kwargs.get('login_password'),
                                  tenant_name=kwargs.get('login_tenant_name'),
                                  auth_url=kwargs.get('auth_url'))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error authenticating to the keystone: %s " % e.message)
     global _os_keystone
     _os_keystone = kclient
@@ -105,7 +105,7 @@
 def _get_endpoint(module, ksclient):
     try:
         endpoint = ksclient.service_catalog.url_for(service_type='network', endpoint_type='publicURL')
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error getting network endpoint: %s" % e.message)
     return endpoint
 
@@ -119,7 +119,7 @@
     }
     try:
         neutron = client.Client('2.0', **kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in connecting to neutron: %s " % e.message)
     return neutron
 
@@ -135,7 +135,7 @@
                         module.fail_json(msg="The VM is available but not Active. state:" + info['status'])
                     server_info = info
                     break
-    except Exception, e:
+    except Exception as e:
             module.fail_json(msg = "Error in getting the server list: %s" % e.message)
     return server_info, server
 
@@ -143,7 +143,7 @@
     kwargs = dict(device_id = instance_id)
     try:
         ports = neutron.list_ports(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = "Error in listing ports: %s" % e.message)
     if not ports['ports']:
         return None
@@ -155,7 +155,7 @@
     }
     try:
         ips = neutron.list_floatingips(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "error in fetching the floatingips's %s" % e.message)
     if not ips['floatingips']:
         module.fail_json(msg = "Could find the ip specified in parameter, Please check")
@@ -172,7 +172,7 @@
     }
     try:
         result = neutron.update_floatingip(floating_ip_id, {'floatingip': kwargs})
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "There was an error in updating the floating ip address: %s" % e.message)
     module.exit_json(changed = True, result = result, public_ip=module.params['ip_address'])
 
@@ -189,7 +189,7 @@
     try:
         nova = nova_client.Client(module.params['login_username'], module.params['login_password'],
                                  module.params['login_tenant_name'], module.params['auth_url'], service_type='compute')
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = " Error in authenticating to nova: %s" % e.message)
     neutron = _get_neutron_client(module, module.params)
     state, floating_ip_id = _get_floating_ip_id(module, neutron)
--- ./lib/ansible/modules/core/cloud/openstack/quantum_network.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/quantum_network.py	(refactored)
@@ -128,7 +128,7 @@
                                  password=kwargs.get('login_password'),
                                  tenant_name=kwargs.get('login_tenant_name'),
                                  auth_url=kwargs.get('auth_url'))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error authenticating to the keystone: %s" %e.message)
     global _os_keystone
     _os_keystone = kclient
@@ -138,7 +138,7 @@
 def _get_endpoint(module, ksclient):
     try:
         endpoint = ksclient.service_catalog.url_for(service_type='network', endpoint_type='publicURL')
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error getting network endpoint: %s " %e.message)
     return endpoint
 
@@ -152,7 +152,7 @@
     }
     try:
         neutron = client.Client('2.0', **kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = " Error in connecting to neutron: %s " %e.message)
     return neutron
 
@@ -178,7 +178,7 @@
     }
     try:
         networks = neutron.list_networks(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in listing neutron networks: %s" % e.message)
     if not networks['networks']:
         return None
@@ -216,7 +216,7 @@
 
     try:
         net = neutron.create_network({'network':network})
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in creating network: %s" % e.message)
     return net['network']['id']
 
@@ -224,7 +224,7 @@
 
     try:
         id = neutron.delete_network(net_id)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in deleting the network: %s" % e.message)
     return True
 
--- ./lib/ansible/modules/core/cloud/openstack/quantum_router.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/quantum_router.py	(refactored)
@@ -99,7 +99,7 @@
                                  password=kwargs.get('login_password'),
                                  tenant_name=kwargs.get('login_tenant_name'),
                                  auth_url=kwargs.get('auth_url'))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error authenticating to the keystone: %s " % e.message)
     global _os_keystone
     _os_keystone = kclient
@@ -109,7 +109,7 @@
 def _get_endpoint(module, ksclient):
     try:
         endpoint = ksclient.service_catalog.url_for(service_type='network', endpoint_type='publicURL')
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error getting network endpoint: %s" % e.message)
     return endpoint
 
@@ -123,7 +123,7 @@
     }
     try:
         neutron = client.Client('2.0', **kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in connecting to neutron: %s " % e.message)
     return neutron
 
@@ -149,7 +149,7 @@
     }
     try:
         routers = neutron.list_routers(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in getting the router list: %s " % e.message)
     if not routers['routers']:
         return None
@@ -163,7 +163,7 @@
     }
     try:
         new_router = neutron.create_router(dict(router=router))
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = "Error in creating router: %s" % e.message)
     return new_router['router']['id']
 
--- ./lib/ansible/modules/core/cloud/openstack/quantum_router_gateway.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/quantum_router_gateway.py	(refactored)
@@ -89,7 +89,7 @@
                                  password=kwargs.get('login_password'),
                                  tenant_name=kwargs.get('login_tenant_name'),
                                  auth_url=kwargs.get('auth_url'))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error authenticating to the keystone: %s " % e.message)
     global _os_keystone
     _os_keystone = kclient
@@ -99,7 +99,7 @@
 def _get_endpoint(module, ksclient):
     try:
         endpoint = ksclient.service_catalog.url_for(service_type='network', endpoint_type='publicURL')
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error getting network endpoint: %s" % e.message)
     return endpoint
 
@@ -113,7 +113,7 @@
     }
     try:
         neutron = client.Client('2.0', **kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in connecting to neutron: %s " % e.message)
     return neutron
 
@@ -123,7 +123,7 @@
     }
     try:
         routers = neutron.list_routers(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in getting the router list: %s " % e.message)
     if not routers['routers']:
             return None
@@ -136,7 +136,7 @@
     }
     try:
         networks = neutron.list_networks(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json("Error in listing neutron networks: %s" % e.message)
     if not networks['networks']:
         return None
@@ -149,7 +149,7 @@
     }
     try:
         ports = neutron.list_ports(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = "Error in listing ports: %s" % e.message)
     if not ports['ports']:
         return None
@@ -161,14 +161,14 @@
     }
     try:
         neutron.add_gateway_router(router_id, kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in adding gateway to router: %s" % e.message)
     return True
 
 def  _remove_gateway_router(neutron, module, router_id):
     try:
         neutron.remove_gateway_router(router_id)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in removing gateway to router: %s" % e.message)
     return True
 
--- ./lib/ansible/modules/core/cloud/openstack/quantum_router_interface.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/quantum_router_interface.py	(refactored)
@@ -100,7 +100,7 @@
                                  password=kwargs.get('login_password'),
                                  tenant_name=kwargs.get('login_tenant_name'),
                                  auth_url=kwargs.get('auth_url'))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error authenticating to the keystone: %s " % e.message)
     global _os_keystone
     _os_keystone = kclient
@@ -110,7 +110,7 @@
 def _get_endpoint(module, ksclient):
     try:
         endpoint = ksclient.service_catalog.url_for(service_type='network', endpoint_type='publicURL')
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error getting network endpoint: %s" % e.message)
     return endpoint
 
@@ -124,7 +124,7 @@
     }
     try:
         neutron = client.Client('2.0', **kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in connecting to neutron: %s " % e.message)
     return neutron
 
@@ -149,7 +149,7 @@
     }
     try:
         routers = neutron.list_routers(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in getting the router list: %s " % e.message)
     if not routers['routers']:
         return None
@@ -164,7 +164,7 @@
     }
     try:
         subnets = neutron.list_subnets(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = " Error in getting the subnet list:%s " % e.message)
     if not subnets['subnets']:
         return None
@@ -177,7 +177,7 @@
     }
     try:
         ports = neutron.list_ports(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = "Error in listing ports: %s" % e.message)
     if not ports['ports']:
         return None
@@ -193,7 +193,7 @@
     }
     try:
         neutron.add_interface_router(router_id, kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error in adding interface to router: %s" % e.message)
     return True
 
@@ -203,7 +203,7 @@
     }
     try:
         neutron.remove_interface_router(router_id, kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Error in removing interface from router: %s" % e.message)
     return True
 
--- ./lib/ansible/modules/core/cloud/openstack/quantum_subnet.py	(original)
+++ ./lib/ansible/modules/core/cloud/openstack/quantum_subnet.py	(refactored)
@@ -134,7 +134,7 @@
                                  password=kwargs.get('login_password'),
                                  tenant_name=kwargs.get('login_tenant_name'),
                                  auth_url=kwargs.get('auth_url'))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error authenticating to the keystone: %s" %e.message)
     global _os_keystone
     _os_keystone = kclient
@@ -144,7 +144,7 @@
 def _get_endpoint(module, ksclient):
     try:
         endpoint = ksclient.service_catalog.url_for(service_type='network', endpoint_type='publicURL')
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Error getting network endpoint: %s" % e.message)
     return endpoint
 
@@ -158,7 +158,7 @@
     }
     try:
         neutron = client.Client('2.0', **kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = " Error in connecting to neutron: %s" % e.message)
     return neutron
 
@@ -183,7 +183,7 @@
     }
     try:
         networks = neutron.list_networks(**kwargs)
-    except Exception, e:
+    except Exception as e:
         module.fail_json("Error in listing neutron networks: %s" % e.message)
     if not networks['networks']:
             return None
@@ -203,7 +203,7 @@
         }
         try:
             subnets = neutron.list_subnets(**kwargs)
-        except Exception, e:
+        except Exception as e:
             module.fail_json( msg = " Error in getting the subnet list:%s " % e.message)
         if not subnets['subnets']:
             return None
@@ -237,7 +237,7 @@
         subnet.pop('dns_nameservers')
     try:
         new_subnet = neutron.create_subnet(dict(subnet=subnet))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg = "Failure in creating subnet: %s" % e.message)
     return new_subnet['subnet']['id']
 
@@ -245,7 +245,7 @@
 def _delete_subnet(module, neutron, subnet_id):
     try:
         neutron.delete_subnet(subnet_id)
-    except Exception, e:
+    except Exception as e:
         module.fail_json( msg = "Error in deleting subnet: %s" % e.message)
     return True
 
--- ./lib/ansible/modules/core/cloud/rackspace/rax.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax.py	(refactored)
@@ -288,17 +288,17 @@
             f = open(user_data)
             user_data = f.read()
             f.close()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='Failed to load %s' % user_data)
 
     # Handle the file contents
-    for rpath in files.keys():
+    for rpath in list(files.keys()):
         lpath = os.path.expanduser(files[rpath])
         try:
             fileobj = open(lpath, 'r')
             files[rpath] = fileobj.read()
             fileobj.close()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='Failed to load %s' % lpath)
     try:
         servers = []
@@ -313,7 +313,7 @@
                                              userdata=user_data,
                                              block_device_mapping_v2=bdmv2,
                                              **extra_create_args))
-    except Exception, e:
+    except Exception as e:
         if e.message:
             msg = str(e.message)
         else:
@@ -332,8 +332,7 @@
                 except:
                     server.status == 'ERROR'
 
-            if not filter(lambda s: s.status not in FINAL_STATUSES,
-                          servers):
+            if not [s for s in servers if s.status not in FINAL_STATUSES]:
                 break
             time.sleep(5)
 
@@ -395,7 +394,7 @@
     for server in servers:
         try:
             server.delete()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             changed = True
@@ -416,19 +415,15 @@
                     instances[instance_id]['status'] = 'DELETED'
                     instances[instance_id]['rax_status'] = 'DELETED'
 
-            if not filter(lambda s: s['status'] not in ('', 'DELETED',
-                                                        'ERROR'),
-                          instances.values()):
+            if not [s for s in list(instances.values()) if s['status'] not in ('', 'DELETED',
+                                                        'ERROR')]:
                 break
 
             time.sleep(5)
 
-    timeout = filter(lambda s: s['status'] not in ('', 'DELETED', 'ERROR'),
-                     instances.values())
-    error = filter(lambda s: s['status'] in ('ERROR'),
-                   instances.values())
-    success = filter(lambda s: s['status'] in ('', 'DELETED'),
-                     instances.values())
+    timeout = [s for s in list(instances.values()) if s['status'] not in ('', 'DELETED', 'ERROR')]
+    error = [s for s in list(instances.values()) if s['status'] in ('ERROR')]
+    success = [s for s in list(instances.values()) if s['status'] in ('', 'DELETED')]
 
     instances = [rax_to_dict(s, 'server') for s in kept]
 
@@ -477,7 +472,7 @@
         if not boot_from_volume and not boot_volume and not image:
             module.fail_json(msg='image is required for the "rax" module')
 
-        for arg, value in dict(name=name, flavor=flavor).iteritems():
+        for arg, value in dict(name=name, flavor=flavor).items():
             if not value:
                 module.fail_json(msg='%s is required for the "rax" module' %
                                      arg)
@@ -502,12 +497,12 @@
         group = meta['group']
 
     # Normalize and ensure all metadata values are strings
-    for k, v in meta.items():
+    for k, v in list(meta.items()):
         if isinstance(v, list):
             meta[k] = ','.join(['%s' % i for i in v])
         elif isinstance(v, dict):
             meta[k] = json.dumps(v)
-        elif not isinstance(v, str):
+        elif not isinstance(v, str):
             meta[k] = '%s' % v
 
     # When using state=absent with group, the absent block won't match the
@@ -543,7 +538,7 @@
                 # %d to the end
                 try:
                     name % 0
-                except TypeError, e:
+                except TypeError as e:
                     if e.message.startswith('not all'):
                         name = '%s%%d' % name
                     else:
@@ -562,7 +557,7 @@
                         number = int(match.group(1))
                         numbers.add(number)
 
-                number_range = xrange(count_offset, count_offset + count)
+                number_range = range(count_offset, count_offset + count)
                 available_numbers = list(set(number_range)
                                          .difference(numbers))
             else:  # Not auto incrementing
@@ -633,7 +628,7 @@
                     # %d to the end
                     try:
                         name % 0
-                    except TypeError, e:
+                    except TypeError as e:
                         if e.message.startswith('not all'):
                             name = '%s%%d' % name
                         else:
@@ -652,7 +647,7 @@
                             number = int(match.group(1))
                             numbers.add(number)
 
-                    number_range = xrange(count_offset,
+                    number_range = range(count_offset,
                                           count_offset + count + len(numbers))
                     available_numbers = list(set(number_range)
                                              .difference(numbers))
--- ./lib/ansible/modules/core/cloud/rackspace/rax_cbs.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_cbs.py	(refactored)
@@ -149,7 +149,7 @@
                                     metadata=meta,
                                     snapshot_id=snapshot_id, **kwargs)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
             else:
                 if wait:
@@ -178,7 +178,7 @@
             try:
                 volume.delete()
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
     module.exit_json(changed=changed, volume=instance)
--- ./lib/ansible/modules/core/cloud/rackspace/rax_cbs_attachments.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_cbs_attachments.py	(refactored)
@@ -118,12 +118,12 @@
             try:
                 volume.attach_to_instance(server, mountpoint=device)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
             volume.get()
 
-        for key, value in vars(volume).iteritems():
+        for key, value in vars(volume).items():
             if (isinstance(value, NON_CALLABLES) and
                     not key.startswith('_')):
                 instance[key] = value
@@ -157,7 +157,7 @@
                                            interval=3, attempts=0,
                                            verbose=False)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
             volume.get()
--- ./lib/ansible/modules/core/cloud/rackspace/rax_cdb.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_cdb.py	(refactored)
@@ -94,7 +94,7 @@
 def save_instance(module, name, flavor, volume, wait, wait_timeout):
 
     for arg, value in dict(name=name, flavor=flavor,
-                           volume=volume).iteritems():
+                           volume=volume).items():
         if not value:
             module.fail_json(msg='%s is required for the "rax_cdb"'
                                  ' module' % arg)
@@ -119,7 +119,7 @@
         action = 'create'
         try:
             instance = cdb.create(name=name, flavor=flavor, volume=volume)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
         else:
             changed = True
@@ -170,7 +170,7 @@
 
     try:
         instance.delete()
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg='%s' % e.message)
     else:
         changed = True
--- ./lib/ansible/modules/core/cloud/rackspace/rax_cdb_database.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_cdb_database.py	(refactored)
@@ -83,7 +83,7 @@
 
     try:
         instance = cdb.get(cdb_id)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg='%s' % e.message)
 
     changed = False
@@ -95,7 +95,7 @@
             database = instance.create_database(name=name,
                                                 character_set=character_set,
                                                 collate=collate)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
         else:
             changed = True
@@ -109,7 +109,7 @@
 
     try:
         instance = cdb.get(cdb_id)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg='%s' % e.message)
 
     changed = False
@@ -119,7 +119,7 @@
     if database:
         try:
             database.delete()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
         else:
             changed = True
--- ./lib/ansible/modules/core/cloud/rackspace/rax_cdb_user.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_cdb_user.py	(refactored)
@@ -89,7 +89,7 @@
 
 def save_user(module, cdb_id, name, password, databases, host):
 
-    for arg, value in dict(cdb_id=cdb_id, name=name).iteritems():
+    for arg, value in dict(cdb_id=cdb_id, name=name).items():
         if not value:
             module.fail_json(msg='%s is required for the "rax_cdb_user" '
                                  'module' % arg)
@@ -98,7 +98,7 @@
 
     try:
         instance = cdb.get(cdb_id)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg='%s' % e.message)
 
     changed = False
@@ -112,7 +112,7 @@
                                         password=password,
                                         database_names=databases,
                                         host=host)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
         else:
             changed = True
@@ -134,7 +134,7 @@
 
                 new_dbs = [db for db in databases if db not in former_dbs]
                 user.grant_user_access(db_names=new_dbs)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
             else:
                 changed = True
@@ -144,7 +144,7 @@
 
 def delete_user(module, cdb_id, name):
 
-    for arg, value in dict(cdb_id=cdb_id, name=name).iteritems():
+    for arg, value in dict(cdb_id=cdb_id, name=name).items():
         if not value:
             module.fail_json(msg='%s is required for the "rax_cdb_user"'
                                  ' module' % arg)
@@ -153,7 +153,7 @@
 
     try:
         instance = cdb.get(cdb_id)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg='%s' % e.message)
 
     changed = False
@@ -163,7 +163,7 @@
     if user:
         try:
             user.delete()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
         else:
             changed = True
@@ -205,7 +205,7 @@
     name = module.params.get('db_username')
     password = module.params.get('db_password')
     databases = module.params.get('databases')
-    host = unicode(module.params.get('host'))
+    host = str(module.params.get('host'))
     state = module.params.get('state')
 
     setup_rax_module(module, pyrax)
--- ./lib/ansible/modules/core/cloud/rackspace/rax_clb.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_clb.py	(refactored)
@@ -171,7 +171,7 @@
 
     if state == 'present':
         if isinstance(meta, dict):
-            metadata = [dict(key=k, value=v) for k, v in meta.items()]
+            metadata = [dict(key=k, value=v) for k, v in list(meta.items())]
 
         if not balancers:
             try:
@@ -180,13 +180,13 @@
                                       algorithm=algorithm, protocol=protocol,
                                       timeout=timeout, virtual_ips=virtual_ips)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
         else:
             balancer = balancers[0]
             setattr(balancer, 'metadata',
                     [dict(key=k, value=v) for k, v in
-                     balancer.get_metadata().items()])
+                     list(balancer.get_metadata().items())])
             atts = {
                 'name': name,
                 'algorithm': algorithm,
@@ -194,7 +194,7 @@
                 'protocol': protocol,
                 'timeout': timeout
             }
-            for att, value in atts.iteritems():
+            for att, value in atts.items():
                 current = getattr(balancer, att)
                 if current != value:
                     changed = True
@@ -238,7 +238,7 @@
             try:
                 balancer.delete()
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
             instance = rax_to_dict(balancer, 'clb')
--- ./lib/ansible/modules/core/cloud/rackspace/rax_clb_nodes.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_clb_nodes.py	(refactored)
@@ -130,7 +130,7 @@
 def _activate_virtualenv(path):
     path = os.path.expanduser(path)
     activate_this = os.path.join(path, 'bin', 'activate_this.py')
-    execfile(activate_this, dict(__file__=activate_this))
+    exec(compile(open(activate_this).read(), activate_this, 'exec'), dict(__file__=activate_this))
 
 
 def _get_node(lb, node_id=None, address=None, port=None):
@@ -192,7 +192,7 @@
     if virtualenv:
         try:
             _activate_virtualenv(virtualenv)
-        except IOError, e:
+        except IOError as e:
             module.fail_json(msg='Failed to activate virtualenv %s (%s)' % (
                                  virtualenv, e))
 
@@ -205,7 +205,7 @@
 
     try:
         lb = pyrax.cloud_loadbalancers.get(load_balancer_id)
-    except pyrax.exc.PyraxException, e:
+    except pyrax.exc.PyraxException as e:
         module.fail_json(msg='%s' % e.message)
 
     node = _get_node(lb, node_id, address, port)
@@ -220,7 +220,7 @@
             result = {}
         except pyrax.exc.NotFound:
             module.exit_json(changed=False, state=state)
-        except pyrax.exc.PyraxException, e:
+        except pyrax.exc.PyraxException as e:
             module.fail_json(msg='%s' % e.message)
     else:  # present
         if not node:
@@ -237,7 +237,7 @@
                         weight=weight, type=typ)
                     resp, body = lb.add_nodes([node])
                     result.update(body['nodes'][0])
-                except pyrax.exc.PyraxException, e:
+                except pyrax.exc.PyraxException as e:
                     module.fail_json(msg='%s' % e.message)
         else:  # Updating an existing node
             mutable = {
@@ -246,7 +246,7 @@
                 'weight': weight,
             }
 
-            for name, value in mutable.items():
+            for name, value in list(mutable.items()):
                 if value is None or value == getattr(node, name):
                     mutable.pop(name)
 
@@ -258,7 +258,7 @@
                 # type; this should probably be fixed in pyrax
                 lb.update_node(node, diff=mutable)
                 result.update(mutable)
-            except pyrax.exc.PyraxException, e:
+            except pyrax.exc.PyraxException as e:
                 module.fail_json(msg='%s' % e.message)
 
     if wait:
--- ./lib/ansible/modules/core/cloud/rackspace/rax_dns.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_dns.py	(refactored)
@@ -89,14 +89,14 @@
 
         try:
             domain = dns.find(name=name)
-        except pyrax.exceptions.NoUniqueMatch, e:
+        except pyrax.exceptions.NoUniqueMatch as e:
             module.fail_json(msg='%s' % e.message)
         except pyrax.exceptions.NotFound:
             try:
                 domain = dns.create(name=name, emailAddress=email, ttl=ttl,
                                     comment=comment)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
         update = {}
@@ -112,7 +112,7 @@
                 domain.update(**update)
                 changed = True
                 domain.get()
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
     elif state == 'absent':
@@ -121,14 +121,14 @@
         except pyrax.exceptions.NotFound:
             domain = {}
             pass
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
         if domain:
             try:
                 domain.delete()
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
     module.exit_json(changed=changed, domain=rax_to_dict(domain))
--- ./lib/ansible/modules/core/cloud/rackspace/rax_dns_record.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_dns_record.py	(refactored)
@@ -145,7 +145,7 @@
                     try:
                         dns.update_ptr_record(item, record, name, data, ttl)
                         changed = True
-                    except Exception, e:
+                    except Exception as e:
                         module.fail_json(msg='%s' % e.message)
                     record.ttl = ttl
                     record.name = name
@@ -161,7 +161,7 @@
             try:
                 results = dns.add_ptr_records(item, [record])
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
         module.exit_json(changed=changed, records=results)
@@ -177,7 +177,7 @@
             try:
                 dns.delete_ptr_records(item, data)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
         module.exit_json(changed=changed, records=results)
@@ -202,14 +202,14 @@
 
         try:
             domain = dns.find(name=domain)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
         try:
             record = domain.find_record(record_type, name=name)
-        except pyrax.exceptions.DomainRecordNotUnique, e:
+        except pyrax.exceptions.DomainRecordNotUnique as e:
             module.fail_json(msg='%s' % e.message)
-        except pyrax.exceptions.DomainRecordNotFound, e:
+        except pyrax.exceptions.DomainRecordNotFound as e:
             try:
                 record_data = {
                     'type': record_type,
@@ -224,7 +224,7 @@
 
                 record = domain.add_records([record_data])[0]
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
         update = {}
@@ -242,28 +242,28 @@
                 record.update(**update)
                 changed = True
                 record.get()
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
     elif state == 'absent':
         try:
             domain = dns.find(name=domain)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
         try:
             record = domain.find_record(record_type, name=name, data=data)
-        except pyrax.exceptions.DomainRecordNotFound, e:
+        except pyrax.exceptions.DomainRecordNotFound as e:
             record = {}
             pass
-        except pyrax.exceptions.DomainRecordNotUnique, e:
+        except pyrax.exceptions.DomainRecordNotUnique as e:
             module.fail_json(msg='%s' % e.message)
 
         if record:
             try:
                 record.delete()
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
     module.exit_json(changed=changed, record=rax_to_dict(record))
--- ./lib/ansible/modules/core/cloud/rackspace/rax_facts.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_facts.py	(refactored)
@@ -79,23 +79,23 @@
         search_opts = dict(name='^%s$' % name)
         try:
             servers = cs.servers.list(search_opts=search_opts)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
     elif address:
         servers = []
         try:
             for server in cs.servers.list():
-                for addresses in server.networks.values():
+                for addresses in list(server.networks.values()):
                     if address in addresses:
                         servers.append(server)
                         break
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
     elif server_id:
         servers = []
         try:
             servers.append(cs.servers.get(server_id))
-        except Exception, e:
+        except Exception as e:
             pass
 
     if len(servers) > 1:
--- ./lib/ansible/modules/core/cloud/rackspace/rax_files.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_files.py	(refactored)
@@ -142,7 +142,7 @@
 try:
     import pyrax
     HAS_PYRAX = True
-except ImportError, e:
+except ImportError as e:
     HAS_PYRAX = False
 
 EXIT_DICT = dict(success=True)
@@ -152,17 +152,17 @@
 def _get_container(module, cf, container):
     try:
         return cf.get_container(container)
-    except pyrax.exc.NoSuchContainer, e:
+    except pyrax.exc.NoSuchContainer as e:
         module.fail_json(msg=e.message)
 
 
 def _fetch_meta(module, container):
     EXIT_DICT['meta'] = dict()
     try:
-        for k, v in container.get_metadata().items():
+        for k, v in list(container.get_metadata().items()):
             split_key = k.split(META_PREFIX)[-1]
             EXIT_DICT['meta'][split_key] = v
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=e.message)
 
 
@@ -172,23 +172,23 @@
     if meta_ and state == 'present':
         try:
             meta_set = c.set_metadata(meta_, clear=clear_meta)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
     elif meta_ and state == 'absent':
         remove_results = []
-        for k, v in meta_.items():
+        for k, v in list(meta_.items()):
             c.remove_metadata_key(k)
             remove_results.append(k)
             EXIT_DICT['deleted_meta_keys'] = remove_results
     elif state == 'absent':
         remove_results = []
-        for k, v in c.get_metadata().items():
+        for k, v in list(c.get_metadata().items()):
             c.remove_metadata_key(k)
             remove_results.append(k)
             EXIT_DICT['deleted_meta_keys'] = remove_results
 
     _fetch_meta(module, c)
-    _locals = locals().keys()
+    _locals = list(locals().keys())
 
     EXIT_DICT['container'] = c.name
     if 'meta_set' in _locals or 'remove_results' in _locals:
@@ -214,12 +214,12 @@
 
     try:
         c = cf.get_container(container_)
-    except pyrax.exc.NoSuchContainer, e:
+    except pyrax.exc.NoSuchContainer as e:
         # Make the container if state=present, otherwise bomb out
         if state == 'present':
             try:
                 c = cf.create_container(container_)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=e.message)
             else:
                 EXIT_DICT['changed'] = True
@@ -232,7 +232,7 @@
         if state == 'absent':
             try:
                 cont_deleted = c.delete()
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg=e.message)
             else:
                 EXIT_DICT['deleted'] = True
@@ -240,7 +240,7 @@
     if meta_:
         try:
             meta_set = c.set_metadata(meta_, clear=clear_meta)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         finally:
             _fetch_meta(module, c)
@@ -248,7 +248,7 @@
     if ttl:
         try:
             c.cdn_ttl = ttl
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             EXIT_DICT['ttl'] = c.cdn_ttl
@@ -256,7 +256,7 @@
     if public:
         try:
             cont_public = c.make_public()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             EXIT_DICT['container_urls'] = dict(url=c.cdn_uri,
@@ -267,7 +267,7 @@
     if private:
         try:
             cont_private = c.make_private()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             EXIT_DICT['set_private'] = True
@@ -275,7 +275,7 @@
     if web_index:
         try:
             cont_web_index = c.set_web_index_page(web_index)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             EXIT_DICT['set_index'] = True
@@ -285,7 +285,7 @@
     if web_error:
         try:
             cont_err_index = c.set_web_error_page(web_error)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             EXIT_DICT['set_error'] = True
@@ -296,7 +296,7 @@
     EXIT_DICT['objs_in_container'] = c.object_count
     EXIT_DICT['total_bytes'] = c.total_bytes
 
-    _locals = locals().keys()
+    _locals = list(locals().keys())
     if ('cont_deleted' in _locals
             or 'meta_set' in _locals
             or 'cont_public' in _locals
--- ./lib/ansible/modules/core/cloud/rackspace/rax_files_objects.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_files_objects.py	(refactored)
@@ -196,7 +196,7 @@
 def _get_container(module, cf, container):
     try:
         return cf.get_container(container)
-    except pyrax.exc.NoSuchContainer, e:
+    except pyrax.exc.NoSuchContainer as e:
         module.fail_json(msg=e.message)
 
 
@@ -225,12 +225,12 @@
     if dest and not is_dir:
         try:
             cont_obj = c.upload_file(src, obj_name=dest, ttl=expires)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
     elif is_dir:
         try:
             id, total_bytes = cf.upload_folder(src, container=c.name, ttl=expires)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
 
         while True:
@@ -241,7 +241,7 @@
     else:
         try:
             cont_obj = c.upload_file(src, ttl=expires)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
 
     num_objs_after = len(c.get_object_names())
@@ -259,7 +259,7 @@
                 for obj in objs:
                     try:
                         result = c.get_object(obj).set_metadata(meta)
-                    except Exception, e:
+                    except Exception as e:
                         module.fail_json(msg=e.message)
                     else:
                         meta_result[obj] = result
@@ -312,7 +312,7 @@
     # If not specified, get the entire container
     if src:
         objs = src.split(',')
-        objs = map(str.strip, objs)
+        objs = list(map(str.strip, objs))
     else:
         objs = c.get_object_names()
 
@@ -326,7 +326,7 @@
     for obj in objs:
         try:
             c.download_object(obj, dest, structure=structure)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             results.append(obj)
@@ -365,7 +365,7 @@
 
     if objs:
         objs = objs.split(',')
-        objs = map(str.strip, objs)
+        objs = list(map(str.strip, objs))
     else:
         objs = c.get_object_names()
 
@@ -375,7 +375,7 @@
     for obj in objs:
         try:
             result = c.delete_object(obj)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             results.append(result)
@@ -415,7 +415,7 @@
 
     if objs:
         objs = objs.split(',')
-        objs = map(str.strip, objs)
+        objs = list(map(str.strip, objs))
     else:
         objs = c.get_object_names()
 
@@ -423,11 +423,11 @@
     for obj in objs:
         try:
             meta = c.get_object(obj).get_metadata()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             results[obj] = dict()
-            for k, v in meta.items():
+            for k, v in list(meta.items()):
                 meta_key = k.split(META_PREFIX)[-1]
                 results[obj][meta_key] = v
 
@@ -453,7 +453,7 @@
         objs = src
 
     objs = objs.split(',')
-    objs = map(str.strip, objs)
+    objs = list(map(str.strip, objs))
 
     c = _get_container(module, cf, container)
 
@@ -461,7 +461,7 @@
     for obj in objs:
         try:
             result = c.get_object(obj).set_metadata(meta, clear=clear_meta)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg=e.message)
         else:
             results.append(result)
@@ -490,30 +490,30 @@
         objs = src
 
     objs = objs.split(',')
-    objs = map(str.strip, objs)
+    objs = list(map(str.strip, objs))
 
     c = _get_container(module, cf, container)
 
     results = []  # Num of metadata keys removed, not objects affected
     for obj in objs:
         if meta:
-            for k, v in meta.items():
+            for k, v in list(meta.items()):
                 try:
                     result = c.get_object(obj).remove_metadata_key(k)
-                except Exception, e:
+                except Exception as e:
                     module.fail_json(msg=e.message)
                 else:
                     results.append(result)
         else:
             try:
                 o = c.get_object(obj)
-            except pyrax.exc.NoSuchObject, e:
+            except pyrax.exc.NoSuchObject as e:
                 module.fail_json(msg=e.message)
 
-            for k, v in o.get_metadata().items():
+            for k, v in list(o.get_metadata().items()):
                 try:
                     result = o.remove_metadata_key(k)
-                except Exception, e:
+                except Exception as e:
                     module.fail_json(msg=e.message)
                 results.append(result)
 
--- ./lib/ansible/modules/core/cloud/rackspace/rax_identity.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_identity.py	(refactored)
@@ -62,7 +62,7 @@
     changed = False
 
     instance.update(rax_to_dict(identity))
-    instance['services'] = instance.get('services', {}).keys()
+    instance['services'] = list(instance.get('services', {}).keys())
 
     if state == 'present':
         if not identity.authenticated:
--- ./lib/ansible/modules/core/cloud/rackspace/rax_keypair.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_keypair.py	(refactored)
@@ -109,7 +109,7 @@
                 f = open(public_key)
                 public_key = f.read()
                 f.close()
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='Failed to load %s' % public_key)
 
         try:
@@ -118,9 +118,9 @@
             try:
                 keypair = cs.keypairs.create(name, public_key)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
     elif state == 'absent':
@@ -133,7 +133,7 @@
             try:
                 keypair.delete()
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
     module.exit_json(changed=changed, keypair=rax_to_dict(keypair))
--- ./lib/ansible/modules/core/cloud/rackspace/rax_meta.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_meta.py	(refactored)
@@ -91,23 +91,23 @@
         search_opts = dict(name='^%s$' % name)
         try:
             servers = cs.servers.list(search_opts=search_opts)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
     elif address:
         servers = []
         try:
             for server in cs.servers.list():
-                for addresses in server.networks.values():
+                for addresses in list(server.networks.values()):
                     if address in addresses:
                         servers.append(server)
                         break
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
     elif server_id:
         servers = []
         try:
             servers.append(cs.servers.get(server_id))
-        except Exception, e:
+        except Exception as e:
             pass
 
     if len(servers) > 1:
@@ -118,12 +118,12 @@
                              'search parameters')
 
     # Normalize and ensure all metadata values are strings
-    for k, v in meta.items():
+    for k, v in list(meta.items()):
         if isinstance(v, list):
             meta[k] = ','.join(['%s' % i for i in v])
         elif isinstance(v, dict):
             meta[k] = json.dumps(v)
-        elif not isinstance(v, str):
+        elif not isinstance(v, str):
             meta[k] = '%s' % v
 
     server = servers[0]
@@ -131,7 +131,7 @@
         changed = False
     else:
         changed = True
-        removed = set(server.metadata.keys()).difference(meta.keys())
+        removed = set(server.metadata.keys()).difference(list(meta.keys()))
         cs.servers.delete_meta(server, list(removed))
         cs.servers.set_meta(server, meta)
         server.get()
--- ./lib/ansible/modules/core/cloud/rackspace/rax_network.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_network.py	(refactored)
@@ -84,9 +84,9 @@
             try:
                 network = pyrax.cloud_networks.create(label, cidr=cidr)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
     elif state == 'absent':
@@ -96,7 +96,7 @@
             changed = True
         except pyrax.exceptions.NetworkNotFound:
             pass
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
     if network:
--- ./lib/ansible/modules/core/cloud/rackspace/rax_queue.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_queue.py	(refactored)
@@ -91,7 +91,7 @@
             try:
                 queue = cq.create(name)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
         else:
             queue = queues[0]
@@ -106,7 +106,7 @@
             try:
                 queue.delete()
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
     module.exit_json(changed=changed, queue=instance)
--- ./lib/ansible/modules/core/cloud/rackspace/rax_scaling_group.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_scaling_group.py	(refactored)
@@ -161,18 +161,18 @@
             f = open(user_data)
             user_data = f.read()
             f.close()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='Failed to load %s' % user_data)
 
     if state == 'present':
         # Normalize and ensure all metadata values are strings
         if meta:
-            for k, v in meta.items():
+            for k, v in list(meta.items()):
                 if isinstance(v, list):
                     meta[k] = ','.join(['%s' % i for i in v])
                 elif isinstance(v, dict):
                     meta[k] = json.dumps(v)
-                elif not isinstance(v, str):
+                elif not isinstance(v, str):
                     meta[k] = '%s' % v
 
         if image:
@@ -194,7 +194,7 @@
         # Handle the file contents
         personality = []
         if files:
-            for rpath in files.keys():
+            for rpath in list(files.keys()):
                 lpath = os.path.expanduser(files[rpath])
                 try:
                     f = open(lpath, 'r')
@@ -203,7 +203,7 @@
                         'contents': f.read()
                     })
                     f.close()
-                except Exception, e:
+                except Exception as e:
                     module.fail_json(msg='Failed to load %s' % lpath)
 
         lbs = []
@@ -225,7 +225,7 @@
 
         try:
             sg = au.find(name=name)
-        except pyrax.exceptions.NoUniqueMatch, e:
+        except pyrax.exceptions.NoUniqueMatch as e:
             module.fail_json(msg='%s' % e.message)
         except pyrax.exceptions.NotFound:
             try:
@@ -240,7 +240,7 @@
                                key_name=key_name, config_drive=config_drive,
                                user_data=user_data)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
         if not changed:
@@ -322,9 +322,9 @@
             sg = au.find(name=name)
             sg.delete()
             changed = True
-        except pyrax.exceptions.NotFound, e:
+        except pyrax.exceptions.NotFound as e:
             sg = {}
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
         module.exit_json(changed=changed, autoscale_group=rax_to_dict(sg))
--- ./lib/ansible/modules/core/cloud/rackspace/rax_scaling_policy.py	(original)
+++ ./lib/ansible/modules/core/cloud/rackspace/rax_scaling_policy.py	(refactored)
@@ -141,16 +141,16 @@
     except ValueError:
         try:
             sg = au.find(name=scaling_group)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
     else:
         try:
             sg = au.get(scaling_group)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
     if state == 'present':
-        policies = filter(lambda p: name == p.name, sg.list_policies())
+        policies = [p for p in sg.list_policies() if name == p.name]
         if len(policies) > 1:
             module.fail_json(msg='No unique policy match found by name')
         if at:
@@ -168,7 +168,7 @@
                                        desired_capacity=desired_capacity,
                                        args=args)
                 changed = True
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg='%s' % e.message)
 
         else:
@@ -209,7 +209,7 @@
 
     else:
         try:
-            policies = filter(lambda p: name == p.name, sg.list_policies())
+            policies = [p for p in sg.list_policies() if name == p.name]
             if len(policies) > 1:
                 module.fail_json(msg='No unique policy match found by name')
             elif not policies:
@@ -217,7 +217,7 @@
             else:
                 policy.delete()
                 changed = True
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg='%s' % e.message)
 
         module.exit_json(changed=changed, autoscale_policy=rax_to_dict(policy))
--- ./lib/ansible/modules/core/cloud/vmware/vsphere_guest.py	(original)
+++ ./lib/ansible/modules/core/cloud/vmware/vsphere_guest.py	(refactored)
@@ -519,17 +519,17 @@
 
     try:
         cluster = [k for k,
-                   v in vsphere_client.get_clusters().items() if v == cluster_name][0]
-    except IndexError, e:
+                   v in list(vsphere_client.get_clusters().items()) if v == cluster_name][0]
+    except IndexError as e:
         vsphere_client.disconnect()
         module.fail_json(msg="Cannot find Cluster named: %s" %
                          cluster_name)
 
     try:
-        rpmor = [k for k, v in vsphere_client.get_resource_pools(
-            from_mor=cluster).items()
+        rpmor = [k for k, v in list(vsphere_client.get_resource_pools(
+            from_mor=cluster).items())
             if v == resource_pool][0]
-    except IndexError, e:
+    except IndexError as e:
         vsphere_client.disconnect()
         module.fail_json(msg="Cannot find Resource Pool named: %s" %
                          resource_pool)
@@ -635,7 +635,7 @@
                 vm.power_off(sync_run=True)
                 vm.get_status()
 
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(
                     msg='Failed to shutdown vm %s: %s' % (guest, e)
                 )
@@ -655,7 +655,7 @@
         if vm.is_powered_off():
             try:
                 vm.power_on(sync_run=True)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(
                     msg='Failed to power on vm %s : %s' % (guest, e)
                 )
@@ -673,7 +673,7 @@
     esxi_hostname = esxi['hostname']
     # Datacenter managed object reference
     dclist = [k for k,
-             v in vsphere_client.get_datacenters().items() if v == datacenter]
+             v in list(vsphere_client.get_datacenters().items()) if v == datacenter]
     if dclist:
         dcmor=dclist[0]
     else:
@@ -687,11 +687,11 @@
 
     # virtualmachineFolder managed object reference
     if vm_extra_config.get('folder'):
-        if vm_extra_config['folder'] not in vsphere_client._get_managed_objects(MORTypes.Folder).values():
+        if vm_extra_config['folder'] not in list(vsphere_client._get_managed_objects(MORTypes.Folder).values()):
             vsphere_client.disconnect()
             module.fail_json(msg="Cannot find folder named: %s" % vm_extra_config['folder'])
 
-        for mor, name in vsphere_client._get_managed_objects(MORTypes.Folder).iteritems():
+        for mor, name in vsphere_client._get_managed_objects(MORTypes.Folder).items():
             if name == vm_extra_config['folder']:
                 vmfmor = mor
     else:
@@ -709,8 +709,8 @@
     # Grab the host managed object reference of the esxi_hostname
     try:
         hostmor = [k for k,
-                   v in vsphere_client.get_hosts().items() if v == esxi_hostname][0]
-    except IndexError, e:
+                   v in list(vsphere_client.get_hosts().items()) if v == esxi_hostname][0]
+    except IndexError as e:
         vsphere_client.disconnect()
         module.fail_json(msg="Cannot find esx host named: %s" % esxi_hostname)
 
@@ -735,17 +735,17 @@
     if resource_pool:
         try:
             cluster = [k for k,
-                       v in vsphere_client.get_clusters().items() if v == cluster_name][0]
-        except IndexError, e:
+                       v in list(vsphere_client.get_clusters().items()) if v == cluster_name][0]
+        except IndexError as e:
             vsphere_client.disconnect()
             module.fail_json(msg="Cannot find Cluster named: %s" %
                              cluster_name)
 
         try:
-            rpmor = [k for k, v in vsphere_client.get_resource_pools(
-                from_mor=cluster).items()
+            rpmor = [k for k, v in list(vsphere_client.get_resource_pools(
+                from_mor=cluster).items())
                 if v == resource_pool][0]
-        except IndexError, e:
+        except IndexError as e:
             vsphere_client.disconnect()
             module.fail_json(msg="Cannot find Resource Pool named: %s" %
                              resource_pool)
@@ -802,7 +802,7 @@
     if vm_disk:
         disk_num = 0
         disk_key = 0
-        for disk in sorted(vm_disk.iterkeys()):
+        for disk in sorted(vm_disk.keys()):
             try:
                 datastore = vm_disk[disk]['datastore']
             except KeyError:
@@ -853,7 +853,7 @@
         add_cdrom(module, vsphere_client, config_target, config, devices,
                   default_devs, cdrom_type, cdrom_iso_path)
     if vm_nic:
-        for nic in sorted(vm_nic.iterkeys()):
+        for nic in sorted(vm_nic.keys()):
             try:
                 nictype = vm_nic[nic]['type']
             except KeyError:
@@ -927,7 +927,7 @@
                     vm.power_off(sync_run=True)
                     vm.get_status()
 
-                except Exception, e:
+                except Exception as e:
                     module.fail_json(
                         msg='Failed to shutdown vm %s: %s' % (guest, e))
             else:
@@ -951,7 +951,7 @@
             module.fail_json(msg="Error removing vm: %s %s" %
                              task.get_error_message())
         module.exit_json(changed=True, changes="VM %s deleted" % guest)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(
             msg='Failed to delete vm %s : %s' % (guest, e))
 
@@ -993,7 +993,7 @@
                         % power_status
             return True
 
-        except Exception, e:
+        except Exception as e:
             return e
 
     return False
@@ -1060,15 +1060,15 @@
 
         if not self.recursive_missing:
             self.recursive_missing = []
-            for key, value in self.interface_dict.items():
+            for key, value in list(self.interface_dict.items()):
                 if isinstance(value, dict):
-                    for k, v in value.items():
+                    for k, v in list(value.items()):
                         if k in self.check_dict[key]:
                             if not isinstance(self.check_dict[key][k], v):
                                 try:
                                     if v == int:
                                         self.check_dict[key][k] = int(self.check_dict[key][k])
-                                    elif v == str:
+                                    elif v == str:
                                         self.check_dict[key][k] = str(self.check_dict[key][k])
                                     else:
                                         raise ValueError
@@ -1107,29 +1107,29 @@
     proto_vm_hardware = {
         'memory_mb': int,
         'num_cpus': int,
-        'scsi': str,
-        'osid': str
+        'scsi': str,
+        'osid': str
     }
 
     proto_vm_disk = {
         'disk1': {
-            'datastore': str,
+            'datastore': str,
             'size_gb': int,
-            'type': str
+            'type': str
         }
     }
 
     proto_vm_nic = {
         'nic1': {
-            'type': str,
-            'network': str,
-            'network_type': str
+            'type': str,
+            'network': str,
+            'network_type': str
         }
     }
 
     proto_esxi = {
-        'datacenter': str,
-        'hostname': str
+        'datacenter': str,
+        'hostname': str
     }
 
     module = AnsibleModule(
@@ -1205,7 +1205,7 @@
     viserver = VIServer()
     try:
         viserver.connect(vcenter_hostname, username, password)
-    except VIApiException, err:
+    except VIApiException as err:
         module.fail_json(msg="Cannot connect to %s: %s" %
                          (vcenter_hostname, err))
 
@@ -1220,7 +1220,7 @@
         if vmware_guest_facts:
             try:
                 module.exit_json(ansible_facts=gather_facts(vm))
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(
                     msg="Fact gather failed with exception %s" % e)
         # Power Changes
@@ -1228,7 +1228,7 @@
             state_result = power_state(vm, state, force)
 
             # Failure
-            if isinstance(state_result, str):
+            if isinstance(state_result, str):
                 module.fail_json(msg=state_result)
             else:
                 module.exit_json(changed=state_result)
--- ./lib/ansible/modules/core/commands/command.py	(original)
+++ ./lib/ansible/modules/core/commands/command.py	(refactored)
@@ -125,7 +125,7 @@
 # ^ a non-escaped space or a non-escaped quote of the same kind
 #   that was matched in the first 'quote' is found, or the end of
 #   the line is reached
-OPTIONS_REGEX = '|'.join(OPTIONS.keys())
+OPTIONS_REGEX = '|'.join(list(OPTIONS.keys()))
 PARAM_REGEX = re.compile(
     r'(^|\s)(' + OPTIONS_REGEX +
     r')=(?P<quote>[\'"])?(.*?)(?(quote)(?<!\\)(?P=quote))((?<!\\)(?=\s)|$)'
@@ -260,7 +260,7 @@
                 # check to see if this is a special parameter for the command
                 k, v = x.split('=', 1)
                 v = unquote(v.strip())
-                if k in OPTIONS.keys():
+                if k in list(OPTIONS.keys()):
                     if k == "chdir":
                         v = os.path.abspath(os.path.expanduser(v))
                         if not (os.path.exists(v) and os.path.isdir(v)):
--- ./lib/ansible/modules/core/database/mysql/mysql_db.py	(original)
+++ ./lib/ansible/modules/core/database/mysql/mysql_db.py	(refactored)
@@ -99,7 +99,7 @@
 - mysql_db: name=my_db state=import target=/tmp/dump.sql.bz2
 '''
 
-import ConfigParser
+import configparser
 import os
 import pipes
 import stat
@@ -233,7 +233,7 @@
 
 
 def load_mycnf():
-    config = ConfigParser.RawConfigParser()
+    config = configparser.RawConfigParser()
     mycnf = os.path.expanduser('~/.my.cnf')
     if not os.path.exists(mycnf):
         return False
@@ -245,14 +245,14 @@
     # as these are both supported by MySQL.
     try:
         passwd = config_get(config, 'client', 'password')
-    except (ConfigParser.NoOptionError):
+    except (configparser.NoOptionError):
         try:
             passwd = config_get(config, 'client', 'pass')
-        except (ConfigParser.NoOptionError):
+        except (configparser.NoOptionError):
             return False
     try:
         creds = dict(user=config_get(config, 'client', 'user'),passwd=passwd)
-    except (ConfigParser.NoOptionError):
+    except (configparser.NoOptionError):
         return False
     return creds
 
@@ -330,7 +330,7 @@
         else:
             db_connection = MySQLdb.connect(host=module.params["login_host"], port=login_port, user=login_user, passwd=login_password, db=connect_to_db)
         cursor = db_connection.cursor()
-    except Exception, e:
+    except Exception as e:
         if "Unknown database" in str(e):
                 errno, errstr = e.args
                 module.fail_json(msg="ERROR: %s %s" % (errno, errstr))
@@ -342,7 +342,7 @@
         if state == "absent":
             try:
                 changed = db_delete(cursor, db)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="error deleting database: " + str(e))
         elif state == "dump":
             rc, stdout, stderr = db_dump(module, login_host, login_user, 
@@ -366,7 +366,7 @@
         if state == "present":
             try:
                 changed = db_create(cursor, db, encoding, collation)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="error creating database: " + str(e))
 
     module.exit_json(changed=changed, db=db)
--- ./lib/ansible/modules/core/database/mysql/mysql_user.py	(original)
+++ ./lib/ansible/modules/core/database/mysql/mysql_user.py	(refactored)
@@ -144,7 +144,7 @@
 password=n<_665{vS43y
 """
 
-import ConfigParser
+import configparser
 import getpass
 import tempfile
 try:
@@ -179,7 +179,7 @@
 def user_add(cursor, user, host, password, new_priv):
     cursor.execute("CREATE USER %s@%s IDENTIFIED BY %s", (user,host,password))
     if new_priv is not None:
-        for db_table, priv in new_priv.iteritems():
+        for db_table, priv in new_priv.items():
             privileges_grant(cursor, user,host,db_table,priv)
     return True
 
@@ -203,7 +203,7 @@
 
         # If the user has privileges on a db.table that doesn't appear at all in
         # the new specification, then revoke all privileges on it.
-        for db_table, priv in curr_priv.iteritems():
+        for db_table, priv in curr_priv.items():
             # If the user has the GRANT OPTION on a db.table, revoke it first.
             if "GRANT" in priv:
                 grant_option = True
@@ -214,7 +214,7 @@
 
         # If the user doesn't currently have any privileges on a db.table, then
         # we can perform a straight grant operation.
-        for db_table, priv in new_priv.iteritems():
+        for db_table, priv in new_priv.items():
             if db_table not in curr_priv:
                 privileges_grant(cursor, user,host,db_table,priv)
                 changed = True
@@ -323,7 +323,7 @@
     # Escape '%' since mysql db.execute uses a format string and the
     # specification of db and table often use a % (SQL wildcard)
     db_table = db_table.replace('%', '%%')
-    priv_string = ",".join(filter(lambda x: x not in [ 'GRANT', 'REQUIRESSL' ], priv))
+    priv_string = ",".join([x for x in priv if x not in [ 'GRANT', 'REQUIRESSL' ]])
     query = ["GRANT %s ON %s" % (priv_string, mysql_quote_identifier(db_table, 'table'))]
     query.append("TO %s@%s")
     if 'GRANT' in priv:
@@ -391,7 +391,7 @@
     return config
 
 def load_mycnf():
-    config = ConfigParser.RawConfigParser()
+    config = configparser.RawConfigParser()
     mycnf = os.path.expanduser('~/.my.cnf')
     if not os.path.exists(mycnf):
         return False
@@ -406,16 +406,16 @@
     # as these are both supported by MySQL.
     try:
         passwd = config_get(config, 'client', 'password')
-    except (ConfigParser.NoOptionError):
+    except (configparser.NoOptionError):
         try:
             passwd = config_get(config, 'client', 'pass')
-        except (ConfigParser.NoOptionError):
+        except (configparser.NoOptionError):
             return False
 
     # If .my.cnf doesn't specify a user, default to user login name
     try:
         user = config_get(config, 'client', 'user')
-    except (ConfigParser.NoOptionError):
+    except (configparser.NoOptionError):
         user = getpass.getuser()
     creds = dict(user=user,passwd=passwd)
     return creds
@@ -462,7 +462,7 @@
     if priv is not None:
         try:
             priv = privileges_unpack(priv)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="invalid privileges string: %s" % str(e))
 
     # Either the caller passes both a username and password with which to connect to
@@ -491,21 +491,21 @@
 
         if not cursor:
             cursor = connect(module, login_user, login_password)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials")
 
     if state == "present":
         if user_exists(cursor, user, host):
             try:
                 changed = user_mod(cursor, user, host, password, priv, append_privs)
-            except (SQLParseError, InvalidPrivsError, MySQLdb.Error), e:
+            except (SQLParseError, InvalidPrivsError, MySQLdb.Error) as e:
                 module.fail_json(msg=str(e))
         else:
             if password is None:
                 module.fail_json(msg="password parameter required when adding a user")
             try:
                 changed = user_add(cursor, user, host, password, priv)
-            except (SQLParseError, InvalidPrivsError, MySQLdb.Error), e:
+            except (SQLParseError, InvalidPrivsError, MySQLdb.Error) as e:
                 module.fail_json(msg=str(e))
     elif state == "absent":
         if user_exists(cursor, user, host):
--- ./lib/ansible/modules/core/database/mysql/mysql_variables.py	(original)
+++ ./lib/ansible/modules/core/database/mysql/mysql_variables.py	(refactored)
@@ -64,7 +64,7 @@
 '''
 
 
-import ConfigParser
+import configparser
 import os
 import warnings
 
@@ -123,7 +123,7 @@
         cursor.execute(query, (value,))
         cursor.fetchall()
         result = True
-    except Exception, e:
+    except Exception as e:
         result = str(e)
     return result
 
@@ -160,7 +160,7 @@
 
 
 def load_mycnf():
-    config = ConfigParser.RawConfigParser()
+    config = configparser.RawConfigParser()
     mycnf = os.path.expanduser('~/.my.cnf')
     if not os.path.exists(mycnf):
         return False
@@ -172,16 +172,16 @@
     # as these are both supported by MySQL.
     try:
         passwd = config_get(config, 'client', 'password')
-    except (ConfigParser.NoOptionError):
+    except (configparser.NoOptionError):
         try:
             passwd = config_get(config, 'client', 'pass')
-        except (ConfigParser.NoOptionError):
+        except (configparser.NoOptionError):
             return False
 
     # If .my.cnf doesn't specify a user, default to user login name
     try:
         user = config_get(config, 'client', 'user')
-    except (ConfigParser.NoOptionError):
+    except (configparser.NoOptionError):
         user = getpass.getuser()
     creds = dict(user=user, passwd=passwd)
     return creds
@@ -230,7 +230,7 @@
         else:
             db_connection = MySQLdb.connect(host=module.params["login_host"], user=login_user, passwd=login_password, db="mysql")
         cursor = db_connection.cursor()
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials")
     if mysqlvar is None:
         module.fail_json(msg="Cannot run without variable to operate with")
@@ -247,7 +247,7 @@
             module.exit_json(msg="Variable already set to requested value", changed=False)
         try:
             result = setvariable(cursor, mysqlvar, value_wanted)
-        except SQLParseError, e:
+        except SQLParseError as e:
             result = str(e)
         if result is True:
             module.exit_json(msg="Variable change succeeded prev_value=%s" % value_actual, changed=True)
--- ./lib/ansible/modules/core/database/postgresql/postgresql_db.py	(original)
+++ ./lib/ansible/modules/core/database/postgresql/postgresql_db.py	(refactored)
@@ -266,7 +266,7 @@
         "login_password":"password",
         "port":"port"
     }
-    kw = dict( (params_map[k], v) for (k, v) in module.params.iteritems()
+    kw = dict( (params_map[k], v) for (k, v) in module.params.items()
               if k in params_map and v != '' )
 
     # If a login_unix_socket is specified, incorporate it here.
@@ -285,7 +285,7 @@
                                               .ISOLATION_LEVEL_AUTOCOMMIT)
         cursor = db_connection.cursor(
                 cursor_factory=psycopg2.extras.DictCursor)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to connect to database: %s" % e)
 
     try:
@@ -300,21 +300,21 @@
         if state == "absent":
             try:
                 changed = db_delete(cursor, db)
-            except SQLParseError, e:
+            except SQLParseError as e:
                 module.fail_json(msg=str(e))
 
         elif state == "present":
             try:
                 changed = db_create(cursor, db, owner, template, encoding,
                                 lc_collate, lc_ctype)
-            except SQLParseError, e:
+            except SQLParseError as e:
                 module.fail_json(msg=str(e))
-    except NotSupportedError, e:
+    except NotSupportedError as e:
         module.fail_json(msg=str(e))
     except SystemExit:
         # Avoid catching this on Python 2.4 
         raise
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Database query failed: %s" % e)
 
     module.exit_json(changed=changed, db=db)
--- ./lib/ansible/modules/core/database/postgresql/postgresql_privs.py	(original)
+++ ./lib/ansible/modules/core/database/postgresql/postgresql_privs.py	(refactored)
@@ -573,7 +573,7 @@
         module.fail_json(msg='Python module "psycopg2" must be installed.')
     try:
         conn = Connection(p)
-    except psycopg2.Error, e:
+    except psycopg2.Error as e:
         module.fail_json(msg='Could not connect to database: %s' % e)
 
     try:
@@ -613,11 +613,11 @@
             schema_qualifier=p.schema
         )
 
-    except Error, e:
+    except Error as e:
         conn.rollback()
         module.fail_json(msg=e.message)
 
-    except psycopg2.Error, e:
+    except psycopg2.Error as e:
         conn.rollback()
         # psycopg2 errors come in connection encoding, reencode
         msg = e.message.decode(conn.encoding).encode(sys.getdefaultencoding(),
--- ./lib/ansible/modules/core/database/postgresql/postgresql_user.py	(original)
+++ ./lib/ansible/modules/core/database/postgresql/postgresql_user.py	(refactored)
@@ -235,7 +235,7 @@
 
         try:
             cursor.execute(' '.join(alter), query_password_data)
-        except psycopg2.InternalError, e:
+        except psycopg2.InternalError as e:
             if e.pgcode == '25006':
                 # Handle errors due to read-only transactions indicated by pgcode 25006
                 # ERROR:  cannot execute ALTER ROLE in a read-only transaction
@@ -243,7 +243,7 @@
                 module.fail_json(msg=e.pgerror)
                 return changed
             else:
-                raise psycopg2.InternalError, e
+                raise psycopg2.InternalError(e)
 
         # Grab new role attributes.
         cursor.execute(select, {"user": user})
@@ -365,7 +365,7 @@
             'table':revoke_table_privilege,
             'database':revoke_database_privilege
         }[type_]
-        for name, privileges in privs[type_].iteritems():
+        for name, privileges in privs[type_].items():
             for privilege in privileges:
                 changed = revoke_func(cursor, user, name, privilege)\
                         or changed
@@ -382,7 +382,7 @@
             'table':grant_table_privilege,
             'database':grant_database_privilege
         }[type_]
-        for name, privileges in privs[type_].iteritems():
+        for name, privileges in privs[type_].items():
             for privilege in privileges:
                 changed = grant_func(cursor, user, name, privilege)\
                         or changed
@@ -487,7 +487,7 @@
     port = module.params["port"]
     try:
         role_attr_flags = parse_role_attrs(module.params["role_attr_flags"])
-    except InvalidFlagsError, e:
+    except InvalidFlagsError as e:
         module.fail_json(msg=str(e))
     if module.params["encrypted"]:
         encrypted = "ENCRYPTED"
@@ -508,7 +508,7 @@
         "port":"port",
         "db":"database"
     }
-    kw = dict( (params_map[k], v) for (k, v) in module.params.iteritems()
+    kw = dict( (params_map[k], v) for (k, v) in module.params.items()
               if k in params_map and v != "" )
 
     # If a login_unix_socket is specified, incorporate it here.
@@ -519,7 +519,7 @@
     try:
         db_connection = psycopg2.connect(**kw)
         cursor = db_connection.cursor()
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to connect to database: %s" % e)
 
     kw = dict(user=user)
@@ -530,16 +530,16 @@
         if user_exists(cursor, user):
             try:
                 changed = user_alter(cursor, module, user, password, role_attr_flags, encrypted, expires)
-            except SQLParseError, e:
+            except SQLParseError as e:
                 module.fail_json(msg=str(e))
         else:
             try:
                 changed = user_add(cursor, user, password, role_attr_flags, encrypted, expires)
-            except SQLParseError, e:
+            except SQLParseError as e:
                 module.fail_json(msg=str(e))
         try:
             changed = grant_privileges(cursor, user, privs) or changed
-        except SQLParseError, e:
+        except SQLParseError as e:
             module.fail_json(msg=str(e))
     else:
         if user_exists(cursor, user):
@@ -550,7 +550,7 @@
                 try:
                     changed = revoke_privileges(cursor, user, privs)
                     user_removed = user_delete(cursor, user)
-                except SQLParseError, e:
+                except SQLParseError as e:
                     module.fail_json(msg=str(e))
                 changed = changed or user_removed
                 if fail_on_user and not user_removed:
--- ./lib/ansible/modules/core/files/acl.py	(original)
+++ ./lib/ansible/modules/core/files/acl.py	(refactored)
@@ -133,8 +133,8 @@
         a.append(False)
     try:
         p,e,t,d = a
-    except ValueError, e:
-        print "wtf?? %s => %s" % (entry,a)
+    except ValueError as e:
+        print("wtf?? %s => %s" % (entry,a))
         raise e
 
     if d:
@@ -196,7 +196,7 @@
 
     try:
         (rc, out, err) = module.run_command(' '.join(cmd), check_rc=check_rc)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=e.strerror)
 
     # trim last line as it is always empty
--- ./lib/ansible/modules/core/files/copy.py	(original)
+++ ./lib/ansible/modules/core/files/copy.py	(refactored)
@@ -274,7 +274,7 @@
                 # the execute bit for the current user set, in
                 # which case the stat() call will raise an OSError 
                 os.stat(os.path.dirname(dest))
-            except OSError, e:
+            except OSError as e:
                 if "permission denied" in str(e).lower():
                     module.fail_json(msg="Destination directory %s is not accessible" % (os.path.dirname(dest)))
             module.fail_json(msg="Destination directory %s does not exist" % (os.path.dirname(dest)))
--- ./lib/ansible/modules/core/files/file.py	(original)
+++ ./lib/ansible/modules/core/files/file.py	(refactored)
@@ -19,7 +19,7 @@
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
 import shutil
-import stat
+from . import stat
 import grp
 import pwd
 try:
@@ -229,12 +229,12 @@
                 if prev_state == 'directory':
                     try:
                         shutil.rmtree(path, ignore_errors=False)
-                    except Exception, e:
+                    except Exception as e:
                         module.fail_json(msg="rmtree failed: %s" % str(e))
                 else:
                     try:
                         os.unlink(path)
-                    except Exception, e:
+                    except Exception as e:
                         module.fail_json(path=path, msg="unlinking failed: %s " % str(e))
             module.exit_json(path=path, changed=True)
         else:
@@ -345,7 +345,7 @@
                     else:
                         os.symlink(src, tmppath)
                     os.rename(tmppath, path)
-                except OSError, e:
+                except OSError as e:
                     if os.path.exists(tmppath):
                         os.unlink(tmppath)
                     module.fail_json(path=path, msg='Error while replacing: %s' % str(e))
@@ -355,7 +355,7 @@
                         os.link(src,path)
                     else:
                         os.symlink(src, path)
-                except OSError, e:
+                except OSError as e:
                     module.fail_json(path=path, msg='Error while linking: %s' % str(e))
 
         if module.check_mode and not os.path.exists(path):
@@ -370,18 +370,18 @@
             if prev_state == 'absent':
                 try:
                     open(path, 'w').close()
-                except OSError, e:
+                except OSError as e:
                     module.fail_json(path=path, msg='Error, could not touch target: %s' % str(e))
             elif prev_state in ['file', 'directory', 'hard']:
                 try:
                     os.utime(path, None)
-                except OSError, e:
+                except OSError as e:
                     module.fail_json(path=path, msg='Error while touching existing target: %s' % str(e))
             else:
                 module.fail_json(msg='Cannot touch other than files, directories, and hardlinks (%s is %s)' % (path, prev_state))
             try:
                 module.set_fs_attributes_if_different(file_args, True)
-            except SystemExit, e:
+            except SystemExit as e:
                 if e.code:
                     # We take this to mean that fail_json() was called from
                     # somewhere in basic.py
--- ./lib/ansible/modules/core/files/ini_file.py	(original)
+++ ./lib/ansible/modules/core/files/ini_file.py	(refactored)
@@ -87,7 +87,7 @@
             backup=yes
 '''
 
-import ConfigParser
+import configparser
 import sys
 
 # ==============================================================
@@ -97,9 +97,9 @@
 
     changed = False
     if (sys.version_info[0] == 2 and sys.version_info[1] >= 7) or sys.version_info[0] >= 3: 
-        cp = ConfigParser.ConfigParser(allow_no_value=True)
+        cp = configparser.ConfigParser(allow_no_value=True)
     else:
-        cp = ConfigParser.ConfigParser()
+        cp = configparser.ConfigParser()
     cp.optionxform = identity
 
     try:
@@ -137,10 +137,10 @@
                 if str(value) != str(oldvalue):
                     cp.set(section, option, value)
                     changed = True
-            except ConfigParser.NoSectionError:
+            except configparser.NoSectionError:
                 cp.set(section, option, value)
                 changed = True
-            except ConfigParser.NoOptionError:
+            except configparser.NoOptionError:
                 cp.set(section, option, value)
                 changed = True
 
--- ./lib/ansible/modules/core/files/lineinfile.py	(original)
+++ ./lib/ansible/modules/core/files/lineinfile.py	(refactored)
@@ -311,7 +311,7 @@
             found.append(cur_line)
         return not match_found
 
-    lines = filter(matcher, lines)
+    lines = list(filter(matcher, lines))
     changed = len(found) > 0
     backupdest = ""
     if changed and not module.check_mode:
--- ./lib/ansible/modules/core/files/stat.py	(original)
+++ ./lib/ansible/modules/core/files/stat.py	(refactored)
@@ -254,7 +254,7 @@
 
 import os
 import sys
-from stat import *
+from .stat import *
 import pwd
 import grp
 
@@ -280,7 +280,7 @@
             st = os.stat(path)
         else:
             st = os.lstat(path)
-    except OSError, e:
+    except OSError as e:
         if e.errno == errno.ENOENT:
             d = { 'exists' : False }
             module.exit_json(changed=False, stat=d)
--- ./lib/ansible/modules/core/files/unarchive.py	(original)
+++ ./lib/ansible/modules/core/files/unarchive.py	(refactored)
@@ -288,7 +288,7 @@
         file_args['path'] = os.path.join(dest, filename)
         try:
             res_args['changed'] = module.set_fs_attributes_if_different(file_args, res_args['changed'])
-        except (IOError, OSError), e:
+        except (IOError, OSError) as e:
             module.fail_json(msg="Unexpected error when accessing exploded file: %s" % str(e))
 
     module.exit_json(**res_args)
--- ./lib/ansible/modules/core/files/xattr.py	(original)
+++ ./lib/ansible/modules/core/files/xattr.py	(refactored)
@@ -124,7 +124,7 @@
 
     try:
         (rc, out, err) = module.run_command(' '.join(cmd), check_rc=check_rc)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="%s!" % e.strerror)
 
     #result = {'raw': out}
--- ./lib/ansible/modules/core/network/basics/get_url.py	(original)
+++ ./lib/ansible/modules/core/network/basics/get_url.py	(refactored)
@@ -162,7 +162,7 @@
     f = os.fdopen(fd, 'wb')
     try:
         shutil.copyfileobj(rsp, f)
-    except Exception, err:
+    except Exception as err:
         os.remove(tempname)
         module.fail_json(msg="failed to create temporary content file: %s" % str(err))
     f.close()
@@ -271,7 +271,7 @@
     if checksum_src != checksum_dest:
         try:
             shutil.copyfile(tmpsrc, dest)
-        except Exception, err:
+        except Exception as err:
             os.remove(tmpsrc)
             module.fail_json(msg="failed to copy %s to %s: %s" % (tmpsrc, dest, str(err)))
         changed = True
--- ./lib/ansible/modules/core/network/basics/uri.py	(original)
+++ ./lib/ansible/modules/core/network/basics/uri.py	(refactored)
@@ -187,7 +187,7 @@
 HAS_URLPARSE = True
 
 try:
-    import urlparse
+    import urllib.parse
     import socket
 except ImportError:
     HAS_URLPARSE = False
@@ -198,7 +198,7 @@
     f = open(tmpsrc, 'wb')
     try:
         f.write(content)
-    except Exception, err:
+    except Exception as err:
         os.remove(tmpsrc)
         module.fail_json(msg="failed to create temporary content file: %s" % str(err))
     f.close()
@@ -233,7 +233,7 @@
     if checksum_src != checksum_dest:
         try:
             shutil.copyfile(tmpsrc, dest)
-        except Exception, err:
+        except Exception as err:
             os.remove(tmpsrc)
             module.fail_json(msg="failed to copy %s to %s: %s" % (tmpsrc, dest, str(err)))
 
@@ -241,7 +241,7 @@
 
 
 def url_filename(url):
-    fn = os.path.basename(urlparse.urlsplit(url)[2])
+    fn = os.path.basename(urllib.parse.urlsplit(url)[2])
     if fn == '':
         return 'index.html'
     return fn
@@ -334,7 +334,7 @@
         module.fail_json(msg="The server's certificate does not match with its hostname.")
     except httplib2.SSLHandshakeError:
         module.fail_json(msg="Unable to validate server's certificate against available CA certs.")
-    except socket.error, e:
+    except socket.error as e:
         module.fail_json(msg="Socket error: %s to %s" % (e, url))
 
 def main():
@@ -382,7 +382,7 @@
 
     # Grab all the http headers. Need this hack since passing multi-values is currently a bit ugly. (e.g. headers='{"Content-Type":"application/json"}')
     dict_headers = {}
-    for key, value in module.params.iteritems():
+    for key, value in module.params.items():
         if key.startswith("HEADER_"):
             skey = key.replace("HEADER_", "")
             dict_headers[skey] = value
@@ -434,7 +434,7 @@
 
     # Transmogrify the headers, replacing '-' with '_', since variables dont work with dashes.
     uresp = {}
-    for key, value in resp.iteritems():
+    for key, value in resp.items():
         ukey = key.replace("-", "_")  
         uresp[ukey] = value
 
@@ -444,7 +444,7 @@
         content_type, params = cgi.parse_header(uresp['content_type'])
         if 'charset' in params:
             content_encoding = params['charset']
-        u_content = unicode(content, content_encoding, errors='xmlcharrefreplace')
+        u_content = str(content, content_encoding, errors='xmlcharrefreplace')
         if content_type.startswith('application/json') or \
                 content_type.startswith('text/json'):
             try:
@@ -453,7 +453,7 @@
             except:
                 pass
     else:
-        u_content = unicode(content, content_encoding, errors='xmlcharrefreplace')
+        u_content = str(content, content_encoding, errors='xmlcharrefreplace')
 
     if resp['status'] not in status_code:
         module.fail_json(msg="Status code was not " + str(status_code), content=u_content, **uresp)
--- ./lib/ansible/modules/core/packaging/language/pip.py	(original)
+++ ./lib/ansible/modules/core/packaging/language/pip.py	(refactored)
@@ -220,7 +220,7 @@
 
     module = AnsibleModule(
         argument_spec=dict(
-            state=dict(default='present', choices=state_map.keys()),
+            state=dict(default='present', choices=list(state_map.keys())),
             name=dict(default=None, required=False),
             version=dict(default=None, required=False, type='str'),
             requirements=dict(default=None, required=False),
--- ./lib/ansible/modules/core/packaging/os/apt.py	(original)
+++ ./lib/ansible/modules/core/packaging/os/apt.py	(refactored)
@@ -164,8 +164,8 @@
 
 HAS_PYTHON_APT = True
 try:
-    import apt
-    import apt.debfile
+    from . import apt
+    from . import apt.debfile
     import apt_pkg
 except ImportError:
     HAS_PYTHON_APT = False
@@ -337,7 +337,7 @@
         else:
             check_arg = ''
 
-        for (k,v) in APT_ENV_VARS.iteritems():
+        for (k,v) in APT_ENV_VARS.items():
             os.environ[k] = v
 
         if build_dep:
@@ -377,7 +377,7 @@
             # to install so they're all done in one shot
             deps_to_install.extend(pkg.missing_deps)
 
-        except Exception, e:
+        except Exception as e:
             m.fail_json(msg="Unable to install package: %s" % str(e))
 
         # and add this deb to the list of packages to install
@@ -437,7 +437,7 @@
         else:
             purge = ''
 
-        for (k,v) in APT_ENV_VARS.iteritems():
+        for (k,v) in APT_ENV_VARS.items():
             os.environ[k] = v
 
         cmd = "%s -q -y %s %s remove %s" % (APT_GET_CMD, dpkg_options, purge, packages)
@@ -483,7 +483,7 @@
 
     apt_cmd_path = m.get_bin_path(apt_cmd, required=True)
 
-    for (k,v) in APT_ENV_VARS.iteritems():
+    for (k,v) in APT_ENV_VARS.items():
         os.environ[k] = v
 
     cmd = '%s -y %s %s %s %s' % (apt_cmd_path, dpkg_options,
@@ -523,7 +523,7 @@
         try:
             module.run_command('apt-get update && apt-get install python-apt -y -q', use_unsafe_shell=True, check_rc=True)
             global apt, apt_pkg
-            import apt
+            from . import apt
             import apt_pkg
         except ImportError:
             module.fail_json(msg="Could not import python modules: apt, apt_pkg. Please install python-apt package.")
--- ./lib/ansible/modules/core/packaging/os/apt_repository.py	(original)
+++ ./lib/ansible/modules/core/packaging/os/apt_repository.py	(refactored)
@@ -89,7 +89,7 @@
 import tempfile
 
 try:
-    import apt
+    from . import apt
     import apt_pkg
     import aptsources.distro as aptsources_distro
     distro = aptsources_distro.get_distro()
@@ -109,7 +109,7 @@
             rc, so, se = module.run_command('%s update && %s install python-apt -y -q' % (apt_get_path, apt_get_path), use_unsafe_shell=True)
             if rc == 0:
                 global apt, apt_pkg, aptsources_distro, distro, HAVE_PYTHON_APT
-                import apt
+                from . import apt
                 import apt_pkg
                 import aptsources.distro as aptsources_distro
                 distro = aptsources_distro.get_distro()
@@ -139,7 +139,7 @@
 
     def __iter__(self):
         '''Simple iterator to go over all sources. Empty, non-source, and other not valid lines will be skipped.'''
-        for file, sources in self.files.items():
+        for file, sources in list(self.files.items()):
             for n, valid, enabled, source, comment in sources:
                 if valid:
                     yield file, n, enabled, source, comment
@@ -234,7 +234,7 @@
         self.files[file] = group
 
     def save(self):
-        for filename, sources in self.files.items():
+        for filename, sources in list(self.files.items()):
             if sources:
                 d, fn = os.path.split(filename)
                 fd, tmp_path = tempfile.mkstemp(prefix=".%s-" % fn, dir=d)
@@ -257,8 +257,8 @@
 
                     try:
                         f.write(line)
-                    except IOError, err:
-                        self.module.fail_json(msg="Failed to write to file %s: %s" % (tmp_path, unicode(err)))
+                    except IOError as err:
+                        self.module.fail_json(msg="Failed to write to file %s: %s" % (tmp_path, str(err)))
                 self.module.atomic_move(tmp_path, filename)
             else:
                 del self.files[filename]
@@ -382,7 +382,7 @@
     @property
     def repos_urls(self):
         _repositories = []
-        for parsed_repos in self.files.values():
+        for parsed_repos in list(self.files.values()):
             for parsed_repo in parsed_repos:
                 enabled = parsed_repo[1]
                 source_line = parsed_repo[3]
@@ -414,7 +414,7 @@
         argument_spec=dict(
             repo=dict(required=True),
             state=dict(choices=['present', 'absent'], default='present'),
-            mode=dict(required=False, default=0644),
+            mode=dict(required=False, default=0o644),
             update_cache = dict(aliases=['update-cache'], type='bool', default='yes'),
             # this should not be needed, but exists as a failsafe
             install_python_apt=dict(required=False, default="yes", type='bool'),
@@ -450,8 +450,8 @@
             sourceslist.add_source(repo)
         elif state == 'absent':
             sourceslist.remove_source(repo)
-    except InvalidSource, err:
-        module.fail_json(msg='Invalid repository string: %s' % unicode(err))
+    except InvalidSource as err:
+        module.fail_json(msg='Invalid repository string: %s' % str(err))
 
     sources_after = sourceslist.dump()
     changed = sources_before != sources_after
@@ -462,8 +462,8 @@
             if update_cache:
                 cache = apt.Cache()
                 cache.update()
-        except OSError, err:
-            module.fail_json(msg=unicode(err))
+        except OSError as err:
+            module.fail_json(msg=str(err))
 
     module.exit_json(changed=changed, repo=repo, state=state)
 
--- ./lib/ansible/modules/core/packaging/os/redhat_subscription.py	(original)
+++ ./lib/ansible/modules/core/packaging/os/redhat_subscription.py	(refactored)
@@ -75,7 +75,7 @@
 import os
 import re
 import types
-import ConfigParser
+import configparser
 import shlex
 
 
@@ -106,7 +106,7 @@
     def update_plugin_conf(self, plugin, enabled=True):
         plugin_conf = '/etc/yum/pluginconf.d/%s.conf' % plugin
         if os.path.isfile(plugin_conf):
-            cfg = ConfigParser.ConfigParser()
+            cfg = configparser.ConfigParser()
             cfg.read([plugin_conf])
             if enabled:
                 cfg.set('main', 'enabled', 1)
@@ -134,7 +134,7 @@
         '''
 
         # Read RHSM defaults ...
-        cp = ConfigParser.ConfigParser()
+        cp = configparser.ConfigParser()
         cp.read(rhsm_conf)
 
         # Add support for specifying a default value w/o having to standup some configuration
@@ -146,7 +146,7 @@
             else:
                 return default
 
-        cp.get_option = types.MethodType(get_option_default, cp, ConfigParser.ConfigParser)
+        cp.get_option = types.MethodType(get_option_default, cp, configparser.ConfigParser)
 
         return cp
 
@@ -171,7 +171,7 @@
         # Pass supplied **kwargs as parameters to subscription-manager.  Ignore
         # non-configuration parameters and replace '_' with '.'.  For example,
         # 'server_hostname' becomes '--system.hostname'.
-        for k,v in kwargs.items():
+        for k,v in list(kwargs.items()):
             if re.search(r'^(system|rhsm)_', k):
                 args.append('--%s=%s' % (k.replace('_','.'), v))
         
@@ -258,7 +258,7 @@
 
     def __init__(self, module, **kwargs):
         self.module = module
-        for k,v in kwargs.items():
+        for k,v in list(kwargs.items()):
             setattr(self, k, v)
 
     def __str__(self):
@@ -372,7 +372,7 @@
                 rhn.configure(**module.params)
                 rhn.register(username, password, autosubscribe, activationkey)
                 rhn.subscribe(pool)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="Failed to register with '%s': %s" % (server_hostname, e))
             else:
                 module.exit_json(changed=True, msg="System successfully registered to '%s'." % server_hostname)
@@ -385,7 +385,7 @@
             try:
                 rhn.unsubscribe()
                 rhn.unregister()
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="Failed to unregister: %s" % e)
             else:
                 module.exit_json(changed=True, msg="System successfully unregistered from %s." % server_hostname)
--- ./lib/ansible/modules/core/packaging/os/rhn_channel.py	(original)
+++ ./lib/ansible/modules/core/packaging/os/rhn_channel.py	(refactored)
@@ -63,7 +63,7 @@
 - rhn_channel: name=rhel-x86_64-server-v2vwin-6 sysname=server01 url=https://rhn.redhat.com/rpc/api user=rhnuser password=guessme
 '''
 
-import xmlrpclib
+import xmlrpc.client
 from operator import itemgetter
 import re
 
@@ -137,7 +137,7 @@
     password = module.params['password']
     
     #initialize connection
-    client = xmlrpclib.Server(saturl, verbose=0)
+    client = xmlrpc.client.Server(saturl, verbose=0)
     session = client.auth.login(user, password)
      
     # get systemid
--- ./lib/ansible/modules/core/packaging/os/rhn_register.py	(original)
+++ ./lib/ansible/modules/core/packaging/os/rhn_register.py	(refactored)
@@ -90,15 +90,15 @@
 
 import sys
 import types
-import xmlrpclib
-import urlparse
+import xmlrpc.client
+import urllib.parse
 
 # Attempt to import rhn client tools
 sys.path.insert(0, '/usr/share/rhn')
 try:
     import up2date_client
     import up2date_client.config
-except ImportError, e:
+except ImportError as e:
     module.fail_json(msg="Unable to import up2date_client.  Is 'rhn-client-tools' installed?\n%s" % e)
 
 # INSERT REDHAT SNIPPETS
@@ -124,7 +124,7 @@
         def get_option_default(self, key, default=''):
             # ignore pep8 W601 errors for this line
             # setting this to use 'in' does not work in the rhn library
-            if self.has_key(key):
+            if key in self:
                 return self[key]
             else:
                 return default
@@ -141,7 +141,7 @@
 
             Returns: str
         '''
-        url = urlparse.urlparse(self.config['serverURL'])
+        url = urllib.parse.urlparse(self.config['serverURL'])
         return url[1].replace('xmlrpc.','')
 
     @property
@@ -234,7 +234,7 @@
                 url = "https://%s/rpc/api" % self.hostname
             else:
                 url = "https://xmlrpc.%s/rpc/api" % self.hostname
-            self.server = xmlrpclib.Server(url, verbose=0)
+            self.server = xmlrpc.client.Server(url, verbose=0)
             self.session = self.server.auth.login(self.username, self.password)
 
         func = getattr(self.server, method)
@@ -315,7 +315,7 @@
                 rhn.enable()
                 rhn.register(module.params['enable_eus'] == True, activationkey)
                 rhn.subscribe(channels)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="Failed to register with '%s': %s" % (rhn.hostname, e))
 
             module.exit_json(changed=True, msg="System successfully registered to '%s'." % rhn.hostname)
@@ -327,7 +327,7 @@
         else:
             try:
                 rhn.unregister()
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="Failed to unregister: %s" % e)
 
             module.exit_json(changed=True, msg="System successfully unregistered from %s." % rhn.hostname)
--- ./lib/ansible/modules/core/packaging/os/rpm_key.py	(original)
+++ ./lib/ansible/modules/core/packaging/os/rpm_key.py	(refactored)
@@ -126,7 +126,7 @@
             tmpfile.write(key)
             tmpfile.close()
             return tmpname
-        except urllib2.URLError, e:
+        except urllib.error.URLError as e:
             self.module.fail_json(msg=str(e))
 
     def normalize_keyid(self, keyid):
--- ./lib/ansible/modules/core/packaging/os/yum.py	(original)
+++ ./lib/ansible/modules/core/packaging/os/yum.py	(refactored)
@@ -24,7 +24,7 @@
 
 import traceback
 import os
-import yum
+from . import yum
 import rpm
 import syslog
 import platform
@@ -33,7 +33,7 @@
 from distutils.version import LooseVersion
 
 try:
-    from yum.misc import find_unfinished_transactions, find_ts_remaining
+    from .yum.misc import find_unfinished_transactions, find_ts_remaining
     from rpmUtils.miscutils import splitFilename
     transaction_helpers = True
 except:
@@ -224,7 +224,7 @@
             pkgs = e + m
             if not pkgs:
                 pkgs.extend(my.returnInstalledPackagesByDep(pkgspec))
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="Failure talking to yum: %s" % e)
 
         return [ po_to_nevra(p) for p in pkgs ]
@@ -267,7 +267,7 @@
             pkgs = e + m
             if not pkgs:
                 pkgs.extend(my.returnPackagesByDep(pkgspec))
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="Failure talking to yum: %s" % e)
             
         return [ po_to_nevra(p) for p in pkgs ]
@@ -314,7 +314,7 @@
                 e,m,u = my.pkgSack.matchPackageNames([pkgspec])
                 pkgs = e + m
             updates = my.doPackageLists(pkgnarrow='updates').updates 
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="Failure talking to yum: %s" % e)
 
         for pkg in pkgs:
@@ -365,7 +365,7 @@
                 e,m,u = my.rpmdb.matchPackageNames([req_spec])
                 pkgs.extend(e)
                 pkgs.extend(m)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="Failure talking to yum: %s" % e)
 
         return set([ po_to_nevra(p) for p in pkgs ])
@@ -542,7 +542,7 @@
                     f.write(data)
                     f.close()
                     pkg = package
-                except Exception, e:
+                except Exception as e:
                     shutil.rmtree(tempdir)
                     module.fail_json(msg="Failure downloading %s, %s" % (spec, e))
 
@@ -612,7 +612,7 @@
             # Remove rpms downloaded for EL5 via url
             try:
                 shutil.rmtree(tempdir)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="Failure deleting temp directory %s, %s" % (tempdir, e))
 
             module.exit_json(changed=True, results=res['results'], changes=dict(installed=pkgs))
@@ -651,7 +651,7 @@
     # Remove rpms downloaded for EL5 via url
     try:
         shutil.rmtree(tempdir)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Failure deleting temp directory %s, %s" % (tempdir, e))
   
     module.exit_json(**res)
@@ -778,7 +778,7 @@
                     nothing_to_do = False
                     break
 
-            if spec in pkgs['update'] and spec in updates.keys():
+            if spec in pkgs['update'] and spec in list(updates.keys()):
                 nothing_to_do = False
 
             if nothing_to_do:
@@ -794,9 +794,9 @@
 
     # list of package updates
     if update_all:
-        will_update = updates.keys()
-    else:
-        will_update = [u for u in pkgs['update'] if u in updates.keys() or u.startswith('@')]
+        will_update = list(updates.keys())
+    else:
+        will_update = [u for u in pkgs['update'] if u in list(updates.keys()) or u.startswith('@')]
 
     # check_mode output
     if module.check_mode:
@@ -890,19 +890,19 @@
         try:
             if disablerepo:
                 my.repos.disableRepo(disablerepo)
-            current_repos = my.repos.repos.keys()
+            current_repos = list(my.repos.repos.keys())
             if enablerepo:
                 try:
                     my.repos.enableRepo(enablerepo)
-                    new_repos = my.repos.repos.keys()
+                    new_repos = list(my.repos.repos.keys())
                     for i in new_repos:
                         if not i in current_repos:
                             rid = my.repos.getRepo(i)
                             a = rid.repoXML.repoid
                     current_repos = new_repos
-                except yum.Errors.YumBaseError, e:
+                except yum.Errors.YumBaseError as e:
                     module.fail_json(msg="Error setting/accessing repos: %s" % (e))
-        except yum.Errors.YumBaseError, e:
+        except yum.Errors.YumBaseError as e:
             module.fail_json(msg="Error accessing repos: %s" % e)
     if state in ['installed', 'present']:
         if disable_gpg_check:
--- ./lib/ansible/modules/core/source_control/git.py	(original)
+++ ./lib/ansible/modules/core/source_control/git.py	(refactored)
@@ -333,7 +333,7 @@
     cmd = "%s status -s" % (git_path)
     rc, stdout, stderr = module.run_command(cmd, cwd=dest)
     lines = stdout.splitlines()
-    lines = filter(lambda c: not re.search('^\\?\\?.*$', c), lines)
+    lines = [c for c in lines if not re.search('^\\?\\?.*$', c)]
 
     return len(lines) > 0
 
--- ./lib/ansible/modules/core/source_control/hg.py	(original)
+++ ./lib/ansible/modules/core/source_control/hg.py	(refactored)
@@ -23,7 +23,7 @@
 # You should have received a copy of the GNU General Public License
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
-import ConfigParser
+import configparser
 
 DOCUMENTATION = '''
 ---
--- ./lib/ansible/modules/core/source_control/subversion.py	(original)
+++ ./lib/ansible/modules/core/source_control/subversion.py	(refactored)
@@ -157,7 +157,7 @@
         # Match only revisioned files, i.e. ignore status '?'.
         regex = re.compile(r'^[^?]')
         # Has local mods if more than 0 modifed revisioned files.
-        return len(filter(regex.match, lines)) > 0
+        return len(list(filter(regex.match, lines))) > 0
 
     def needs_update(self):
         curr, url = self.get_revision()
--- ./lib/ansible/modules/core/system/authorized_key.py	(original)
+++ ./lib/ansible/modules/core/system/authorized_key.py	(refactored)
@@ -143,7 +143,7 @@
 
     def __init__(self, *args, **kw):
         super(keydict,self).__init__(*args, **kw)
-        self.itemlist = super(keydict,self).keys()
+        self.itemlist = list(super(keydict,self).keys())
     def __setitem__(self, key, value):
         self.itemlist.append(key)
         super(keydict,self).__setitem__(key, value)        
@@ -170,7 +170,7 @@
 
     try:
         user_entry = pwd.getpwnam(user)
-    except KeyError, e:
+    except KeyError as e:
         module.fail_json(msg="Failed to lookup user %s: %s" % (user, str(e)))
     if path is None:
         homedir    = user_entry.pw_dir
@@ -188,11 +188,11 @@
 
     if manage_dir:
         if not os.path.exists(sshdir):
-            os.mkdir(sshdir, 0700)
+            os.mkdir(sshdir, 0o700)
             if module.selinux_enabled():
                 module.set_default_selinux_context(sshdir, False)
         os.chown(sshdir, uid, gid)
-        os.chmod(sshdir, 0700)
+        os.chmod(sshdir, 0o700)
 
     if not os.path.exists(keysfile):
         basedir = os.path.dirname(keysfile)
@@ -207,7 +207,7 @@
 
     try:
         os.chown(keysfile, uid, gid)
-        os.chmod(keysfile, 0600)
+        os.chmod(keysfile, 0o600)
     except OSError:
         pass
 
@@ -314,13 +314,13 @@
     fd, tmp_path = tempfile.mkstemp('', 'tmp', os.path.dirname(filename))
     f = open(tmp_path,"w")
     try:
-        for index, key in keys.items():
+        for index, key in list(keys.items()):
             try:
                 (keyhash,type,options,comment) = key
                 option_str = ""
                 if options:
                     option_strings = []
-                    for option_key in options.keys():
+                    for option_key in list(options.keys()):
                         if options[option_key]:
                             option_strings.append("%s=%s" % (option_key, options[option_key]))
                         else:
@@ -332,7 +332,7 @@
             except:
                 key_line = key
             f.writelines(key_line)
-    except IOError, e:
+    except IOError as e:
         module.fail_json(msg="Failed to write to file %s: %s" % (tmp_path, str(e)))
     f.close()
     module.atomic_move(tmp_path, filename)
--- ./lib/ansible/modules/core/system/cron.py	(original)
+++ ./lib/ansible/modules/core/system/cron.py	(refactored)
@@ -186,7 +186,7 @@
                 f = open(self.cron_file, 'r')
                 self.lines = f.read().splitlines()
                 f.close()
-            except IOError, e:
+            except IOError as e:
                 # cron file does not exist
                 return
             except:
@@ -270,7 +270,7 @@
         try:
             os.unlink(self.cron_file)
             return True
-        except OSError, e:
+        except OSError as e:
             # cron file does not exist
             return False
         except:
@@ -436,7 +436,7 @@
     res_args     = dict()
 
     # Ensure all files generated are only writable by the owning user.  Primarily relevant for the cron_file option.
-    os.umask(022)
+    os.umask(0o22)
     crontab = CronTab(module, user, cron_file)
 
     if crontab.syslogging:
--- ./lib/ansible/modules/core/system/hostname.py	(original)
+++ ./lib/ansible/modules/core/system/hostname.py	(refactored)
@@ -157,7 +157,7 @@
         if not os.path.isfile(self.HOSTNAME_FILE):
             try:
                 open(self.HOSTNAME_FILE, "a").write("")
-            except IOError, err:
+            except IOError as err:
                 self.module.fail_json(msg="failed to write file: %s" %
                     str(err))
         try:
@@ -166,7 +166,7 @@
                 return f.read().strip()
             finally:
                 f.close()
-        except Exception, err:
+        except Exception as err:
             self.module.fail_json(msg="failed to read hostname: %s" %
                 str(err))
 
@@ -177,7 +177,7 @@
                 f.write("%s\n" % name)
             finally:
                 f.close()
-        except Exception, err:
+        except Exception as err:
             self.module.fail_json(msg="failed to update hostname: %s" %
                 str(err))
 
@@ -201,7 +201,7 @@
                         return v.strip()
             finally:
                 f.close()
-        except Exception, err:
+        except Exception as err:
             self.module.fail_json(msg="failed to read hostname: %s" %
                 str(err))
 
@@ -226,7 +226,7 @@
                 f.writelines(lines)
             finally:
                 f.close()
-        except Exception, err:
+        except Exception as err:
             self.module.fail_json(msg="failed to update hostname: %s" %
                 str(err))
 
@@ -293,7 +293,7 @@
                     line = line.strip()
                     if line.startswith('hostname='):
                         return line[10:].strip('"')
-            except Exception, err:
+            except Exception as err:
                 self.module.fail_json(msg="failed to read hostname: %s" % str(err))
         finally:
             f.close()
@@ -314,7 +314,7 @@
 
                 f = open(self.HOSTNAME_FILE, 'w')
                 f.write('\n'.join(lines) + '\n')
-            except Exception, err:
+            except Exception as err:
                 self.module.fail_json(msg="failed to update hostname: %s" % str(err))
         finally:
             f.close()
--- ./lib/ansible/modules/core/system/mount.py	(original)
+++ ./lib/ansible/modules/core/system/mount.py	(refactored)
@@ -292,7 +292,7 @@
             if os.path.exists(name):
                 try:
                     os.rmdir(name)
-                except (OSError, IOError), e:
+                except (OSError, IOError) as e:
                     module.fail_json(msg="Error rmdir %s: %s" % (name, str(e)))
 
         module.exit_json(changed=changed, **args)
@@ -311,7 +311,7 @@
             if not os.path.exists(name):
                 try:
                     os.makedirs(name)
-                except (OSError, IOError), e:
+                except (OSError, IOError) as e:
                     module.fail_json(msg="Error making dir %s: %s" % (name, str(e)))
 
         name, changed = set_mount(**args)
--- ./lib/ansible/modules/core/system/seboolean.py	(original)
+++ ./lib/ansible/modules/core/system/seboolean.py	(refactored)
@@ -54,7 +54,7 @@
 '''
 
 try:
-    import selinux
+    from . import selinux
     HAVE_SELINUX=True
 except ImportError:
     HAVE_SELINUX=False
@@ -69,7 +69,7 @@
     bools = []
     try:
         rc, bools = selinux.security_get_boolean_names()
-    except OSError, e:
+    except OSError as e:
         module.fail_json(msg="Failed to get list of boolean names")
     if name in bools:
         return True
@@ -80,7 +80,7 @@
     state = 0
     try:
         state = selinux.security_get_boolean_active(name)
-    except OSError, e:
+    except OSError as e:
         module.fail_json(msg="Failed to determine current state for boolean %s" % name)
     if state == 1:
         return True
@@ -138,7 +138,7 @@
 
         semanage.semanage_disconnect(handle)
         semanage.semanage_handle_destroy(handle)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Failed to manage policy for boolean %s: %s" % (name, str(e)))
     return True
 
@@ -149,7 +149,7 @@
         value = 1
     try:
         rc = selinux.security_set_boolean(name, value)
-    except OSError, e:
+    except OSError as e:
         module.fail_json(msg="Failed to set boolean %s to %s" % (name, value))
     if rc == 0:
         return True
--- ./lib/ansible/modules/core/system/selinux.py	(original)
+++ ./lib/ansible/modules/core/system/selinux.py	(refactored)
@@ -59,9 +59,9 @@
 import sys
 
 try:
-    import selinux
+    from . import selinux
 except ImportError:
-    print "failed=True msg='libselinux-python required for this module'"
+    print("failed=True msg='libselinux-python required for this module'")
     sys.exit(1)
 
 # getter subroutines
--- ./lib/ansible/modules/core/system/service.py	(original)
+++ ./lib/ansible/modules/core/system/service.py	(refactored)
@@ -216,7 +216,7 @@
                 os._exit(0)
 
             # Start the command
-            if isinstance(cmd, str):
+            if isinstance(cmd, str):
                 cmd = shlex.split(cmd)
             p = subprocess.Popen(cmd, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE, preexec_fn=lambda: os.close(pipe[1]))
             stdout = ""
@@ -414,7 +414,7 @@
             # Check if init is the systemd command, using comm as cmdline could be symlink
             try:
                 f = open('/proc/1/comm', 'r')
-            except IOError, err:
+            except IOError as err:
                 # If comm doesn't exist, old kernel, no systemd
                 return False
 
--- ./lib/ansible/modules/core/system/setup.py	(original)
+++ ./lib/ansible/modules/core/system/setup.py	(refactored)
@@ -80,7 +80,7 @@
     setup_options = dict(module_setup=True)
     facts = ansible_facts(module)
 
-    for (k, v) in facts.items():
+    for (k, v) in list(facts.items()):
         setup_options["ansible_%s" % k.replace('-', '_')] = v
 
     # Look for the path to the facter and ohai binary and set
@@ -98,7 +98,7 @@
         except:
             facter = False
         if facter:
-            for (k,v) in facter_ds.items():
+            for (k,v) in list(facter_ds.items()):
                 setup_options["facter_%s" % k] = v
 
     # ditto for ohai
@@ -110,13 +110,13 @@
         except:
             ohai = False
         if ohai:
-            for (k,v) in ohai_ds.items():
+            for (k,v) in list(ohai_ds.items()):
                 k2 = "ohai_%s" % k.replace('-', '_')
                 setup_options[k2] = v
 
     setup_result = { 'ansible_facts': {} }
 
-    for (k,v) in setup_options.items():
+    for (k,v) in list(setup_options.items()):
         if module.params['filter'] == '*' or fnmatch.fnmatch(k, module.params['filter']):
             setup_result['ansible_facts'][k] = v
 
--- ./lib/ansible/modules/core/system/sysctl.py	(original)
+++ ./lib/ansible/modules/core/system/sysctl.py	(refactored)
@@ -190,7 +190,7 @@
                 return '1'
             else:
                 return '0'
-        elif isinstance(value, str):
+        elif isinstance(value, str):
             if value.lower() in BOOLEANS_TRUE:
                 return '1'
             elif value.lower() in BOOLEANS_FALSE:
@@ -254,7 +254,7 @@
                 f = open(self.sysctl_file, "r")
                 lines = f.readlines()
                 f.close()
-            except IOError, e:
+            except IOError as e:
                 self.module.fail_json(msg="Failed to open %s: %s" % (self.sysctl_file, str(e)))
 
         for line in lines:
@@ -304,7 +304,7 @@
         try:
             for l in self.fixed_lines:
                 f.write(l.strip() + "\n")
-        except IOError, e:
+        except IOError as e:
             self.module.fail_json(msg="Failed to write to file %s: %s" % (tmp_path, str(e)))
         f.flush()
         f.close()
--- ./lib/ansible/modules/core/system/user.py	(original)
+++ ./lib/ansible/modules/core/system/user.py	(refactored)
@@ -274,7 +274,7 @@
         if module.params['expires']:
             try:
                 self.expires = time.gmtime(module.params['expires'])
-            except Exception,e:
+            except Exception as e:
                 module.fail_json("Invalid expires time %s: %s" %(self.expires, str(e)))
 
         if module.params['ssh_key_file'] is not None:
@@ -502,7 +502,7 @@
         if self.groups is None:
             return None
         info = self.user_info()
-        groups = set(filter(None, self.groups.split(',')))
+        groups = set([_f for _f in self.groups.split(',') if _f])
         for g in set(groups):
             if not self.group_exists(g):
                 self.module.fail_json(msg="Group %s does not exist" % (g))
@@ -571,9 +571,9 @@
         ssh_dir = os.path.dirname(ssh_key_file)
         if not os.path.exists(ssh_dir):
             try:
-                os.mkdir(ssh_dir, 0700)
+                os.mkdir(ssh_dir, 0o700)
                 os.chown(ssh_dir, info[2], info[3])
-            except OSError, e:
+            except OSError as e:
                 return (1, '', 'Failed to create %s: %s' % (ssh_dir, str(e)))
         if os.path.exists(ssh_key_file):
             return (None, 'Key already exists', '')
@@ -639,12 +639,12 @@
             if os.path.exists('/etc/skel'):
                 try:
                     shutil.copytree('/etc/skel', path, symlinks=True)
-                except OSError, e:
+                except OSError as e:
                     self.module.exit_json(failed=True, msg="%s" % e)
         else:
             try:
                 os.makedirs(path)
-            except OSError, e:
+            except OSError as e:
                 self.module.exit_json(failed=True, msg="%s" % e)
 
     def chown_homedir(self, uid, gid, path):
@@ -655,7 +655,7 @@
                     os.chown(path, uid, gid)
                 for f in files:
                     os.chown(os.path.join(root, f), uid, gid)
-        except OSError, e:
+        except OSError as e:
             self.module.exit_json(failed=True, msg="%s" % e)
 
 
@@ -1262,7 +1262,7 @@
                         line = ':'.join(fields)
                         lines.append('%s\n' % line)
                     open(self.SHADOWFILE, 'w+').writelines(lines)
-                except Exception, err:
+                except Exception as err:
                     self.module.fail_json(msg="failed to update users password: %s" % str(err))
 
             return (rc, out, err)
@@ -1350,7 +1350,7 @@
                         lines.append('%s\n' % line)
                     open(self.SHADOWFILE, 'w+').writelines(lines)
                     rc = 0
-                except Exception, err:
+                except Exception as err:
                     self.module.fail_json(msg="failed to update users password: %s" % str(err))
 
             return (rc, out, err)
@@ -1620,7 +1620,7 @@
             self.chown_homedir(int(self.uid), int(self.group), self.home)
 
         for field in self.fields:
-            if self.__dict__.has_key(field[0]) and self.__dict__[field[0]]:
+            if field[0] in self.__dict__ and self.__dict__[field[0]]:
 
                 cmd = self._get_dscl()
                 cmd += [ '-create', '/Users/%s' % self.name,
@@ -1657,7 +1657,7 @@
         self._make_group_numerical()
 
         for field in self.fields:
-            if self.__dict__.has_key(field[0]) and self.__dict__[field[0]]:
+            if field[0] in self.__dict__ and self.__dict__[field[0]]:
                 current = self._get_user_property(field[1])
                 if current is None or current != self.__dict__[field[0]]:
                     cmd = self._get_dscl()
--- ./lib/ansible/modules/core/utilities/logic/async_status.py	(original)
+++ ./lib/ansible/modules/core/utilities/logic/async_status.py	(refactored)
@@ -90,7 +90,7 @@
         data['ansible_job_id'] = jid
 
     # Fix error: TypeError: exit_json() keywords must be strings
-    data = dict([(str(k), v) for k, v in data.iteritems()])
+    data = dict([(str(k), v) for k, v in data.items()])
 
     module.exit_json(**data)
 
--- ./lib/ansible/modules/core/utilities/logic/async_wrapper.py	(original)
+++ ./lib/ansible/modules/core/utilities/logic/async_wrapper.py	(refactored)
@@ -42,7 +42,7 @@
             # exit first parent
             sys.exit(0)
     except OSError as e:
-        print >>sys.stderr, "fork #1 failed: %d (%s)" % (e.errno, e.strerror)
+        print("fork #1 failed: %d (%s)" % (e.errno, e.strerror), file=sys.stderr)
         sys.exit(1)
 
     # decouple from parent environment
@@ -57,7 +57,7 @@
             # print "Daemon PID %d" % pid
             sys.exit(0)
     except OSError as e:
-        print >>sys.stderr, "fork #2 failed: %d (%s)" % (e.errno, e.strerror)
+        print("fork #2 failed: %d (%s)" % (e.errno, e.strerror), file=sys.stderr)
         sys.exit(1)
 
     dev_null = open('/dev/null','rw')
@@ -66,10 +66,10 @@
     os.dup2(dev_null.fileno(), sys.stderr.fileno())
 
 if len(sys.argv) < 3:
-    print(json.dumps({
+    print((json.dumps({
         "failed" : True,
         "msg"    : "usage: async_wrapper <jid> <time_limit> <modulescript> <argsfile>.  Humans, do not call directly!"
-    }))
+    })))
     sys.exit(1)
 
 jid = "%s.%d" % (sys.argv[1], os.getpid())
@@ -89,10 +89,10 @@
     try:
         os.makedirs(logdir)
     except:
-        print(json.dumps({
+        print((json.dumps({
             "failed" : 1,
             "msg" : "could not create: %s" % logdir
-        }))
+        })))
 
 def _run_command(wrapped_cmd, jid, log_path):
 
@@ -154,7 +154,7 @@
         # the argsfile at the very first start of their execution anyway
         time.sleep(1)
         debug("Return async_wrapper task started.")
-        print(json.dumps({ "started" : 1, "ansible_job_id" : jid, "results_file" : log_path }))
+        print((json.dumps({ "started" : 1, "ansible_job_id" : jid, "results_file" : log_path })))
         sys.stdout.flush()
         sys.exit(0)
     else:
--- ./lib/ansible/modules/core/utilities/logic/wait_for.py	(original)
+++ ./lib/ansible/modules/core/utilities/logic/wait_for.py	(refactored)
@@ -184,7 +184,7 @@
         for p in psutil.process_iter():
             connections = p.get_connections(kind='inet')
             for conn in connections:
-                if conn.status not in self.connection_states.values():
+                if conn.status not in list(self.connection_states.values()):
                     continue
                 (local_ip, local_port) = conn.local_address
                 if self.port == local_port and self.ip in [self.match_all_ips[self.family], local_ip]:
@@ -280,7 +280,7 @@
         hexed = _little_endian_convert_32bit(hexed)
     elif family == socket.AF_INET6:
         # xrange loops through each 8 character (4B) set in the 128bit total
-        hexed = "".join([ _little_endian_convert_32bit(hexed[x:x+8]) for x in xrange(0, 32, 8) ])
+        hexed = "".join([ _little_endian_convert_32bit(hexed[x:x+8]) for x in range(0, 32, 8) ])
     return (family, hexed)
 
 def _little_endian_convert_32bit(block):
@@ -297,7 +297,7 @@
     """
     # xrange starts at 6, and increments by -2 until it reaches -2
     # which lets us start at the end of the string block and work to the begining
-    return "".join([ block[x:x+2] for x in xrange(6, -2, -2) ])
+    return "".join([ block[x:x+2] for x in range(6, -2, -2) ])
 
 def main():
 
@@ -400,7 +400,7 @@
                             pass
                     else:
                         break
-                except OSError, e:
+                except OSError as e:
                     # File not present
                     if e.errno == 2:
                         time.sleep(1)
--- ./lib/ansible/modules/core/web_infrastructure/django_manage.py	(original)
+++ ./lib/ansible/modules/core/web_infrastructure/django_manage.py	(refactored)
@@ -268,7 +268,7 @@
     lines = out.split('\n')
     filt = globals().get(command + "_filter_output", None)
     if filt:
-        filtered_output = filter(filt, out.split('\n'))
+        filtered_output = list(filter(filt, out.split('\n')))
         if len(filtered_output):
             changed = filtered_output
 
--- ./lib/ansible/modules/core/web_infrastructure/htpasswd.py	(original)
+++ ./lib/ansible/modules/core/web_infrastructure/htpasswd.py	(refactored)
@@ -208,7 +208,7 @@
 
         check_file_attrs(module, changed, msg)
         module.exit_json(msg=msg, changed=changed)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=str(e))
 
 
--- ./lib/ansible/modules/core/windows/win_feature.py	(original)
+++ ./lib/ansible/modules/core/windows/win_feature.py	(refactored)
@@ -74,7 +74,7 @@
 EXAMPLES = '''
 # This installs IIS.
 # The names of features available for install can be run by running the following Powershell Command:
-# PS C:\Users\Administrator> Import-Module ServerManager; Get-WindowsFeature
+# PS C:\\Users\Administrator> Import-Module ServerManager; Get-WindowsFeature
 $ ansible -i hosts -m win_feature -a "name=Web-Server" all
 $ ansible -i hosts -m win_feature -a "name=Web-Server,Web-Common-Http" all
 
--- ./lib/ansible/modules/core/windows/win_get_url.py	(original)
+++ ./lib/ansible/modules/core/windows/win_get_url.py	(refactored)
@@ -47,11 +47,11 @@
 EXAMPLES = '''
 # Downloading a JPEG and saving it to a file with the ansible command.
 # Note the "dest" is quoted rather instead of escaping the backslashes
-$ ansible -i hosts -c winrm -m win_get_url -a "url=http://www.example.com/earthrise.jpg dest='C:\Users\Administrator\earthrise.jpg'" all
+$ ansible -i hosts -c winrm -m win_get_url -a "url=http://www.example.com/earthrise.jpg dest='C:\\Users\Administrator\earthrise.jpg'" all
 
 # Playbook example
-- name: Download earthrise.jpg to 'C:\Users\RandomUser\earthrise.jpg'
+- name: Download earthrise.jpg to 'C:\\Users\RandomUser\earthrise.jpg'
   win_get_url:
     url: 'http://www.example.com/earthrise.jpg'
-    dest: 'C:\Users\RandomUser\earthrise.jpg'
+    dest: 'C:\\Users\RandomUser\earthrise.jpg'
 '''
--- ./lib/ansible/modules/extras/cloud/google/gce_img.py	(original)
+++ ./lib/ansible/modules/extras/cloud/google/gce_img.py	(refactored)
@@ -144,7 +144,7 @@
     except ResourceNotFoundError:
       module.fail_json(msg='Disk %s not found in zone %s' % (source, zone),
                        changed=False)
-    except GoogleBaseError, e:
+    except GoogleBaseError as e:
       module.fail_json(msg=str(e), changed=False)
 
   try:
@@ -152,7 +152,7 @@
     return True
   except ResourceExistsError:
     return False
-  except GoogleBaseError, e:
+  except GoogleBaseError as e:
     module.fail_json(msg=str(e), changed=False)
 
 
@@ -163,7 +163,7 @@
     return True
   except ResourceNotFoundError:
     return False
-  except GoogleBaseError, e:
+  except GoogleBaseError as e:
     module.fail_json(msg=str(e), changed=False)
 
 
--- ./lib/ansible/modules/extras/cloud/lxc/lxc_container.py	(original)
+++ ./lib/ansible/modules/extras/cloud/lxc/lxc_container.py	(refactored)
@@ -312,7 +312,7 @@
     import lxc
 except ImportError:
     msg = 'The lxc module is not importable. Check the requirements.'
-    print("failed=True msg='%s'" % msg)
+    print(("failed=True msg='%s'" % msg))
     raise SystemExit(msg)
 
 
@@ -439,7 +439,7 @@
         f.close()
 
     # Ensure the script is executable.
-    os.chmod(script_file, 0755)
+    os.chmod(script_file, 0o755)
 
     # Get temporary directory.
     tempdir = tempfile.gettempdir()
@@ -528,7 +528,7 @@
         :rtype: ``list``
         """
 
-        for key, value in variables_dict.items():
+        for key, value in list(variables_dict.items()):
             build_command.append(
                 '%s %s' % (key, value)
             )
@@ -547,7 +547,7 @@
             variables.pop(v, None)
 
         return_dict = dict()
-        for k, v in variables.items():
+        for k, v in list(variables.items()):
             _var = self.module.params.get(k)
             if not [i for i in [None, ''] + BOOLEANS_FALSE if i == _var]:
                 return_dict[v] = _var
@@ -575,7 +575,7 @@
 
         lockfile = '/var/lock/subsys/lxc'
 
-        for _ in xrange(timeout):
+        for _ in range(timeout):
             if os.path.exists(lockfile):
                 time.sleep(1)
             else:
@@ -778,7 +778,7 @@
         """
 
         self.container = self.get_container_bind()
-        for _ in xrange(timeout):
+        for _ in range(timeout):
             if self._get_state() != 'running':
                 self.container.start()
                 self.state_change = True
@@ -815,7 +815,7 @@
         :type timeout: ``int``
         """
 
-        for _ in xrange(timeout):
+        for _ in range(timeout):
             if not self._container_exists(name=self.container_name):
                 break
 
@@ -1395,7 +1395,7 @@
             ),
             backing_store=dict(
                 type='str',
-                choices=LXC_BACKING_STORE.keys(),
+                choices=list(LXC_BACKING_STORE.keys()),
                 default='dir'
             ),
             template_options=dict(
@@ -1433,7 +1433,7 @@
                 type='str'
             ),
             state=dict(
-                choices=LXC_ANSIBLE_STATES.keys(),
+                choices=list(LXC_ANSIBLE_STATES.keys()),
                 default='started'
             ),
             container_command=dict(
@@ -1447,7 +1447,7 @@
                 default='false'
             ),
             container_log_level=dict(
-                choices=[n for i in LXC_LOGGING_LEVELS.values() for n in i],
+                choices=[n for i in list(LXC_LOGGING_LEVELS.values()) for n in i],
                 default='INFO'
             ),
             archive=dict(
@@ -1459,7 +1459,7 @@
                 default='/tmp'
             ),
             archive_compression=dict(
-                choices=LXC_COMPRESSION_MAP.keys(),
+                choices=list(LXC_COMPRESSION_MAP.keys()),
                 default='gzip'
             )
         ),
--- ./lib/ansible/modules/extras/cloud/misc/ovirt.py	(original)
+++ ./lib/ansible/modules/extras/cloud/misc/ovirt.py	(refactored)
@@ -211,7 +211,7 @@
     from ovirtsdk.api import API
     from ovirtsdk.xml import params
 except ImportError:
-    print "failed=True msg='ovirtsdk required for this module'"
+    print("failed=True msg='ovirtsdk required for this module'")
     sys.exit(1)
 
 # ------------------------------------------------------------------- #
@@ -222,7 +222,7 @@
     try:
         value = api.test()
     except:
-        print "error connecting to the oVirt API"
+        print("error connecting to the oVirt API")
         sys.exit(1)
     return api
 
@@ -251,17 +251,17 @@
     try:
         conn.vms.add(vmparams)
     except:
-        print "Error creating VM with specified parameters"
+        print("Error creating VM with specified parameters")
         sys.exit(1)
     vm = conn.vms.get(name=vmname)
     try:
         vm.disks.add(vmdisk)
     except:
-        print "Error attaching disk"
+        print("Error attaching disk")
     try:
         vm.nics.add(nic_net1)
     except:
-        print "Error adding nic"
+        print("Error adding nic")
 
 
 # create an instance from a template
@@ -270,7 +270,7 @@
     try:
         conn.vms.add(vmparams)
     except:
-        print 'error adding template %s' % image
+        print('error adding template %s' % image)
         sys.exit(1)
 
 
@@ -304,7 +304,7 @@
 # Get the VMs status
 def vm_status(conn, vmname):
     status = conn.vms.get(name=vmname).status.state
-    print "vm status is : %s" % status
+    print("vm status is : %s" % status)
     return status
 
 
@@ -313,10 +313,10 @@
     vm = conn.vms.get(name=vmname)
     if vm == None:
         name = "empty"
-        print "vmname: %s" % name
+        print("vmname: %s" % name)
     else:
         name = vm.get_name()
-        print "vmname: %s" % name
+        print("vmname: %s" % name)
     return name
 
 # ------------------------------------------------------------------- #
--- ./lib/ansible/modules/extras/cloud/misc/virt.py	(original)
+++ ./lib/ansible/modules/extras/cloud/misc/virt.py	(refactored)
@@ -88,7 +88,7 @@
 try:
     import libvirt
 except ImportError:
-    print "failed=True msg='libvirt python module unavailable'"
+    print("failed=True msg='libvirt python module unavailable'")
     sys.exit(1)
 
 ALL_COMMANDS = []
@@ -479,7 +479,7 @@
     rc = VIRT_SUCCESS
     try:
         rc, result = core(module)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=str(e))
 
     if rc != 0: # something went wrong emit the msg
--- ./lib/ansible/modules/extras/database/misc/mongodb_user.py	(original)
+++ ./lib/ansible/modules/extras/database/misc/mongodb_user.py	(refactored)
@@ -113,7 +113,7 @@
 - mongodb_user: database=burgers name=bob replica_set=blecher password=12345 roles='readWriteAnyDatabase' state=present
 '''
 
-import ConfigParser
+import configparser
 from distutils.version import LooseVersion
 try:
     from pymongo.errors import ConnectionFailure
@@ -141,7 +141,7 @@
     else:
         try:
             db.add_user(user, password, None, roles=roles)
-        except OperationFailure, e:
+        except OperationFailure as e:
             err_msg = str(e)
             if LooseVersion(PyMongoVersion) <= LooseVersion('2.5'):
                 err_msg = err_msg + ' (Note: you must be on mongodb 2.4+ and pymongo 2.5+ to use the roles param)'
@@ -152,7 +152,7 @@
     db.remove_user(user)
 
 def load_mongocnf():
-    config = ConfigParser.RawConfigParser()
+    config = configparser.RawConfigParser()
     mongocnf = os.path.expanduser('~/.mongodb.cnf')
 
     try:
@@ -161,7 +161,7 @@
           user=config.get('client', 'user'),
           password=config.get('client', 'pass')
         )
-    except (ConfigParser.NoOptionError, IOError):
+    except (configparser.NoOptionError, IOError):
         return False
 
     return creds
@@ -228,7 +228,7 @@
         if login_user is not None and login_password is not None:
             client.admin.authenticate(login_user, login_password)
 
-    except ConnectionFailure, e:
+    except ConnectionFailure as e:
         module.fail_json(msg='unable to connect to database: %s' % str(e))
 
     if state == 'present':
@@ -237,13 +237,13 @@
 
         try:
             user_add(module, client, db_name, user, password, roles)
-        except OperationFailure, e:
+        except OperationFailure as e:
             module.fail_json(msg='Unable to add or update user: %s' % str(e))
 
     elif state == 'absent':
         try:
             user_remove(client, db_name, user)
-        except OperationFailure, e:
+        except OperationFailure as e:
             module.fail_json(msg='Unable to remove user: %s' % str(e))
 
     module.exit_json(changed=True, user=user)
--- ./lib/ansible/modules/extras/database/misc/redis.py	(original)
+++ ./lib/ansible/modules/extras/database/misc/redis.py	(refactored)
@@ -122,7 +122,7 @@
 '''
 
 try:
-    import redis
+    from . import redis
 except ImportError:
     redis_found = False
 else:
@@ -214,7 +214,7 @@
                               password=login_password)
         try:
             r.ping()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="unable to connect to database: %s" % e)
 
         #Check if we are already in the mode that we want
@@ -276,7 +276,7 @@
                               db=db)
         try:
             r.ping()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="unable to connect to database: %s" % e)
 
         # Do the stuff
@@ -303,13 +303,13 @@
 
         try:
             r.ping()
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="unable to connect to database: %s" % e)
 
         
         try:
             old_value = r.config_get(name)[name]
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="unable to read config: %s" % e)
         changed = old_value != value
 
@@ -318,7 +318,7 @@
         else:
             try:
                 r.config_set(name, value)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(msg="unable to write config: %s" % e)
             module.exit_json(changed=changed, name=name, value=value)
     else:
--- ./lib/ansible/modules/extras/database/misc/riak.py	(original)
+++ ./lib/ansible/modules/extras/database/misc/riak.py	(refactored)
@@ -94,7 +94,7 @@
 - riak: wait_for_service=kv
 '''
 
-import urllib2
+import urllib.request, urllib.error, urllib.parse
 import time
 import socket
 import sys
--- ./lib/ansible/modules/extras/database/mysql/mysql_replication.py	(original)
+++ ./lib/ansible/modules/extras/database/mysql/mysql_replication.py	(refactored)
@@ -126,7 +126,7 @@
 - mysql_replication: mode=getslave login_host=ansible.example.com login_port=3308
 '''
 
-import ConfigParser
+import configparser
 import os
 import warnings
 
@@ -206,7 +206,7 @@
 
 
 def load_mycnf():
-    config = ConfigParser.RawConfigParser()
+    config = configparser.RawConfigParser()
     mycnf = os.path.expanduser('~/.my.cnf')
     if not os.path.exists(mycnf):
         return False
@@ -218,16 +218,16 @@
     # as these are both supported by MySQL.
     try:
         passwd = config_get(config, 'client', 'password')
-    except (ConfigParser.NoOptionError):
+    except (configparser.NoOptionError):
         try:
             passwd = config_get(config, 'client', 'pass')
-        except (ConfigParser.NoOptionError):
+        except (configparser.NoOptionError):
             return False
 
     # If .my.cnf doesn't specify a user, default to user login name
     try:
         user = config_get(config, 'client', 'user')
-    except (ConfigParser.NoOptionError):
+    except (configparser.NoOptionError):
         user = getpass.getuser()
     creds = dict(user=user, passwd=passwd)
     return creds
@@ -308,11 +308,11 @@
             module.fail_json(msg="login_host is required when login_port is defined, login_host cannot be localhost when login_port is defined")
         else:
             db_connection = MySQLdb.connect(host=module.params["login_host"], port=int(module.params["login_port"]), user=login_user, passwd=login_password)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials")
     try:
         cursor = db_connection.cursor(cursorclass=MySQLdb.cursors.DictCursor)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Trouble getting DictCursor from db_connection: %s" % e)
 
     if mode in "getmaster":
--- ./lib/ansible/modules/extras/database/postgresql/postgresql_ext.py	(original)
+++ ./lib/ansible/modules/extras/database/postgresql/postgresql_ext.py	(refactored)
@@ -146,7 +146,7 @@
         "login_password":"password",
         "port":"port"
     }
-    kw = dict( (params_map[k], v) for (k, v) in module.params.iteritems()
+    kw = dict( (params_map[k], v) for (k, v) in module.params.items()
               if k in params_map and v != '' )
     try:
         db_connection = psycopg2.connect(database=db, **kw)
@@ -159,7 +159,7 @@
                                               .ISOLATION_LEVEL_AUTOCOMMIT)
         cursor = db_connection.cursor(
                 cursor_factory=psycopg2.extras.DictCursor)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to connect to database: %s" % e)
 
     try:
@@ -175,9 +175,9 @@
 
         elif state == "present":
             changed = ext_create(cursor, ext)
-    except NotSupportedError, e:
+    except NotSupportedError as e:
         module.fail_json(msg=str(e))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="Database query failed: %s" % e)
 
     module.exit_json(changed=changed, db=db)
--- ./lib/ansible/modules/extras/database/postgresql/postgresql_lang.py	(original)
+++ ./lib/ansible/modules/extras/database/postgresql/postgresql_lang.py	(refactored)
@@ -203,12 +203,12 @@
         "port":"port",
         "db":"database"
     }
-    kw = dict( (params_map[k], v) for (k, v) in module.params.iteritems()
+    kw = dict( (params_map[k], v) for (k, v) in module.params.items()
               if k in params_map and v != "" )
     try:
         db_connection = psycopg2.connect(**kw)
         cursor = db_connection.cursor()
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to connect to database: %s" % e)
     changed = False
     lang_dropped = False
--- ./lib/ansible/modules/extras/files/patch.py	(original)
+++ ./lib/ansible/modules/extras/files/patch.py	(refactored)
@@ -156,7 +156,7 @@
             apply_patch(patch_func, p.src, p.basedir, dest_file=p.dest, strip=p.strip,
                         dry_run=module.check_mode)
             changed = True
-        except PatchError, e:
+        except PatchError as e:
             module.fail_json(msg=str(e))
 
     module.exit_json(changed=changed)
--- ./lib/ansible/modules/extras/monitoring/airbrake_deployment.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/airbrake_deployment.py	(refactored)
@@ -71,7 +71,7 @@
                        revision=4.2
 '''
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 # ===========================================
 # Module execution.
@@ -116,7 +116,7 @@
         module.exit_json(changed=True)
 
     # Send the data to airbrake
-    data = urllib.urlencode(params)
+    data = urllib.parse.urlencode(params)
     response, info = fetch_url(module, url, data=data)
     if info['status'] == 200:
         module.exit_json(changed=True)
--- ./lib/ansible/modules/extras/monitoring/bigpanda.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/bigpanda.py	(refactored)
@@ -162,7 +162,7 @@
             module.exit_json(changed=True, **deployment)
         else:
             module.fail_json(msg=json.dumps(info))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=str(e))
 
 # import module snippets
--- ./lib/ansible/modules/extras/monitoring/boundary_meter.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/boundary_meter.py	(refactored)
@@ -191,7 +191,7 @@
             try:
                 cert_file = '%s/%s.pem' % (config_directory,cert_type)
                 os.remove(cert_file)
-            except OSError, e:  
+            except OSError as e:  
                 module.fail_json("Failed to remove " + cert_type + ".pem file")
 
     return 0, "Meter " + name + " deleted"
@@ -213,7 +213,7 @@
                 cert_file = open(cert_file_path, 'w')
                 cert_file.write(body)
                 cert_file.close
-                os.chmod(cert_file_path, 0600)
+                os.chmod(cert_file_path, 0o600)
             except: 
                 module.fail_json("Could not write to certificate file")
 
--- ./lib/ansible/modules/extras/monitoring/logentries.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/logentries.py	(refactored)
@@ -133,7 +133,7 @@
 
     # Handle multiple log files
     logs = p["path"].split(",")
-    logs = filter(None, logs)
+    logs = [_f for _f in logs if _f]
 
     if p["state"] in ["present", "followed"]:
         follow_log(module, le_path, logs, name=p['name'], logtype=p['logtype'])
--- ./lib/ansible/modules/extras/monitoring/nagios.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/nagios.py	(refactored)
@@ -115,7 +115,7 @@
 - nagios: action=command command='DISABLE_FAILURE_PREDICTION'
 '''
 
-import ConfigParser
+import configparser
 import types
 import time
 import os.path
@@ -212,7 +212,7 @@
         # Make sure minutes is a number
         try:
             m = int(minutes)
-            if not isinstance(m, types.IntType):
+            if not isinstance(m, int):
                 module.fail_json(msg='minutes must be a number')
         except Exception:
             module.fail_json(msg='invalid entry for minutes')
--- ./lib/ansible/modules/extras/monitoring/newrelic_deployment.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/newrelic_deployment.py	(refactored)
@@ -82,7 +82,7 @@
                        revision=1.0
 '''
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 # ===========================================
 # Module execution.
@@ -128,7 +128,7 @@
 
     # Send the data to NewRelic
     url = "https://rpm.newrelic.com/deployments.xml"
-    data = urllib.urlencode(params)
+    data = urllib.parse.urlencode(params)
     headers = {
         'x-api-key': module.params["token"],
     }
--- ./lib/ansible/modules/extras/monitoring/pingdom.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/pingdom.py	(refactored)
@@ -67,7 +67,7 @@
 '''
 
 try:
-    import pingdom
+    from . import pingdom
     HAS_PINGDOM = True
 except:
     HAS_PINGDOM = False
--- ./lib/ansible/modules/extras/monitoring/rollbar_deployment.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/rollbar_deployment.py	(refactored)
@@ -76,7 +76,7 @@
                       comment='Test Deploy'
 '''
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 def main():
 
@@ -118,9 +118,9 @@
     url = module.params.get('url')
 
     try:
-        data = urllib.urlencode(params)
+        data = urllib.parse.urlencode(params)
         response, info = fetch_url(module, url, data=data)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg='Unable to notify Rollbar: %s' % e)
     else:
         if info['status'] == 200:
--- ./lib/ansible/modules/extras/monitoring/stackdriver.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/stackdriver.py	(refactored)
@@ -175,7 +175,7 @@
             module.fail_json(msg="revision_id required for deploy events")
         try:
             send_deploy_event(module, key, revision_id, deployed_by, deployed_to, repository)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="unable to sent deploy event: %s" % e)
 
     if event == 'annotation':
@@ -183,7 +183,7 @@
             module.fail_json(msg="msg required for annotation events")
         try:
             send_annotation_event(module, key, msg, annotated_by, level, instance_id, event_epoch)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="unable to sent annotation event: %s" % e)
 
     changed = True
--- ./lib/ansible/modules/extras/monitoring/uptimerobot.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/uptimerobot.py	(refactored)
@@ -50,8 +50,8 @@
 '''
 
 import json
-import urllib
-import urllib2
+import urllib.request, urllib.parse, urllib.error
+import urllib.request, urllib.error, urllib.parse
 import time
 
 API_BASE = "http://api.uptimerobot.com/"
@@ -71,11 +71,11 @@
 
 def checkID(params):
 
-	data = urllib.urlencode(params)
+	data = urllib.parse.urlencode(params)
 
 	full_uri = API_BASE + API_ACTIONS['status'] + data
 
-	req = urllib2.urlopen(full_uri)
+	req = urllib.request.urlopen(full_uri)
 
 	result = req.read()
 
@@ -90,11 +90,11 @@
 
 	params['monitorStatus'] = 1
 
-	data = urllib.urlencode(params)
+	data = urllib.parse.urlencode(params)
 
 	full_uri = API_BASE + API_ACTIONS['editMonitor'] + data
 
-	req = urllib2.urlopen(full_uri)
+	req = urllib.request.urlopen(full_uri)
 
 	result = req.read()
 
@@ -109,11 +109,11 @@
 
 	params['monitorStatus'] = 0
 
-	data = urllib.urlencode(params)
+	data = urllib.parse.urlencode(params)
 
 	full_uri = API_BASE + API_ACTIONS['editMonitor'] + data
 
-	req = urllib2.urlopen(full_uri)
+	req = urllib.request.urlopen(full_uri)
 
 	result = req.read()
 
--- ./lib/ansible/modules/extras/monitoring/zabbix_group.py	(original)
+++ ./lib/ansible/modules/extras/monitoring/zabbix_group.py	(refactored)
@@ -159,7 +159,7 @@
         login_user = module.params['login_user'] or os.environ['ZABBIX_LOGIN_USER']
         login_password = module.params['login_password'] or os.environ['ZABBIX_LOGIN_PASSWORD']
         server_url = module.params['server_url'] or os.environ['ZABBIX_SERVER_URL']
-    except KeyError, e:
+    except KeyError as e:
         module.fail_json(msg='Missing login data: %s is not set.' % e.message)
 
     host_group = module.params['host_group']
--- ./lib/ansible/modules/extras/network/dnsimple.py	(original)
+++ ./lib/ansible/modules/extras/network/dnsimple.py	(refactored)
@@ -131,10 +131,10 @@
 
 import os
 try:
-    from dnsimple import DNSimple
-    from dnsimple.dnsimple import DNSimpleException
+    from .dnsimple import DNSimple
+    from .dnsimple.dnsimple import DNSimpleException
 except ImportError:
-    print "failed=True msg='dnsimple required for this module'"
+    print("failed=True msg='dnsimple required for this module'")
     sys.exit(1)
 
 def main():
@@ -291,7 +291,7 @@
             else:
                 module.fail_json(msg="'%s' is an unknown value for the state argument" % state)
 
-    except DNSimpleException, e:
+    except DNSimpleException as e:
         module.fail_json(msg="Unable to contact DNSimple: %s" % e.message)
 
     module.fail_json(msg="Unknown what you wanted me to do")
--- ./lib/ansible/modules/extras/network/dnsmadeeasy.py	(original)
+++ ./lib/ansible/modules/extras/network/dnsmadeeasy.py	(refactored)
@@ -113,7 +113,7 @@
 # DNSMadeEasy module specific support methods.
 #
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 IMPORT_ERROR = None
 try:
@@ -121,7 +121,7 @@
     from time import strftime, gmtime
     import hashlib
     import hmac
-except ImportError, e:
+except ImportError as e:
     IMPORT_ERROR = str(e)
 
 class DME2:
@@ -160,8 +160,8 @@
 
     def query(self, resource, method, data=None):
         url = self.baseurl + resource
-        if data and not isinstance(data, str):
-            data = urllib.urlencode(data)
+        if data and not isinstance(data, str):
+            data = urllib.parse.urlencode(data)
 
         response, info = fetch_url(self.module, url, data=data, method=method, headers=self._headers())
         if info['status'] not in (200, 201, 204):
@@ -169,7 +169,7 @@
 
         try:
             return json.load(response)
-        except Exception, e:
+        except Exception as e:
             return {}
 
     def getDomain(self, domain_id):
--- ./lib/ansible/modules/extras/network/openvswitch_bridge.py	(original)
+++ ./lib/ansible/modules/extras/network/openvswitch_bridge.py	(refactored)
@@ -92,7 +92,7 @@
                 changed = True
             else:
                 changed = False
-        except Exception, e:
+        except Exception as e:
             self.module.fail_json(msg=str(e))
         self.module.exit_json(changed=changed)
 
@@ -108,7 +108,7 @@
                 if not self.exists():
                     self.add()
                     changed = True
-        except Exception, e:
+        except Exception as e:
             self.module.fail_json(msg=str(e))
         self.module.exit_json(changed=changed)
 
--- ./lib/ansible/modules/extras/network/openvswitch_port.py	(original)
+++ ./lib/ansible/modules/extras/network/openvswitch_port.py	(refactored)
@@ -95,7 +95,7 @@
                 changed = True
             else:
                 changed = False
-        except Exception, e:
+        except Exception as e:
             self.module.fail_json(msg=str(e))
         self.module.exit_json(changed=changed)
 
@@ -111,7 +111,7 @@
                 if not self.exists():
                     self.add()
                     changed = True
-        except Exception, e:
+        except Exception as e:
             self.module.fail_json(msg=str(e))
         self.module.exit_json(changed=changed)
 
--- ./lib/ansible/modules/extras/network/snmp_facts.py	(original)
+++ ./lib/ansible/modules/extras/network/snmp_facts.py	(refactored)
@@ -153,7 +153,7 @@
                             2: 'down',
                             3: 'testing'
                           }
-    if int_adminstatus in adminstatus_options.keys():
+    if int_adminstatus in list(adminstatus_options.keys()):
         return adminstatus_options[int_adminstatus]
     else:
         return ""
@@ -168,7 +168,7 @@
                            6: 'notPresent',
                            7: 'lowerLayerDown'
                          }
-    if int_operstatus in operstatus_options.keys():
+    if int_operstatus in list(operstatus_options.keys()):
         return operstatus_options[int_operstatus]
     else:
         return ""
--- ./lib/ansible/modules/extras/network/citrix/netscaler.py	(original)
+++ ./lib/ansible/modules/extras/network/citrix/netscaler.py	(refactored)
@@ -99,7 +99,7 @@
 
 import base64
 import socket
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 class netscaler(object):
 
@@ -111,7 +111,7 @@
     def http_request(self, api_endpoint, data_json={}):
         request_url = self._nsc_protocol + '://' + self._nsc_host + self._nitro_base_url + api_endpoint
 
-        data_json = urllib.urlencode(data_json)
+        data_json = urllib.parse.urlencode(data_json)
         if not len(data_json):
             data_json = None
 
@@ -173,7 +173,7 @@
     rc = 0
     try:
         rc, result = core(module)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=str(e))
 
     if rc != 0:
--- ./lib/ansible/modules/extras/network/f5/bigip_facts.py	(original)
+++ ./lib/ansible/modules/extras/network/f5/bigip_facts.py	(refactored)
@@ -173,7 +173,7 @@
         self.interfaces = api.Networking.Interfaces.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.interfaces = filter(re_filter.search, self.interfaces)
+            self.interfaces = list(filter(re_filter.search, self.interfaces))
 
     def get_list(self):
         return self.interfaces
@@ -278,7 +278,7 @@
         self.self_ips = api.Networking.SelfIPV2.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.self_ips = filter(re_filter.search, self.self_ips)
+            self.self_ips = list(filter(re_filter.search, self.self_ips))
 
     def get_list(self):
         return self.self_ips
@@ -332,7 +332,7 @@
         self.trunks = api.Networking.Trunk.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.trunks = filter(re_filter.search, self.trunks)
+            self.trunks = list(filter(re_filter.search, self.trunks))
 
     def get_list(self):
         return self.trunks
@@ -392,7 +392,7 @@
         self.vlans = api.Networking.VLAN.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.vlans = filter(re_filter.search, self.vlans)
+            self.vlans = list(filter(re_filter.search, self.vlans))
 
     def get_list(self):
         return self.vlans
@@ -486,7 +486,7 @@
         self.virtual_servers = api.LocalLB.VirtualServer.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.virtual_servers = filter(re_filter.search, self.virtual_servers)
+            self.virtual_servers = list(filter(re_filter.search, self.virtual_servers))
 
     def get_list(self):
         return self.virtual_servers
@@ -636,7 +636,7 @@
         self.pool_names = api.LocalLB.Pool.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.pool_names = filter(re_filter.search, self.pool_names)
+            self.pool_names = list(filter(re_filter.search, self.pool_names))
 
     def get_list(self):
         return self.pool_names
@@ -741,7 +741,7 @@
         self.devices = api.Management.Device.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.devices = filter(re_filter.search, self.devices)
+            self.devices = list(filter(re_filter.search, self.devices))
 
     def get_list(self):
         return self.devices
@@ -846,7 +846,7 @@
         self.device_groups = api.Management.DeviceGroup.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.device_groups = filter(re_filter.search, self.device_groups)
+            self.device_groups = list(filter(re_filter.search, self.device_groups))
 
     def get_list(self):
         return self.device_groups
@@ -894,7 +894,7 @@
         self.traffic_groups = api.Management.TrafficGroup.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.traffic_groups = filter(re_filter.search, self.traffic_groups)
+            self.traffic_groups = list(filter(re_filter.search, self.traffic_groups))
 
     def get_list(self):
         return self.traffic_groups
@@ -942,7 +942,7 @@
         self.rules = api.LocalLB.Rule.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.traffic_groups = filter(re_filter.search, self.rules)
+            self.traffic_groups = list(filter(re_filter.search, self.rules))
 
     def get_list(self):
         return self.rules
@@ -974,7 +974,7 @@
         self.nodes = api.LocalLB.NodeAddressV2.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.nodes = filter(re_filter.search, self.nodes)
+            self.nodes = list(filter(re_filter.search, self.nodes))
 
     def get_list(self):
         return self.nodes
@@ -1028,7 +1028,7 @@
         self.virtual_addresses = api.LocalLB.VirtualAddressV2.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.virtual_addresses = filter(re_filter.search, self.virtual_addresses)
+            self.virtual_addresses = list(filter(re_filter.search, self.virtual_addresses))
 
     def get_list(self):
         return self.virtual_addresses
@@ -1085,7 +1085,7 @@
         self.address_classes = api.LocalLB.Class.get_address_class_list()
         if regex:
             re_filter = re.compile(regex)
-            self.address_classes = filter(re_filter.search, self.address_classes)
+            self.address_classes = list(filter(re_filter.search, self.address_classes))
 
     def get_list(self):
         return self.address_classes
@@ -1093,7 +1093,7 @@
     def get_address_class(self):
         key = self.api.LocalLB.Class.get_address_class(self.address_classes)
         value = self.api.LocalLB.Class.get_address_class_member_data_value(key)
-        result = map(zip, [x['members'] for x in key], value)
+        result = list(map(zip, [x['members'] for x in key], value))
         return result
 
     def get_description(self):
@@ -1117,7 +1117,7 @@
         self.certificates = [x['certificate']['cert_info']['id'] for x in self.certificate_list]
         if regex:
             re_filter = re.compile(regex)
-            self.certificates = filter(re_filter.search, self.certificates)
+            self.certificates = list(filter(re_filter.search, self.certificates))
             self.certificate_list = [x for x in self.certificate_list if x['certificate']['cert_info']['id'] in self.certificates]
 
     def get_list(self):
@@ -1144,7 +1144,7 @@
         self.keys = [x['key_info']['id'] for x in self.key_list]
         if regex:
             re_filter = re.compile(regex)
-            self.keys = filter(re_filter.search, self.keys)
+            self.keys = list(filter(re_filter.search, self.keys))
             self.key_list = [x for x in self.key_list if x['key_info']['id'] in self.keys]
 
     def get_list(self):
@@ -1169,7 +1169,7 @@
         self.profiles = api.LocalLB.ProfileClientSSL.get_list()
         if regex:
             re_filter = re.compile(regex)
-            self.profiles = filter(re_filter.search, self.profiles)
+            self.profiles = list(filter(re_filter.search, self.profiles))
 
     def get_list(self):
         return self.profiles
@@ -1520,11 +1520,11 @@
 
 def generate_certificate_dict(f5, regex):
     certificates = Certificates(f5.get_api(), regex)
-    return dict(zip(certificates.get_list(), certificates.get_certificate_list()))
+    return dict(list(zip(certificates.get_list(), certificates.get_certificate_list())))
 
 def generate_key_dict(f5, regex):
     keys = Keys(f5.get_api(), regex)
-    return dict(zip(keys.get_list(), keys.get_key_list()))
+    return dict(list(zip(keys.get_list(), keys.get_key_list())))
 
 def generate_client_ssl_profile_dict(f5, regex):
     profiles = ProfileClientSSL(f5.get_api(), regex)
@@ -1591,13 +1591,13 @@
         regex = fnmatch.translate(fact_filter)
     else:
         regex = None
-    include = map(lambda x: x.lower(), module.params['include'])
+    include = [x.lower() for x in module.params['include']]
     valid_includes = ('address_class', 'certificate', 'client_ssl_profile',
                       'device_group', 'interface', 'key', 'node', 'pool',
                       'rule', 'self_ip', 'software', 'system_info',
                       'traffic_group', 'trunk', 'virtual_address',
                       'virtual_server', 'vlan')
-    include_test = map(lambda x: x in valid_includes, include)
+    include_test = [x in valid_includes for x in include]
     if not all(include_test):
         module.fail_json(msg="value of include must be one or more of: %s, got: %s" % (",".join(valid_includes), ",".join(include)))
 
@@ -1659,7 +1659,7 @@
 
         result = {'ansible_facts': facts}
 
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="received exception: %s\ntraceback: %s" % (e, traceback.format_exc()))
 
     module.exit_json(**result)
--- ./lib/ansible/modules/extras/network/f5/bigip_monitor_http.py	(original)
+++ ./lib/ansible/modules/extras/network/f5/bigip_monitor_http.py	(refactored)
@@ -188,7 +188,7 @@
             result = True
         else:
             module.fail_json(msg='Monitor already exists, but has a different type (%s) or parent(%s)' % (ttype, parent))
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "was not found" in str(e):
             result = False
         else:
@@ -201,7 +201,7 @@
 
     try:
         api.LocalLB.Monitor.create_template(templates=[{'template_name': monitor, 'template_type': TEMPLATE_TYPE}], template_attributes=[template_attributes])
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "already exists" in str(e):
             return False
         else:
@@ -214,7 +214,7 @@
 
     try:
         api.LocalLB.Monitor.delete_template(template_names=[monitor])
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         # maybe it was deleted since we checked
         if "was not found" in str(e):
             return False
@@ -228,7 +228,7 @@
 
     try:
         return str_property == api.LocalLB.Monitor.get_template_string_property([monitor], [str_property['type']])[0]
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         # happens in check mode if not created yet
         if "was not found" in str(e):
             return True
@@ -246,7 +246,7 @@
 
     try:
         return int_property == api.LocalLB.Monitor.get_template_integer_property([monitor], [int_property['type']])[0]
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         # happens in check mode if not created yet
         if "was not found" in str(e):
             return True
@@ -289,7 +289,7 @@
         api.LocalLB.Monitor.set_template_destination(template_names=[monitor], destinations=[ipport])
         return True, ""
 
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "Cannot modify the address type of monitor" in str(e):
             return False, "Cannot modify the address type of monitor if already assigned to a pool."
         else:
@@ -453,7 +453,7 @@
             #else: monitor doesn't exist (check mode) or ipport is already ok
 
 
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="received exception: %s" % e)
 
     module.exit_json(**result)
--- ./lib/ansible/modules/extras/network/f5/bigip_monitor_tcp.py	(original)
+++ ./lib/ansible/modules/extras/network/f5/bigip_monitor_tcp.py	(refactored)
@@ -207,7 +207,7 @@
             result = True
         else:
             module.fail_json(msg='Monitor already exists, but has a different type (%s) or parent(%s)' % (ttype, parent))
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "was not found" in str(e):
             result = False
         else:
@@ -220,7 +220,7 @@
 
     try: 
         api.LocalLB.Monitor.create_template(templates=[{'template_name': monitor, 'template_type': TEMPLATE_TYPE}], template_attributes=[template_attributes])
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "already exists" in str(e):
             return False
         else:
@@ -233,7 +233,7 @@
 
     try:
         api.LocalLB.Monitor.delete_template(template_names=[monitor])
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         # maybe it was deleted since we checked
         if "was not found" in str(e):
             return False
@@ -247,7 +247,7 @@
 
     try:
         return str_property == api.LocalLB.Monitor.get_template_string_property([monitor], [str_property['type']])[0]
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         # happens in check mode if not created yet
         if "was not found" in str(e):
             return True
@@ -266,7 +266,7 @@
 
     try:
         return int_property == api.LocalLB.Monitor.get_template_integer_property([monitor], [int_property['type']])[0]
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         # happens in check mode if not created yet
         if "was not found" in str(e):
             return True
@@ -309,7 +309,7 @@
         api.LocalLB.Monitor.set_template_destination(template_names=[monitor], destinations=[ipport])
         return True, ""
 
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "Cannot modify the address type of monitor" in str(e):
             return False, "Cannot modify the address type of monitor if already assigned to a pool."
         else:
@@ -478,7 +478,7 @@
             #else: monitor doesn't exist (check mode) or ipport is already ok
 
 
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="received exception: %s" % e)
 
     module.exit_json(**result)
--- ./lib/ansible/modules/extras/network/f5/bigip_node.py	(original)
+++ ./lib/ansible/modules/extras/network/f5/bigip_node.py	(refactored)
@@ -160,7 +160,7 @@
     try:
         api.LocalLB.NodeAddressV2.get_object_status(nodes=[address])
         result = True
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "was not found" in str(e):
             result = False
         else:
@@ -173,7 +173,7 @@
         api.LocalLB.NodeAddressV2.create(nodes=[name], addresses=[address], limits=[0])
         result = True
         desc = ""
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "already exists" in str(e):
             result = False
             desc = "referenced name or IP already in use"
@@ -190,7 +190,7 @@
         api.LocalLB.NodeAddressV2.delete_node_address(nodes=[address])
         result = True
         desc = ""
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "is referenced by a member of pool" in str(e):
             result = False
             desc = "node referenced by pool"
@@ -283,7 +283,7 @@
                             set_node_description(api, address, description)
                         result = {'changed': True}
 
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="received exception: %s" % e)
 
     module.exit_json(**result)
--- ./lib/ansible/modules/extras/network/f5/bigip_pool.py	(original)
+++ ./lib/ansible/modules/extras/network/f5/bigip_pool.py	(refactored)
@@ -241,7 +241,7 @@
     try:
         api.LocalLB.Pool.get_object_status(pool_names=[pool])
         result = True
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "was not found" in str(e):
             result = False
         else:
@@ -307,7 +307,7 @@
         api.LocalLB.Pool.get_member_object_status(pool_names=[pool],
                                                   members=[members])
         result = True
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "was not found" in str(e):
             result = False
         else:
@@ -320,7 +320,7 @@
     try:
         api.LocalLB.NodeAddressV2.delete_node_address(nodes=[address])
         result = True
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "is referenced by a member of pool" in str(e):
             result = False
         else:
@@ -456,7 +456,7 @@
                     try:
                         remove_pool(api, pool)
                         result = {'changed': True}
-                    except bigsuds.OperationFailed, e:
+                    except bigsuds.OperationFailed as e:
                         if "was not found" in str(e):
                             result = {'changed': False}
                         else:
@@ -479,7 +479,7 @@
                     try:
                         create_pool(api, pool, lb_method)
                         result = {'changed': True}
-                    except bigsuds.OperationFailed, e:
+                    except bigsuds.OperationFailed as e:
                         if "already exists" in str(e):
                             update = True
                         else:
@@ -525,7 +525,7 @@
                         add_pool_member(api, pool, address, port)
                     result = {'changed': True}
 
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="received exception: %s" % e)
 
     module.exit_json(**result)
--- ./lib/ansible/modules/extras/network/f5/bigip_pool_member.py	(original)
+++ ./lib/ansible/modules/extras/network/f5/bigip_pool_member.py	(refactored)
@@ -195,7 +195,7 @@
     try:
         api.LocalLB.Pool.get_object_status(pool_names=[pool])
         result = True
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "was not found" in str(e):
             result = False
         else:
@@ -211,7 +211,7 @@
         api.LocalLB.Pool.get_member_object_status(pool_names=[pool],
                                                   members=[members])
         result = True
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "was not found" in str(e):
             result = False
         else:
@@ -224,7 +224,7 @@
     try:
         api.LocalLB.NodeAddressV2.delete_node_address(nodes=[address])
         result = True
-    except bigsuds.OperationFailed, e:
+    except bigsuds.OperationFailed as e:
         if "is referenced by a member of pool" in str(e):
             result = False
         else:
@@ -367,7 +367,7 @@
                         set_ratio(api, pool, address, port, ratio)
                     result = {'changed': True}
 
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="received exception: %s" % e)
 
     module.exit_json(**result)
--- ./lib/ansible/modules/extras/notification/flowdock.py	(original)
+++ ./lib/ansible/modules/extras/notification/flowdock.py	(refactored)
@@ -103,7 +103,7 @@
             tags=tag1,tag2,tag3
 '''
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 # ===========================================
 # Module execution.
@@ -178,7 +178,7 @@
         module.exit_json(changed=False)
 
     # Send the data to Flowdock
-    data = urllib.urlencode(params)
+    data = urllib.parse.urlencode(params)
     response, info = fetch_url(module, url, data=data)
     if info['status'] != 200:
         module.fail_json(msg="unable to send msg: %s" % info['msg'])
--- ./lib/ansible/modules/extras/notification/grove.py	(original)
+++ ./lib/ansible/modules/extras/notification/grove.py	(refactored)
@@ -49,7 +49,7 @@
     message=deployed {{ target }}
 '''
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 BASE_URL = 'https://grove.io/api/notice/%s/'
 
@@ -65,7 +65,7 @@
     if icon_url is not None:
         my_data['icon_url'] = icon_url
 
-    data = urllib.urlencode(my_data)
+    data = urllib.parse.urlencode(my_data)
     response, info = fetch_url(module, my_url, data=data)
     if info['status'] != 200:
         module.fail_json(msg="failed to send notification: %s" % info['msg'])
--- ./lib/ansible/modules/extras/notification/hipchat.py	(original)
+++ ./lib/ansible/modules/extras/notification/hipchat.py	(refactored)
@@ -75,7 +75,7 @@
 #
 
 MSG_URI = "https://api.hipchat.com/v1/rooms/message"
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 def send_msg(module, token, room, msg_from, msg, msg_format='text',
              color='yellow', notify=False, api=MSG_URI):
@@ -95,7 +95,7 @@
         params['notify'] = 0
 
     url = api + "?auth_token=%s" % (token)
-    data = urllib.urlencode(params)
+    data = urllib.parse.urlencode(params)
     response, info = fetch_url(module, url, data=data)
     if info['status'] == 200:
         return response.read()
@@ -136,7 +136,7 @@
 
     try:
         send_msg(module, token, room, msg_from, msg, msg_format, color, notify, api)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to sent msg: %s" % e)
 
     changed = True
--- ./lib/ansible/modules/extras/notification/irc.py	(original)
+++ ./lib/ansible/modules/extras/notification/irc.py	(refactored)
@@ -204,7 +204,7 @@
 
     try:
         send_msg(channel, msg, server, port, key, nick, color, passwd, timeout, use_ssl)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to send to IRC: %s" % e)
 
     module.exit_json(changed=False, channel=channel, nick=nick,
--- ./lib/ansible/modules/extras/notification/jabber.py	(original)
+++ ./lib/ansible/modules/extras/notification/jabber.py	(refactored)
@@ -154,7 +154,7 @@
             conn.send(msg)
         time.sleep(1)
         conn.disconnect()
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to send msg: %s" % e)
 
     module.exit_json(changed=False, to=to, user=user, msg=msg.getBody())
--- ./lib/ansible/modules/extras/notification/mail.py	(original)
+++ ./lib/ansible/modules/extras/notification/mail.py	(refactored)
@@ -141,7 +141,7 @@
     import email.utils
     from email.utils import parseaddr, formataddr
     from email.mime.base import MIMEBase
-    from mail.mime.multipart import MIMEMultipart
+    from .mail.mime.multipart import MIMEMultipart
     from email.mime.text import MIMEText
 except ImportError:
     from email import Encoders as encoders
@@ -194,7 +194,7 @@
             smtp = smtplib.SMTP_SSL(host, port=int(port))
         except (smtplib.SMTPException, ssl.SSLError):
             smtp = smtplib.SMTP(host, port=int(port))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(rc=1, msg='Failed to send mail to server %s on port %s: %s' % (host, port, e))
 
     smtp.ehlo()
@@ -259,7 +259,7 @@
 
                 part.add_header('Content-disposition', 'attachment', filename=os.path.basename(file))
                 msg.attach(part)
-            except Exception, e:
+            except Exception as e:
                 module.fail_json(rc=1, msg="Failed to send mail: can't attach file %s: %s" % (file, e))
                 sys.exit()
 
@@ -267,7 +267,7 @@
 
     try:
         smtp.sendmail(sender_addr, set(addr_list), composed)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(rc=1, msg='Failed to send mail to %s: %s' % (", ".join(addr_list), e))
 
     smtp.quit()
--- ./lib/ansible/modules/extras/notification/mqtt.py	(original)
+++ ./lib/ansible/modules/extras/notification/mqtt.py	(refactored)
@@ -156,7 +156,7 @@
                     hostname=server,
                     port=port,
                     auth=auth)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="unable to publish to MQTT broker %s" % (e))
 
     module.exit_json(changed=False, topic=topic)
--- ./lib/ansible/modules/extras/notification/nexmo.py	(original)
+++ ./lib/ansible/modules/extras/notification/nexmo.py	(refactored)
@@ -71,7 +71,7 @@
     msg: "{{ inventory_hostname }} completed"
 """
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 NEXMO_API = 'https://rest.nexmo.com/sms/json'
 
@@ -87,7 +87,7 @@
     }
     for number in module.params.get('dest'):
         msg['to'] = number
-        url = "%s?%s" % (NEXMO_API, urllib.urlencode(msg))
+        url = "%s?%s" % (NEXMO_API, urllib.parse.urlencode(msg))
 
         headers = dict(Accept='application/json')
         response, info = fetch_url(module, url, headers=headers)
--- ./lib/ansible/modules/extras/notification/sns.py	(original)
+++ ./lib/ansible/modules/extras/notification/sns.py	(refactored)
@@ -108,18 +108,18 @@
     import boto.ec2
     import boto.sns
 except ImportError:
-    print "failed=True msg='boto required for this module'"
+    print("failed=True msg='boto required for this module'")
     sys.exit(1)
 
 
 def arn_topic_lookup(connection, short_topic):
     response = connection.get_all_topics()
-    result = response[u'ListTopicsResponse'][u'ListTopicsResult']
+    result = response['ListTopicsResponse']['ListTopicsResult']
     # topic names cannot have colons, so this captures the full topic name
     lookup_topic = ':{}'.format(short_topic)
-    for topic in result[u'Topics']:
-        if topic[u'TopicArn'].endswith(lookup_topic):
-            return topic[u'TopicArn']
+    for topic in result['Topics']:
+        if topic['TopicArn'].endswith(lookup_topic):
+            return topic['TopicArn']
     return None
 
 
@@ -154,7 +154,7 @@
         module.fail_json(msg="region must be specified")
     try:
         connection = connect_to_aws(boto.sns, region, **aws_connect_params)
-    except boto.exception.NoAuthHandlerFound, e:
+    except boto.exception.NoAuthHandlerFound as e:
         module.fail_json(msg=str(e))
 
     # .publish() takes full ARN topic id, but I'm lazy and type shortnames
@@ -183,7 +183,7 @@
     try:
         connection.publish(topic=arn_topic, subject=subject,
                            message_structure='json', message=json_msg)
-    except boto.exception.BotoServerError, e:
+    except boto.exception.BotoServerError as e:
         module.fail_json(msg=str(e))
 
     module.exit_json(msg="OK")
--- ./lib/ansible/modules/extras/notification/twilio.py	(original)
+++ ./lib/ansible/modules/extras/notification/twilio.py	(refactored)
@@ -75,7 +75,7 @@
 # text module support methods
 #
 import base64
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 
 def post_text(module, account_sid, auth_token, msg, from_number, to_number):
@@ -84,7 +84,7 @@
     AGENT = "Ansible/1.5"
 
     data = {'From':from_number, 'To':to_number, 'Body':msg}
-    encoded_data = urllib.urlencode(data)
+    encoded_data = urllib.parse.urlencode(data)
 
     base64string = base64.encodestring('%s:%s' % \
         (account_sid, auth_token)).replace('\n', '')
--- ./lib/ansible/modules/extras/notification/typetalk.py	(original)
+++ ./lib/ansible/modules/extras/notification/typetalk.py	(refactored)
@@ -34,7 +34,7 @@
 '''
 
 try:
-    import urllib
+    import urllib.request, urllib.parse, urllib.error
 except ImportError:
     urllib = None
 
@@ -48,7 +48,7 @@
 
 
 def do_request(module, url, params, headers=None):
-    data = urllib.urlencode(params)
+    data = urllib.parse.urlencode(params)
     if headers is None:
         headers = dict()
     headers = dict(headers, **{
@@ -84,7 +84,7 @@
         }
         do_request(module, url, {'message': msg}, headers)
         return True, {'access_token': access_token}
-    except ConnectionError, e:
+    except ConnectionError as e:
         return False, e
 
 
--- ./lib/ansible/modules/extras/packaging/os/dnf.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/dnf.py	(refactored)
@@ -22,10 +22,10 @@
 
 import traceback
 import os
-import dnf
+from . import dnf
 
 try:
-    from dnf import find_unfinished_transactions, find_ts_remaining
+    from .dnf import find_unfinished_transactions, find_ts_remaining
     from rpmUtils.miscutils import splitFilename
     transaction_helpers = True
 except:
@@ -182,7 +182,7 @@
             pkgs = e + m
             if not pkgs:
                 pkgs.extend(my.returnInstalledPackagesByDep(pkgspec))
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="Failure talking to dnf: %s" % e)
 
         return [ po_to_nevra(p) for p in pkgs ]
@@ -221,7 +221,7 @@
             pkgs = e + m
             if not pkgs:
                 pkgs.extend(my.returnPackagesByDep(pkgspec))
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="Failure talking to dnf: %s" % e)
             
         return [ po_to_nevra(p) for p in pkgs ]
@@ -267,7 +267,7 @@
                 e,m,u = my.pkgSack.matchPackageNames([pkgspec])
                 pkgs = e + m
             updates = my.doPackageLists(pkgnarrow='updates').updates 
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="Failure talking to dnf: %s" % e)
 
         for pkg in pkgs:
@@ -316,7 +316,7 @@
                 e,m,u = my.rpmdb.matchPackageNames([req_spec])
                 pkgs.extend(e)
                 pkgs.extend(m)
-        except Exception, e:
+        except Exception as e:
             module.fail_json(msg="Failure talking to dnf: %s" % e)
 
         return set([ po_to_nevra(p) for p in pkgs ])
@@ -747,15 +747,15 @@
             for r in en_repos:
                 try:
                     my.repos.enableRepo(r)
-                    new_repos = my.repos.repos.keys()
+                    new_repos = list(my.repos.repos.keys())
                     for i in new_repos:
                         if not i in current_repos:
                             rid = my.repos.getRepo(i)
                             a = rid.repoXML.repoid
                     current_repos = new_repos
-                except dnf.exceptions.Error, e:
+                except dnf.exceptions.Error as e:
                     module.fail_json(msg="Error setting/accessing repo %s: %s" % (r, e))
-        except dnf.exceptions.Error, e:
+        except dnf.exceptions.Error as e:
             module.fail_json(msg="Error accessing repos: %s" % e)
 
     if state in ['installed', 'present']:
--- ./lib/ansible/modules/extras/packaging/os/homebrew.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/homebrew.py	(refactored)
@@ -83,7 +83,7 @@
 # utils ------------------------------------------------------------------- {{{
 def _create_regex_group(s):
     lines = (line.strip() for line in s.split('\n') if line.strip())
-    chars = filter(None, (line.split('#')[0].strip() for line in lines))
+    chars = [_f for _f in (line.split('#')[0].strip() for line in lines) if _f]
     group = r'[^' + r''.join(chars) + r']'
     return re.compile(group)
 # /utils ------------------------------------------------------------------ }}}
@@ -138,7 +138,7 @@
              - os.path.sep
         '''
 
-        if isinstance(path, str):
+        if isinstance(path, str):
             return not cls.INVALID_PATH_REGEX.search(path)
 
         try:
@@ -166,7 +166,7 @@
             return True
 
         return (
-            isinstance(brew_path, str)
+            isinstance(brew_path, str)
             and not cls.INVALID_BREW_PATH_REGEX.search(brew_path)
         )
 
@@ -178,7 +178,7 @@
             return True
 
         return (
-            isinstance(package, str)
+            isinstance(package, str)
             and not cls.INVALID_PACKAGE_REGEX.search(package)
         )
 
@@ -199,7 +199,7 @@
             return True
         else:
             return (
-                isinstance(state, str)
+                isinstance(state, str)
                 and state.lower() in (
                     'installed',
                     'upgraded',
@@ -248,7 +248,7 @@
             raise HomebrewException(self.message)
 
         else:
-            if isinstance(path, str):
+            if isinstance(path, str):
                 self._path = path.split(':')
             else:
                 self._path = path
@@ -319,7 +319,7 @@
         self.message = ''
 
     def _setup_instance_vars(self, **kwargs):
-        for key, val in kwargs.iteritems():
+        for key, val in kwargs.items():
             setattr(self, key, val)
 
     def _prep(self):
@@ -453,7 +453,7 @@
             'update',
         ])
         if rc == 0:
-            if out and isinstance(out, str):
+            if out and isinstance(out, str):
                 already_updated = any(
                     re.search(r'Already up-to-date.', s.strip(), re.IGNORECASE)
                     for s in out.split('\n')
--- ./lib/ansible/modules/extras/packaging/os/homebrew_cask.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/homebrew_cask.py	(refactored)
@@ -54,7 +54,7 @@
 # utils ------------------------------------------------------------------- {{{
 def _create_regex_group(s):
     lines = (line.strip() for line in s.split('\n') if line.strip())
-    chars = filter(None, (line.split('#')[0].strip() for line in lines))
+    chars = [_f for _f in (line.split('#')[0].strip() for line in lines) if _f]
     group = r'[^' + r''.join(chars) + r']'
     return re.compile(group)
 # /utils ------------------------------------------------------------------ }}}
@@ -107,7 +107,7 @@
              - os.path.sep
         '''
 
-        if isinstance(path, str):
+        if isinstance(path, str):
             return not cls.INVALID_PATH_REGEX.search(path)
 
         try:
@@ -134,7 +134,7 @@
             return True
 
         return (
-            isinstance(brew_path, str)
+            isinstance(brew_path, str)
             and not cls.INVALID_BREW_PATH_REGEX.search(brew_path)
         )
 
@@ -146,7 +146,7 @@
             return True
 
         return (
-            isinstance(cask, str)
+            isinstance(cask, str)
             and not cls.INVALID_CASK_REGEX.search(cask)
         )
 
@@ -162,7 +162,7 @@
             return True
         else:
             return (
-                isinstance(state, str)
+                isinstance(state, str)
                 and state.lower() in (
                     'installed',
                     'absent',
@@ -206,7 +206,7 @@
             raise HomebrewCaskException(self.message)
 
         else:
-            if isinstance(path, str):
+            if isinstance(path, str):
                 self._path = path.split(':')
             else:
                 self._path = path
@@ -271,7 +271,7 @@
         self.message = ''
 
     def _setup_instance_vars(self, **kwargs):
-        for key, val in kwargs.iteritems():
+        for key, val in kwargs.items():
             setattr(self, key, val)
 
     def _prep(self):
@@ -359,7 +359,7 @@
             'update',
         ], path_prefix=self.path[0])
         if rc == 0:
-            if out and isinstance(out, str):
+            if out and isinstance(out, str):
                 already_updated = any(
                     re.search(r'Already up-to-date.', s.strip(), re.IGNORECASE)
                     for s in out.split('\n')
--- ./lib/ansible/modules/extras/packaging/os/layman.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/layman.py	(refactored)
@@ -79,8 +79,8 @@
 USERAGENT = 'ansible-httpget'
 
 try:
-    from layman.api import LaymanAPI
-    from layman.config import BareConfig
+    from .layman.api import LaymanAPI
+    from .layman.config import BareConfig
     HAS_LAYMAN_API = True
 except ImportError:
     HAS_LAYMAN_API = False
@@ -117,7 +117,7 @@
     try:
         with open(dest, 'w') as f:
             shutil.copyfileobj(response, f)
-    except IOError, e:
+    except IOError as e:
         raise ModuleError("Failed to write: %s" % str(e))
 
 
@@ -236,7 +236,7 @@
         else:
             changed = uninstall_overlay(name)
 
-    except ModuleError, e:
+    except ModuleError as e:
         module.fail_json(msg=e.message)
     else:
         module.exit_json(changed=changed, name=name)
--- ./lib/ansible/modules/extras/packaging/os/pkg5.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/pkg5.py	(refactored)
@@ -116,7 +116,7 @@
         },
     }
 
-    to_modify = filter(behaviour[state]['filter'], packages)
+    to_modify = list(filter(behaviour[state]['filter'], packages))
     if to_modify:
         rc, out, err = module.run_command(
             [
--- ./lib/ansible/modules/extras/packaging/os/pkg5_publisher.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/pkg5_publisher.py	(refactored)
@@ -170,7 +170,7 @@
 
     publishers = {}
     for line in lines:
-        values = dict(zip(keys, map(unstringify, line.split("\t"))))
+        values = dict(list(zip(keys, list(map(unstringify, line.split("\t"))))))
         name = values['publisher']
 
         if not name in publishers:
--- ./lib/ansible/modules/extras/packaging/os/pkgng.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/pkgng.py	(refactored)
@@ -98,7 +98,7 @@
 def pkgng_older_than(module, pkgng_path, compare_version):
 
     rc, out, err = module.run_command("%s -v" % pkgng_path)
-    version = map(lambda x: int(x), re.split(r'[\._]', out))
+    version = [int(x) for x in re.split(r'[\._]', out)]
 
     i = 0
     new_pkgng = True
@@ -239,10 +239,8 @@
 
 def annotate_packages(module, pkgng_path, packages, annotation):
     annotate_c = 0
-    annotations = map(lambda _annotation:
-        re.match(r'(?P<operation>[\+-:])(?P<tag>\w+)(=(?P<value>\w+))?',
-            _annotation).groupdict(),
-        re.split(r',', annotation))
+    annotations = [re.match(r'(?P<operation>[\+-:])(?P<tag>\w+)(=(?P<value>\w+))?',
+            _annotation).groupdict() for _annotation in re.split(r',', annotation)]
 
     operation = {
         '+': annotation_add,
--- ./lib/ansible/modules/extras/packaging/os/portage.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/portage.py	(refactored)
@@ -268,7 +268,7 @@
         'getbinpkg': '--getbinpkg',
         'usepkgonly': '--usepkgonly',
     }
-    for flag, arg in emerge_flags.iteritems():
+    for flag, arg in emerge_flags.items():
         if p[flag]:
             args.append(arg)
 
--- ./lib/ansible/modules/extras/packaging/os/zypper.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/zypper.py	(refactored)
@@ -130,7 +130,7 @@
         package = m.group(1)
         result = m.group(2)
         if not name.startswith(package):
-            print name + ':' + package + ':' + stdoutline + '\n'
+            print(name + ':' + package + ':' + stdoutline + '\n')
             return None
         if result == 'is installed':
             installed_state[name] = True
--- ./lib/ansible/modules/extras/packaging/os/zypper_repository.py	(original)
+++ ./lib/ansible/modules/extras/packaging/os/zypper_repository.py	(refactored)
@@ -136,7 +136,7 @@
             if k not in realrepo:
                 return False
 
-        for k, v in realrepo.items():
+        for k, v in list(realrepo.items()):
             if k in repocmp:
                 if v.rstrip("/") != repocmp[k].rstrip("/"):
                     return False
--- ./lib/ansible/modules/extras/source_control/bzr.py	(original)
+++ ./lib/ansible/modules/extras/source_control/bzr.py	(refactored)
@@ -19,7 +19,7 @@
 # You should have received a copy of the GNU General Public License
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
-DOCUMENTATION = u'''
+DOCUMENTATION = '''
 ---
 module: bzr
 author: André Paramés
@@ -107,7 +107,7 @@
         rc, stdout, stderr = self.module.run_command(cmd, cwd=self.dest)
         lines = stdout.splitlines()
 
-        lines = filter(lambda c: not re.search('^\\?\\?.*$', c), lines)
+        lines = [c for c in lines if not re.search('^\\?\\?.*$', c)]
         return len(lines) > 0
 
     def reset(self, force):
--- ./lib/ansible/modules/extras/system/alternatives.py	(original)
+++ ./lib/ansible/modules/extras/system/alternatives.py	(refactored)
@@ -132,7 +132,7 @@
             )
 
             module.exit_json(changed=True)
-        except subprocess.CalledProcessError, cpe:
+        except subprocess.CalledProcessError as cpe:
             module.fail_json(msg=str(dir(cpe)))
     else:
         module.exit_json(changed=False)
--- ./lib/ansible/modules/extras/system/capabilities.py	(original)
+++ ./lib/ansible/modules/extras/system/capabilities.py	(refactored)
@@ -97,7 +97,7 @@
                 self.module.exit_json(changed=True, msg='capabilities changed')
             else:
                 # remove from current cap list if it's already set (but op/flags differ)
-                current = filter(lambda x: x[0] != self.capability_tup[0], current)
+                current = [x for x in current if x[0] != self.capability_tup[0]]
                 # add new cap with correct op/flags
                 current.append( self.capability_tup )
                 self.module.exit_json(changed=True, state=self.state, msg='capabilities changed', stdout=self.setcap(self.path, current))
@@ -107,7 +107,7 @@
                 self.module.exit_json(changed=True, msg='capabilities changed')
             else:
                 # remove from current cap list and then set current list
-                current = filter(lambda x: x[0] != self.capability_tup[0], current)
+                current = [x for x in current if x[0] != self.capability_tup[0]]
                 self.module.exit_json(changed=True, state=self.state, msg='capabilities changed', stdout=self.setcap(self.path, current))
         self.module.exit_json(changed=False, state=self.state)
 
--- ./lib/ansible/modules/extras/system/crypttab.py	(original)
+++ ./lib/ansible/modules/extras/system/crypttab.py	(refactored)
@@ -123,7 +123,7 @@
     try:
         crypttab = Crypttab(path)
         existing_line = crypttab.match(name)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg="failed to open and parse crypttab file: %s" % e,
                          **module.params)
 
@@ -298,8 +298,8 @@
 
     def add(self, opts_string):
         changed = False
-        for k, v in Options(opts_string).items():
-            if self.has_key(k):
+        for k, v in list(Options(opts_string).items()):
+            if k in self:
                 if self[k] != v:
                     changed = True
             else:
@@ -310,7 +310,7 @@
     def remove(self, opts_string):
         changed = False
         for k in Options(opts_string):
-            if self.has_key(k):
+            if k in self:
                 del self[k]
                 changed = True
         return changed, 'removed options'
@@ -328,7 +328,7 @@
         return iter(self.itemlist)
 
     def __setitem__(self, key, value):
-        if not self.has_key(key):
+        if key not in self:
             self.itemlist.append(key)
         super(Options, self).__setitem__(key, value)
 
@@ -342,7 +342,7 @@
 
     def __str__(self):
         ret = []
-        for k, v in self.items():
+        for k, v in list(self.items()):
             if v is None:
                 ret.append(k)
             else:
--- ./lib/ansible/modules/extras/system/firewalld.py	(original)
+++ ./lib/ansible/modules/extras/system/firewalld.py	(refactored)
@@ -92,10 +92,10 @@
     if not fw.connected:
         raise Exception('failed to connect to the firewalld daemon')
 except ImportError:
-    print "failed=True msg='firewalld required for this module'"
+    print("failed=True msg='firewalld required for this module'")
     sys.exit(1)
-except Exception, e:
-    print "failed=True msg='%s'" % str(e)
+except Exception as e:
+    print("failed=True msg='%s'" % str(e))
     sys.exit(1)
 
 ################
--- ./lib/ansible/modules/extras/system/getent.py	(original)
+++ ./lib/ansible/modules/extras/system/getent.py	(refactored)
@@ -110,7 +110,7 @@
 
     try:
         rc, out, err = module.run_command(cmd)
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg=str(e))
 
     msg = "Unexpected failure!"
--- ./lib/ansible/modules/extras/system/gluster_volume.py	(original)
+++ ./lib/ansible/modules/extras/system/gluster_volume.py	(refactored)
@@ -141,7 +141,7 @@
         rc, out, err = module.run_command(args, **kwargs)
         if rc != 0:
             module.fail_json(msg='error running gluster (%s) command (rc=%d): %s' % (' '.join(args), rc, out or err))
-    except Exception, e:
+    except Exception as e:
         module.fail_json(msg='error running gluster (%s) command: %s' % (' '.join(args), str(e)))
     return out
 
@@ -404,7 +404,7 @@
                     changed = True
 
             # set options
-            for option in options.keys():
+            for option in list(options.keys()):
                 if option not in volumes[volume_name]['options'] or volumes[volume_name]['options'][option] != options[option]:
                     set_volume_option(volume_name, option, options[option])
                     changed = True
--- ./lib/ansible/modules/extras/system/known_hosts.py	(original)
+++ ./lib/ansible/modules/extras/system/known_hosts.py	(refactored)
@@ -121,7 +121,7 @@
     if replace==True or (current==False and state=="present"):
         try:
             inf=open(path,"r")
-        except IOError, e:
+        except IOError as e:
             if e.errno == errno.ENOENT:
                 inf=None
             else:
@@ -136,7 +136,7 @@
             outf.write(key)
             outf.flush()
             module.atomic_move(outf.name,path)
-        except (IOError,OSError),e:
+        except (IOError,OSError) as e:
             module.fail_json(msg="Failed to write to file %s: %s" % \
                                  (path,str(e)))
 
@@ -170,7 +170,7 @@
         outf=tempfile.NamedTemporaryFile()
         outf.write(key)
         outf.flush()
-    except IOError,e:
+    except IOError as e:
         module.fail_json(msg="Failed to write to temporary file %s: %s" % \
                              (outf.name,str(e)))
     rc,stdout,stderr=module.run_command([sshkeygen,'-F',host,
--- ./lib/ansible/modules/extras/system/locale_gen.py	(original)
+++ ./lib/ansible/modules/extras/system/locale_gen.py	(refactored)
@@ -72,7 +72,7 @@
 def fix_case(name):
     """locale -a might return the encoding in either lower or upper case.
     Passing through this function makes them uniform for comparisons."""
-    for s, r in LOCALE_NORMALIZATION.iteritems():
+    for s, r in LOCALE_NORMALIZATION.items():
         name = name.replace(s, r)
     return name
 
@@ -191,7 +191,7 @@
                     apply_change(state, name)
                 else:
                     apply_change_ubuntu(state, name)
-            except EnvironmentError, e:
+            except EnvironmentError as e:
                 module.fail_json(msg=e.strerror, exitValue=e.errno)
 
         module.exit_json(name=name, changed=changed, msg="OK")
--- ./lib/ansible/modules/extras/system/modprobe.py	(original)
+++ ./lib/ansible/modules/extras/system/modprobe.py	(refactored)
@@ -81,7 +81,7 @@
                 present = True
                 break
         modules.close()
-    except IOError, e:
+    except IOError as e:
         module.fail_json(msg=str(e), **args)
 
     # Check only; don't modify
--- ./lib/ansible/modules/extras/system/svc.py	(original)
+++ ./lib/ansible/modules/extras/system/svc.py	(refactored)
@@ -152,7 +152,7 @@
         if os.path.exists(self.src_full):
             try:
                 os.symlink(self.src_full, self.svc_full)
-            except OSError, e:
+            except OSError as e:
                 self.module.fail_json(path=self.src_full, msg='Error while linking: %s' % str(e))
         else:
             self.module.fail_json(msg="Could not find source for service to enable (%s)." % self.src_full)
@@ -160,7 +160,7 @@
     def disable(self):
         try:
             os.unlink(self.svc_full)
-        except OSError, e:
+        except OSError as e:
             self.module.fail_json(path=self.svc_full, msg='Error while unlinking: %s' % str(e))
         self.execute_command([self.svc_cmd,'-dx',self.src_full])
 
@@ -221,7 +221,7 @@
     def execute_command(self, cmd):
         try:
             (rc, out, err) = self.module.run_command(' '.join(cmd))
-        except Exception, e:
+        except Exception as e:
             self.module.fail_json(msg="failed to execute: %s" % str(e))
         return (rc, out, err)
 
@@ -265,7 +265,7 @@
                     svc.enable()
                 else:
                     svc.disable()
-            except (OSError, IOError), e:
+            except (OSError, IOError) as e:
                 module.fail_json(msg="Could change service link: %s" % str(e))
 
     if state is not None and state != svc.state:
@@ -282,7 +282,7 @@
                     open(d_file, "a").close()
                 else:
                     os.unlink(d_file)
-            except (OSError, IOError), e:
+            except (OSError, IOError) as e:
                 module.fail_json(msg="Could change downed file: %s " % (str(e)))
 
     module.exit_json(changed=changed, svc=svc.report())
--- ./lib/ansible/modules/extras/system/ufw.py	(original)
+++ ./lib/ansible/modules/extras/system/ufw.py	(refactored)
@@ -193,7 +193,7 @@
     cmds = []
 
     def execute(cmd):
-        cmd = ' '.join(map(itemgetter(-1), filter(itemgetter(0), cmd)))
+        cmd = ' '.join(map(itemgetter(-1), list(filter(itemgetter(0), cmd))))
 
         cmds.append(cmd)
         (rc, out, err) = module.run_command(cmd)
@@ -221,7 +221,7 @@
     (_, pre_rules, _) = module.run_command("grep '^### tuple' /lib/ufw/user*.rules")
 
     # Execute commands
-    for (command, value) in commands.iteritems():
+    for (command, value) in commands.items():
         cmd = [[ufw_bin], [module.check_mode, '--dry-run']]
 
         if command == 'state':
--- ./lib/ansible/modules/extras/system/zfs.py	(original)
+++ ./lib/ansible/modules/extras/system/zfs.py	(refactored)
@@ -263,7 +263,7 @@
         if volblocksize:
             cmd.append('-b %s' % volblocksize)
         if properties:
-            for prop, value in properties.iteritems():
+            for prop, value in properties.items():
                 cmd.append('-o %s="%s"' % (prop, value))
         if volsize:
             cmd.append('-V')
@@ -302,7 +302,7 @@
 
     def set_properties_if_changed(self):
         current_properties = self.get_current_properties()
-        for prop, value in self.properties.iteritems():
+        for prop, value in self.properties.items():
             if current_properties[prop] != value:
                 if prop in self.immutable_properties:
                     self.module.fail_json(msg='Cannot change property %s after creation.' % prop)
@@ -386,7 +386,7 @@
 
     # Get all valid zfs-properties
     properties = dict()
-    for prop, value in module.params.iteritems():
+    for prop, value in module.params.items():
         if prop in ['CHECKMODE']:
             continue
         if value:
--- ./lib/ansible/modules/extras/web_infrastructure/ejabberd_user.py	(original)
+++ ./lib/ansible/modules/extras/web_infrastructure/ejabberd_user.py	(refactored)
@@ -98,7 +98,7 @@
         try:
             options = [self.user, self.host, self.pwd]
             (rc, out, err) = self.run_command('check_password', options)
-        except EjabberdUserException, e:
+        except EjabberdUserException as e:
             (rc, out, err) = (1, None, "required attribute(s) missing")
         return rc
 
@@ -111,7 +111,7 @@
         try:
             options = [self.user, self.host]
             (rc, out, err) = self.run_command('check_account', options)
-        except EjabberdUserException, e:
+        except EjabberdUserException as e:
             (rc, out, err) = (1, None, "required attribute(s) missing")
         return not bool(int(rc))
 
@@ -139,7 +139,7 @@
         try:
             options = [self.user, self.host, self.pwd]
             (rc, out, err) = self.run_command('change_password', options)
-        except EjabberdUserException, e:
+        except EjabberdUserException as e:
             (rc, out, err) = (1, None, "required attribute(s) missing")
         return (rc, out, err)
 
@@ -150,7 +150,7 @@
         try:
             options = [self.user, self.host, self.pwd]
             (rc, out, err) = self.run_command('register', options)
-        except EjabberdUserException, e:
+        except EjabberdUserException as e:
             (rc, out, err) = (1, None, "required attribute(s) missing")
         return (rc, out, err)
 
@@ -160,7 +160,7 @@
         try:
             options = [self.user, self.host]
             (rc, out, err) = self.run_command('unregister', options)
-        except EjabberdUserException, e:
+        except EjabberdUserException as e:
             (rc, out, err) = (1, None, "required attribute(s) missing")
         return (rc, out, err)
 
--- ./lib/ansible/modules/extras/web_infrastructure/jira.py	(original)
+++ ./lib/ansible/modules/extras/web_infrastructure/jira.py	(refactored)
@@ -335,7 +335,7 @@
 
         ret = method(restbase, user, passwd, module.params)
 
-    except Exception, e:
+    except Exception as e:
         return module.fail_json(msg=e.message)
 
 
--- ./lib/ansible/playbook/__init__.py	(original)
+++ ./lib/ansible/playbook/__init__.py	(refactored)
@@ -243,7 +243,7 @@
         elif isinstance(play['vars'], list):
             # nobody should really do this, but handle vars: a=1 b=2
             play_vars = play['vars'][:]
-            play_vars.extend([{k:v} for k,v in vars.iteritems()])
+            play_vars.extend([{k:v} for k,v in vars.items()])
 
         return play_vars
 
@@ -353,7 +353,7 @@
 
         # summarize the results
         results = {}
-        for host in self.stats.processed.keys():
+        for host in list(self.stats.processed.keys()):
             results[host] = self.stats.summarize(host)
         return results
 
@@ -444,7 +444,7 @@
                 # if not polling, playbook requested fire and forget, so don't poll
                 results = self._async_poll(poller, task.async_seconds, task.async_poll_interval)
             else:
-                for (host, res) in results.get('contacted', {}).iteritems():
+                for (host, res) in results.get('contacted', {}).items():
                     self.runner_callbacks.on_async_ok(host, res, poller.runner.vars_cache[host]['ansible_job_id'])
 
         contacted = results.get('contacted',{})
@@ -452,7 +452,7 @@
 
         self.inventory.lift_restriction()
 
-        if len(contacted.keys()) == 0 and len(dark.keys()) == 0:
+        if len(list(contacted.keys())) == 0 and len(list(dark.keys())) == 0:
             return None
 
         return results
@@ -522,7 +522,7 @@
                 utils.update_hash(self.SETUP_CACHE, host, facts)
 
         # add facts to the global setup cache
-        for host, result in contacted.iteritems():
+        for host, result in contacted.items():
             if 'results' in result:
                 # task ran with_ lookup plugin, so facts are encapsulated in
                 # multiple list items in the results key
@@ -542,12 +542,12 @@
         # also have to register some failed, but ignored, tasks
         if task.ignore_errors and task.register:
             failed = results.get('failed', {})
-            for host, result in failed.iteritems():
+            for host, result in failed.items():
                 _register_play_vars(host, result)
 
         # flag which notify handlers need to be run
         if task.notify and len(task.notify) > 0:
-            for host, results in results.get('contacted',{}).iteritems():
+            for host, results in results.get('contacted',{}).items():
                 if results.get('changed', False):
                     for handler_name in task.notify:
                         self._flag_handler(play, template(play.basedir, handler_name, task.module_vars), host)
@@ -635,7 +635,7 @@
         # now for each result, load into the setup cache so we can
         # let runner template out future commands
         setup_ok = setup_results.get('contacted', {})
-        for (host, result) in setup_ok.iteritems():
+        for (host, result) in setup_ok.items():
             utils.update_hash(self.SETUP_CACHE, host, {'module_setup': True})
             utils.update_hash(self.SETUP_CACHE, host, result.get('ansible_facts', {}))
         return setup_results
--- ./lib/ansible/playbook/play.py	(original)
+++ ./lib/ansible/playbook/play.py	(refactored)
@@ -58,7 +58,7 @@
     def __init__(self, playbook, ds, basedir, vault_password=None):
         ''' constructor loads from a play datastructure '''
 
-        for x in ds.keys():
+        for x in list(ds.keys()):
             if not x in Play.VALID_KEYS:
                 raise errors.AnsibleError("%s is not a legal parameter of an Ansible Play" % x)
 
@@ -77,7 +77,7 @@
 
         if self.tags is None:
             self.tags = []
-        elif type(self.tags) in [ str, unicode ]:
+        elif type(self.tags) in [ str, str ]:
             self.tags = self.tags.split(",")
         elif type(self.tags) != list:
             self.tags = []
@@ -304,11 +304,11 @@
                         # (dep_vars) to look for tags going forward
                         def __merge_tags(var_obj):
                             old_tags = dep_vars.get('tags', [])
-                            if isinstance(old_tags, str):
+                            if isinstance(old_tags, str):
                                 old_tags = [old_tags, ]
                             if isinstance(var_obj, dict):
                                 new_tags = var_obj.get('tags', [])
-                                if isinstance(new_tags, str):
+                                if isinstance(new_tags, str):
                                     new_tags = [new_tags, ]
                             else:
                                 new_tags = []
@@ -356,7 +356,7 @@
                                 self.included_roles.append(dep)
 
                         def _merge_conditional(cur_conditionals, new_conditionals):
-                            if isinstance(new_conditionals, (str, bool)):
+                            if isinstance(new_conditionals, (str, bool)):
                                 cur_conditionals.append(new_conditionals)
                             elif isinstance(new_conditionals, list):
                                 cur_conditionals.extend(new_conditionals)
@@ -615,7 +615,7 @@
                     elif k.startswith("when_"):
                         utils.deprecated("\"when_<criteria>:\" is a removed deprecated feature, use the simplified 'when:' conditional directly", None, removed=True)
                     elif k == 'when':
-                        if isinstance(x[k], (str, bool)):
+                        if isinstance(x[k], (str, bool)):
                             included_additional_conditions.append(x[k])
                         elif type(x[k]) is list:
                             included_additional_conditions.extend(x[k])
@@ -720,7 +720,7 @@
             for item in self.vars:
                 if getattr(item, 'items', None) is None:
                     raise errors.AnsibleError("expecting a key-value pair in 'vars' section")
-                k, v = item.items()[0]
+                k, v = list(item.items())[0]
                 vars[k] = v
         else:
             vars.update(self.vars)
@@ -746,7 +746,7 @@
                                   )
 
         elif type(self.vars_prompt) == dict:
-            for (vname, prompt) in self.vars_prompt.iteritems():
+            for (vname, prompt) in self.vars_prompt.items():
                 prompt_msg = "%s: " % prompt
                 if vname not in self.playbook.extra_vars:
                     vars[vname] = self.playbook.callbacks.on_vars_prompt(
@@ -829,7 +829,7 @@
                     role_tags[this_role] = []
 
                 if 'tags' in task['vars']:
-                    if isinstance(task['vars']['tags'], str):
+                    if isinstance(task['vars']['tags'], str):
                         role_tags[this_role] += shlex.split(task['vars']['tags'])
                     else:
                         role_tags[this_role] += task['vars']['tags']
--- ./lib/ansible/playbook/task.py	(original)
+++ ./lib/ansible/playbook/task.py	(refactored)
@@ -66,7 +66,7 @@
         if os.path.exists(library):
             utils.plugins.module_finder.add_directory(library)
 
-        for x in ds.keys():
+        for x in list(ds.keys()):
 
             # code to allow for saying "modulename: args" versus "action: modulename args"
             if x in utils.plugins.module_finder:
@@ -80,14 +80,14 @@
                     ds[x] = ''
                 elif ds[x] is None:
                     ds[x] = ''
-                if not isinstance(ds[x], str):
+                if not isinstance(ds[x], str):
                     raise errors.AnsibleError("action specified for task %s has invalid type %s" % (ds.get('name', "%s: %s" % (x, ds[x])), type(ds[x])))
                 ds['action'] = x + " " + ds[x]
                 ds.pop(x)
 
             # code to allow "with_glob" and to reference a lookup plugin named glob
             elif x.startswith("with_"):
-                if isinstance(ds[x], str):
+                if isinstance(ds[x], str):
                     param = ds[x].strip()
 
                 plugin_name = x.replace("with_","")
@@ -99,7 +99,7 @@
                     raise errors.AnsibleError("cannot find lookup plugin named %s for usage in with_%s" % (plugin_name, plugin_name))
 
             elif x in [ 'changed_when', 'failed_when', 'when']:
-                if isinstance(ds[x], str):
+                if isinstance(ds[x], str):
                     param = ds[x].strip()
                     # Only a variable, no logic
                     if (param.startswith('{{') and
@@ -270,11 +270,11 @@
         self.always_run = ds.get('always_run', False)
 
         # action should be a string
-        if not isinstance(self.action, str):
+        if not isinstance(self.action, str):
             raise errors.AnsibleError("action is of type '%s' and not a string in task. name: %s" % (type(self.action).__name__, self.name))
 
         # notify can be a string or a list, store as a list
-        if isinstance(self.notify, str):
+        if isinstance(self.notify, str):
             self.notify = [ self.notify ]
 
         # split the action line into a module name + arguments
@@ -334,14 +334,14 @@
         import_tags = module_vars.get('tags',[])
         if type(import_tags) in [int,float]:
             import_tags = str(import_tags)
-        elif type(import_tags) in [str,unicode]:
+        elif type(import_tags) in [str,str]:
             # allow the user to list comma delimited tags
             import_tags = import_tags.split(",")
 
         # tags allow certain parts of a playbook to be run without running the whole playbook
         apply_tags = ds.get('tags', None)
         if apply_tags is not None:
-            if type(apply_tags) in [ str, unicode ]:
+            if type(apply_tags) in [ str, str ]:
                 tags.append(apply_tags)
             elif type(apply_tags) in [ int, float ]:
                 tags.append(str(apply_tags))
--- ./lib/ansible/runner/__init__.py	(original)
+++ ./lib/ansible/runner/__init__.py	(refactored)
@@ -49,7 +49,7 @@
 from ansible.module_utils.splitter import split_args, unquote
 from ansible.cache import FactCache
 from ansible.utils import update_hash
-from ansible.utils.unicode import to_bytes
+from ansible.utils.str import to_bytes
 
 module_replacer = ModuleReplacer(strip_comments=False)
 
@@ -279,8 +279,8 @@
             return module_args
         if not isinstance(complex_args, dict):
             raise errors.AnsibleError("complex arguments are not a dictionary: %s" % complex_args)
-        for (k,v) in complex_args.iteritems():
-            if isinstance(v, str):
+        for (k,v) in complex_args.items():
+            if isinstance(v, str):
                 module_args = "%s=%s %s" % (k, pipes.quote(v), module_args)
         return module_args
 
@@ -295,7 +295,7 @@
         afd, afile = tempfile.mkstemp()
         afo = os.fdopen(afd, 'w')
         try:
-            if not isinstance(data, unicode):
+            if not isinstance(data, str):
                 #ensure the data is valid UTF-8
                 data.decode('utf-8')
             else:
@@ -759,7 +759,7 @@
             # first template them if they contain a variable
 
             returned_args = args
-            if isinstance(args, str):
+            if isinstance(args, str):
                 # If the complex_args were evaluated to a dictionary and there are
                 # more keys in the templated version than the evaled version, some
                 # param inserted additional keys (the template() call also runs
@@ -1016,7 +1016,7 @@
 
         # filter omitted arguments out from complex_args
         if complex_args:
-            complex_args = dict(filter(lambda x: x[1] != self.omit_token, complex_args.iteritems()))
+            complex_args = dict([x for x in iter(complex_args.items()) if x[1] != self.omit_token])
 
         # Filter omitted arguments out from module_args.
         # We do this with split_args instead of parse_kv to ensure
@@ -1173,12 +1173,12 @@
                                                           executable=executable,
                                                           in_data=in_data)
 
-            if type(stdout) not in [ str, unicode ]:
+            if type(stdout) not in [ str, str ]:
                 out = ''.join(stdout.readlines())
             else:
                 out = stdout
 
-            if type(stderr) not in [ str, unicode ]:
+            if type(stderr) not in [ str, str ]:
                 err = ''.join(stderr.readlines())
             else:
                 err = stderr
@@ -1489,7 +1489,7 @@
             try:
                 results = self._parallel_exec(hosts)
             except IOError as ie:
-                print(ie.errno)
+                print((ie.errno))
                 if ie.errno == 32:
                     # broken pipe from Ctrl+C
                     raise errors.AnsibleError("interrupted")
--- ./lib/ansible/runner/poller.py	(original)
+++ ./lib/ansible/runner/poller.py	(refactored)
@@ -35,7 +35,7 @@
         # True to work with the `and` below
         skipped = True
         jid = None
-        for (host, res) in results['contacted'].iteritems():
+        for (host, res) in results['contacted'].items():
             if res.get('started', False):
                 self.hosts_to_poll.append(host)
                 jid = res.get('ansible_job_id', None)
@@ -45,7 +45,7 @@
                 skipped = skipped and res.get('skipped', False)
                 self.runner.vars_cache[host]['ansible_job_id'] = ''
                 self.results['contacted'][host] = res
-        for (host, res) in results['dark'].iteritems():
+        for (host, res) in results['dark'].items():
             self.runner.vars_cache[host]['ansible_job_id'] = ''
             self.results['dark'][host] = res
 
@@ -71,7 +71,7 @@
 
         hosts = []
         poll_results = { 'contacted': {}, 'dark': {}, 'polled': {}}
-        for (host, res) in results['contacted'].iteritems():
+        for (host, res) in results['contacted'].items():
             if res.get('started',False):
                 hosts.append(host)
                 poll_results['polled'][host] = res
@@ -82,7 +82,7 @@
                     self.runner.callbacks.on_async_failed(host, res, self.runner.vars_cache[host]['ansible_job_id'])
                 else:
                     self.runner.callbacks.on_async_ok(host, res, self.runner.vars_cache[host]['ansible_job_id'])
-        for (host, res) in results['dark'].iteritems():
+        for (host, res) in results['dark'].items():
             self.results['dark'][host] = res
             poll_results['dark'][host] = res
             if host in self.hosts_to_poll:
@@ -106,7 +106,7 @@
 
             poll_results = self.poll()
 
-            for (host, res) in poll_results['polled'].iteritems():
+            for (host, res) in poll_results['polled'].items():
                 if res.get('started'):
                     self.runner.callbacks.on_async_poll(host, res, self.runner.vars_cache[host]['ansible_job_id'], clock)
 
--- ./lib/ansible/runner/return_data.py	(original)
+++ ./lib/ansible/runner/return_data.py	(refactored)
@@ -42,7 +42,7 @@
         # changes made to particular files
         self.diff = diff
 
-        if type(self.result) in [ str, unicode ]:
+        if type(self.result) in [ str, str ]:
             self.result = utils.parse_json(self.result, from_remote=True, no_exceptions=True)
 
         if self.host is None:
--- ./lib/ansible/runner/action_plugins/add_host.py	(original)
+++ ./lib/ansible/runner/action_plugins/add_host.py	(refactored)
@@ -95,7 +95,7 @@
         new_host.vars = combine_vars(new_host.vars, inventory.get_host_variables(new_name, update_cached=True, vault_password=inventory._vault_password))
 
         # Add any passed variables to the new_host
-        for k in args.keys():
+        for k in list(args.keys()):
             if not k in [ 'name', 'hostname', 'groupname', 'groups' ]:
                 new_host.set_variable(k, args[k])
 
--- ./lib/ansible/runner/action_plugins/copy.py	(original)
+++ ./lib/ansible/runner/action_plugins/copy.py	(refactored)
@@ -31,7 +31,8 @@
 ## fixes https://github.com/ansible/ansible/issues/3518
 # http://mypy.pythonblogs.com/12_mypy/archive/1253_workaround_for_python_bug_ascii_codec_cant_encode_character_uxa0_in_position_111_ordinal_not_in_range128.html
 import sys
-reload(sys)
+import imp
+imp.reload(sys)
 sys.setdefaultencoding("utf8")
 
 
@@ -58,7 +59,7 @@
         # now we need to unescape it so that the newlines are evaluated properly
         # when writing the file to disk
         if content:
-            if isinstance(content, unicode):
+            if isinstance(content, str):
                 try:
                     content = content.decode('unicode-escape')
                 except UnicodeDecodeError:
@@ -89,7 +90,7 @@
                 else:
                     content_tempfile = self._create_content_tempfile(content)
                 source = content_tempfile
-            except Exception, err:
+            except Exception as err:
                 result = dict(failed=True, msg="could not write content temp file: %s" % err)
                 return ReturnData(conn=conn, result=result)
         # if we have first_available_file in our vars
@@ -323,7 +324,7 @@
         f = os.fdopen(fd, 'w')
         try:
             f.write(content)
-        except Exception, err:
+        except Exception as err:
             os.remove(content_tempfile)
             raise Exception(err)
         finally:
--- ./lib/ansible/runner/action_plugins/group_by.py	(original)
+++ ./lib/ansible/runner/action_plugins/group_by.py	(refactored)
@@ -88,7 +88,7 @@
         result['groups'] = groups
 
         ### add to inventory
-        for group, hosts in groups.items():
+        for group, hosts in list(groups.items()):
             inv_group = inventory.get_group(group)
             if not inv_group:
                 inv_group = ansible.inventory.Group(name=group)
--- ./lib/ansible/runner/action_plugins/pause.py	(original)
+++ ./lib/ansible/runner/action_plugins/pause.py	(refactored)
@@ -72,14 +72,14 @@
                     self.pause_type = 'seconds'
                     self.seconds = int(args['seconds'])
                     self.duration_unit = 'seconds'
-            except ValueError, e:
+            except ValueError as e:
                 raise ae("non-integer value given for prompt duration:\n%s" % str(e))
         # Is 'prompt' a key in 'args'?
         elif 'prompt' in args:
             self.pause_type = 'prompt'
             self.prompt = "[%s]\n%s:\n" % (hosts, args['prompt'])
         # Is 'args' empty, then this is the default prompted pause
-        elif len(args.keys()) == 0:
+        elif len(list(args.keys())) == 0:
             self.pause_type = 'prompt'
             self.prompt = "[%s]\nPress enter to continue:\n" % hosts
         # I have no idea what you're trying to do. But it's so wrong.
@@ -95,16 +95,16 @@
         try:
             self._start()
             if not self.pause_type == 'prompt':
-                print "[%s]\nPausing for %s seconds" % (hosts, self.seconds)
+                print("[%s]\nPausing for %s seconds" % (hosts, self.seconds))
                 time.sleep(self.seconds)
             else:
                 # Clear out any unflushed buffered input which would
                 # otherwise be consumed by raw_input() prematurely.
                 tcflush(sys.stdin, TCIFLUSH)
-                self.result['user_input'] = raw_input(self.prompt.encode(sys.stdout.encoding))
+                self.result['user_input'] = input(self.prompt.encode(sys.stdout.encoding))
         except KeyboardInterrupt:
             while True:
-                print '\nAction? (a)bort/(c)ontinue: '
+                print('\nAction? (a)bort/(c)ontinue: ')
                 c = getch()
                 if c == 'c':
                     # continue playbook evaluation
@@ -122,7 +122,7 @@
         self.start = time.time()
         self.result['start'] = str(datetime.datetime.now())
         if not self.pause_type == 'prompt':
-            print "(^C-c = continue early, ^C-a = abort)"
+            print("(^C-c = continue early, ^C-a = abort)")
 
     def _stop(self):
         ''' calculate the duration we actually paused for and then
--- ./lib/ansible/runner/action_plugins/set_fact.py	(original)
+++ ./lib/ansible/runner/action_plugins/set_fact.py	(refactored)
@@ -36,9 +36,9 @@
         # parse the k=v arguments and convert any special boolean
         # strings into proper booleans (issue #8629)
         parsed_args = utils.parse_kv(module_args)
-        for k,v in parsed_args.iteritems():
+        for k,v in parsed_args.items():
             # convert certain strings to boolean values
-            if isinstance(v, str) and v.lower() in ('true', 'false', 'yes', 'no'):
+            if isinstance(v, str) and v.lower() in ('true', 'false', 'yes', 'no'):
                 parsed_args[k] = utils.boolean(v)
 
         # and finally update the options with the parsed/modified args
--- ./lib/ansible/runner/action_plugins/template.py	(original)
+++ ./lib/ansible/runner/action_plugins/template.py	(refactored)
@@ -97,7 +97,7 @@
         # template the source data locally & get ready to transfer
         try:
             resultant = template.template_from_file(self.runner.basedir, source, inject, vault_password=self.runner.vault_pass)
-        except Exception, e:
+        except Exception as e:
             result = dict(failed=True, msg=type(e).__name__ + ": " + str(e))
             return ReturnData(conn=conn, comm_ok=False, result=result)
 
--- ./lib/ansible/runner/action_plugins/unarchive.py	(original)
+++ ./lib/ansible/runner/action_plugins/unarchive.py	(refactored)
@@ -26,7 +26,8 @@
 ## fixes https://github.com/ansible/ansible/issues/3518
 # http://mypy.pythonblogs.com/12_mypy/archive/1253_workaround_for_python_bug_ascii_codec_cant_encode_character_uxa0_in_position_111_ordinal_not_in_range128.html
 import sys
-reload(sys)
+import imp
+imp.reload(sys)
 sys.setdefaultencoding("utf8")
 import pipes
 
--- ./lib/ansible/runner/action_plugins/win_copy.py	(original)
+++ ./lib/ansible/runner/action_plugins/win_copy.py	(refactored)
@@ -31,7 +31,8 @@
 ## fixes https://github.com/ansible/ansible/issues/3518
 # http://mypy.pythonblogs.com/12_mypy/archive/1253_workaround_for_python_bug_ascii_codec_cant_encode_character_uxa0_in_position_111_ordinal_not_in_range128.html
 import sys
-reload(sys)
+import imp
+imp.reload(sys)
 sys.setdefaultencoding("utf8")
 
 
@@ -58,7 +59,7 @@
         # now we need to unescape it so that the newlines are evaluated properly
         # when writing the file to disk
         if content:
-            if isinstance(content, unicode):
+            if isinstance(content, str):
                 try:
                     content = content.decode('unicode-escape')
                 except UnicodeDecodeError:
@@ -89,7 +90,7 @@
                 else:
                     content_tempfile = self._create_content_tempfile(content)
                 source = content_tempfile
-            except Exception, err:
+            except Exception as err:
                 result = dict(failed=True, msg="could not write content temp file: %s" % err)
                 return ReturnData(conn=conn, result=result)
         # if we have first_available_file in our vars
@@ -319,7 +320,7 @@
         f = os.fdopen(fd, 'w')
         try:
             f.write(content)
-        except Exception, err:
+        except Exception as err:
             os.remove(content_tempfile)
             raise Exception(err)
         finally:
--- ./lib/ansible/runner/action_plugins/win_template.py	(original)
+++ ./lib/ansible/runner/action_plugins/win_template.py	(refactored)
@@ -82,7 +82,7 @@
         # template the source data locally & get ready to transfer
         try:
             resultant = template.template_from_file(self.runner.basedir, source, inject, vault_password=self.runner.vault_pass)
-        except Exception, e:
+        except Exception as e:
             result = dict(failed=True, msg=type(e).__name__ + ": " + str(e))
             return ReturnData(conn=conn, comm_ok=False, result=result)
 
--- ./lib/ansible/runner/connection_plugins/chroot.py	(original)
+++ ./lib/ansible/runner/connection_plugins/chroot.py	(refactored)
@@ -26,7 +26,7 @@
 import subprocess
 from ansible import errors
 from ansible import utils
-from ansible.utils.unicode import to_bytes
+from ansible.utils.str import to_bytes
 from ansible.callbacks import vvv
 import ansible.constants as C
 
--- ./lib/ansible/runner/connection_plugins/jail.py	(original)
+++ ./lib/ansible/runner/connection_plugins/jail.py	(refactored)
@@ -26,7 +26,7 @@
 import shlex
 import subprocess
 from ansible import errors
-from ansible.utils.unicode import to_bytes
+from ansible.utils.str import to_bytes
 from ansible.callbacks import vvv
 import ansible.constants as C
 
--- ./lib/ansible/runner/connection_plugins/libvirt_lxc.py	(original)
+++ ./lib/ansible/runner/connection_plugins/libvirt_lxc.py	(refactored)
@@ -80,7 +80,7 @@
         local_cmd = self._generate_cmd(executable, cmd)
 
         vvv("EXEC %s" % (local_cmd), host=self.lxc)
-        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, str),
+        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, str),
                              cwd=self.runner.basedir,
                              stdin=subprocess.PIPE,
                              stdout=subprocess.PIPE, stderr=subprocess.PIPE)
--- ./lib/ansible/runner/connection_plugins/local.py	(original)
+++ ./lib/ansible/runner/connection_plugins/local.py	(refactored)
@@ -65,7 +65,7 @@
         executable = executable.split()[0] if executable else None
 
         vvv("EXEC %s" % (local_cmd), host=self.host)
-        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, str),
+        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, str),
                              cwd=self.runner.basedir, executable=executable,
                              stdin=subprocess.PIPE,
                              stdout=subprocess.PIPE, stderr=subprocess.PIPE)
--- ./lib/ansible/runner/connection_plugins/paramiko_ssh.py	(original)
+++ ./lib/ansible/runner/connection_plugins/paramiko_ssh.py	(refactored)
@@ -85,7 +85,7 @@
             # clear out any premature input on sys.stdin
             tcflush(sys.stdin, TCIFLUSH)
 
-            inp = raw_input(AUTHENTICITY_MSG % (hostname, ktype, fingerprint))
+            inp = input(AUTHENTICITY_MSG % (hostname, ktype, fingerprint))
             sys.stdin = old_stdin
             if inp not in ['yes','y','']:
                 fcntl.flock(self.runner.output_lockfile, fcntl.LOCK_UN)
@@ -173,7 +173,7 @@
                 key_filename=key_filename, password=self.password,
                 timeout=self.runner.timeout, port=self.port)
 
-        except Exception, e:
+        except Exception as e:
 
             msg = str(e)
             if "PID check failed" in msg:
@@ -203,7 +203,7 @@
             self.ssh.get_transport().set_keepalive(5)
             chan = self.ssh.get_transport().open_session()
 
-        except Exception, e:
+        except Exception as e:
 
             msg = "Failed to open session"
             if len(str(e)) > 0:
@@ -286,7 +286,7 @@
 
         try:
             self.sftp = self.ssh.open_sftp()
-        except Exception, e:
+        except Exception as e:
             raise errors.AnsibleError("failed to open a SFTP connection (%s)" % e)
 
         try:
@@ -310,7 +310,7 @@
 
         try:
             self.sftp = self._connect_sftp()
-        except Exception, e:
+        except Exception as e:
             raise errors.AnsibleError("failed to open a SFTP connection (%s)", e)
 
         try:
@@ -321,8 +321,8 @@
     def _any_keys_added(self):
 
         added_any = False
-        for hostname, keys in self.ssh._host_keys.iteritems():
-            for keytype, key in keys.iteritems():
+        for hostname, keys in self.ssh._host_keys.items():
+            for keytype, key in keys.items():
                 added_this_time = getattr(key, '_added_by_ansible_this_time', False)
                 if added_this_time:
                     return True
@@ -343,18 +343,18 @@
 
         f = open(filename, 'w')
 
-        for hostname, keys in self.ssh._host_keys.iteritems():
-
-            for keytype, key in keys.iteritems():
+        for hostname, keys in self.ssh._host_keys.items():
+
+            for keytype, key in keys.items():
 
                 # was f.write
                 added_this_time = getattr(key, '_added_by_ansible_this_time', False)
                 if not added_this_time:
                     f.write("%s %s %s\n" % (hostname, keytype, key.get_base64()))
 
-        for hostname, keys in self.ssh._host_keys.iteritems():
-
-            for keytype, key in keys.iteritems():
+        for hostname, keys in self.ssh._host_keys.items():
+
+            for keytype, key in keys.items():
                 added_this_time = getattr(key, '_added_by_ansible_this_time', False)
                 if added_this_time:
                     f.write("%s %s %s\n" % (hostname, keytype, key.get_base64()))
@@ -399,7 +399,7 @@
                 # the file will be moved into place rather than cleaned up.
 
                 tmp_keyfile = tempfile.NamedTemporaryFile(dir=key_dir, delete=False)
-                os.chmod(tmp_keyfile.name, key_stat.st_mode & 07777)
+                os.chmod(tmp_keyfile.name, key_stat.st_mode & 0o7777)
                 os.chown(tmp_keyfile.name, key_stat.st_uid, key_stat.st_gid)
 
                 self._save_ssh_host_keys(tmp_keyfile.name)
--- ./lib/ansible/runner/connection_plugins/ssh.py	(original)
+++ ./lib/ansible/runner/connection_plugins/ssh.py	(refactored)
@@ -53,7 +53,7 @@
         self.become_methods_supported=['sudo', 'su', 'pbrun']
 
         fcntl.lockf(self.runner.process_lockfile, fcntl.LOCK_EX)
-        self.cp_dir = utils.prepare_writeable_dir('$HOME/.ansible/cp',mode=0700)
+        self.cp_dir = utils.prepare_writeable_dir('$HOME/.ansible/cp',mode=0o700)
         fcntl.lockf(self.runner.process_lockfile, fcntl.LOCK_UN)
 
     def connect(self):
@@ -222,7 +222,7 @@
                 continue
             try:
                 host_fh = open(hf)
-            except IOError, e:
+            except IOError as e:
                 hfiles_not_found += 1
                 continue
             else:
--- ./lib/ansible/runner/connection_plugins/winrm.py	(original)
+++ ./lib/ansible/runner/connection_plugins/winrm.py	(refactored)
@@ -15,14 +15,14 @@
 # You should have received a copy of the GNU General Public License
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
-from __future__ import absolute_import
+
 
 import base64
 import os
 import re
 import shlex
 import traceback
-import urlparse
+import urllib.parse
 from ansible import errors
 from ansible import utils
 from ansible.callbacks import vvv, vvvv, verbose
@@ -86,7 +86,7 @@
                 realm = self.user.split('@', 1)[1].strip() or None
             else:
                 realm = None
-            endpoint = urlparse.urlunsplit((scheme, netloc, '/wsman', '', ''))
+            endpoint = urllib.parse.urlunsplit((scheme, netloc, '/wsman', '', ''))
             vvvv('WINRM CONNECT: transport=%s endpoint=%s' % (transport, endpoint),
                  host=self.host)
             protocol = Protocol(endpoint, transport=transport,
@@ -95,7 +95,7 @@
             try:
                 protocol.send_message('')
                 return protocol
-            except WinRMTransportError, exc:
+            except WinRMTransportError as exc:
                 err_msg = str(exc)
                 if re.search(r'Operation\s+?timed\s+?out', err_msg, re.I):
                     raise errors.AnsibleError("the connection attempt timed out")
@@ -159,7 +159,7 @@
             cmd_parts = powershell._encode_script(script, as_list=True)
         try:
             result = self._winrm_exec(cmd_parts[0], cmd_parts[1:], from_exec=True)
-        except Exception, e:
+        except Exception as e:
             traceback.print_exc()
             raise errors.AnsibleError("failed to exec cmd %s" % cmd)
         return (result.status_code, '', result.std_out.encode('utf-8'), result.std_err.encode('utf-8'))
@@ -185,7 +185,7 @@
             # windows command length), divide by 2.67 (UTF16LE base64 command
             # encoding), then by 1.35 again (data base64 encoding).
             buffer_size = int(((8190 - len(cmd)) / 2.67) / 1.35)
-            for offset in xrange(0, in_size, buffer_size):
+            for offset in range(0, in_size, buffer_size):
                 try:
                     out_data = in_file.read(buffer_size)
                     if offset == 0:
--- ./lib/ansible/runner/connection_plugins/zone.py	(original)
+++ ./lib/ansible/runner/connection_plugins/zone.py	(refactored)
@@ -27,7 +27,7 @@
 import shlex
 import subprocess
 from ansible import errors
-from ansible.utils.unicode import to_bytes
+from ansible.utils.str import to_bytes
 from ansible.callbacks import vvv
 import ansible.constants as C
 
--- ./lib/ansible/runner/filter_plugins/core.py	(original)
+++ ./lib/ansible/runner/filter_plugins/core.py	(refactored)
@@ -15,7 +15,7 @@
 # You should have received a copy of the GNU General Public License
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
-from __future__ import absolute_import
+
 
 import sys
 import base64
@@ -39,7 +39,7 @@
 
 from ansible import errors
 from ansible.utils.hashing import md5s, checksum_s
-from ansible.utils.unicode import unicode_wrap, to_unicode
+from ansible.utils.str import unicode_wrap, to_unicode
 
 
 UUID_NAMESPACE_ANSIBLE = uuid.UUID('361E6D51-FAEC-444A-9079-341386DA8E2E')
@@ -127,7 +127,7 @@
     ''' return a bool for the arg '''
     if a is None or type(a) == bool:
         return a
-    if type(a) in types.StringTypes:
+    if type(a) in str:
         a = a.lower()
     if a in ['yes', 'on', '1', 'true', 1]:
         return True
@@ -166,7 +166,7 @@
 def regex_replace(value='', pattern='', replacement='', ignorecase=False):
     ''' Perform a `re.sub` returning a string '''
 
-    if not isinstance(value, str):
+    if not isinstance(value, str):
         value = str(value)
 
     if ignorecase:
@@ -208,13 +208,13 @@
     try:
         method = getattr(py_operator, operator)
         return method(Version(str(value)), Version(str(version)))
-    except Exception, e:
+    except Exception as e:
         raise errors.AnsibleFilterError('Version comparison: %s' % e)
 
 @environmentfilter
 def rand(environment, end, start=None, step=None):
     r = SystemRandom()
-    if isinstance(end, (int, long)):
+    if isinstance(end, int):
         if not start:
             start = 0
         if not step:
--- ./lib/ansible/runner/filter_plugins/mathstuff.py	(original)
+++ ./lib/ansible/runner/filter_plugins/mathstuff.py	(refactored)
@@ -15,7 +15,7 @@
 # You should have received a copy of the GNU General Public License
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
-from __future__ import absolute_import
+
 
 import math
 import collections
@@ -35,21 +35,21 @@
     if isinstance(a,collections.Hashable) and isinstance(b,collections.Hashable):
         c = set(a) & set(b)
     else:
-        c = unique(filter(lambda x: x in b, a))
+        c = unique([x for x in a if x in b])
     return c
 
 def difference(a, b):
     if isinstance(a,collections.Hashable) and isinstance(b,collections.Hashable):
         c = set(a) - set(b)
     else:
-        c = unique(filter(lambda x: x not in b, a))
+        c = unique([x for x in a if x not in b])
     return c
 
 def symmetric_difference(a, b):
     if isinstance(a,collections.Hashable) and isinstance(b,collections.Hashable):
         c = set(a) ^ set(b)
     else:
-        c = unique(filter(lambda x: x not in intersect(a,b), union(a,b)))
+        c = unique([x for x in union(a,b) if x not in intersect(a,b)])
     return c
 
 def union(a, b):
@@ -80,14 +80,14 @@
             return math.log10(x)
         else:
             return math.log(x, base)
-    except TypeError, e:
+    except TypeError as e:
         raise errors.AnsibleFilterError('log() can only be used on numbers: %s' % str(e))
 
 
 def power(x, y):
     try:
         return math.pow(x, y)
-    except TypeError, e:
+    except TypeError as e:
         raise errors.AnsibleFilterError('pow() can only be used on numbers: %s' % str(e))
 
 
@@ -97,7 +97,7 @@
             return math.sqrt(x)
         else:
             return math.pow(x, 1.0/float(base))
-    except TypeError, e:
+    except TypeError as e:
         raise errors.AnsibleFilterError('root() can only be used on numbers: %s' % str(e))
 
 
--- ./lib/ansible/runner/lookup_plugins/consul_kv.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/consul_kv.py	(refactored)
@@ -53,7 +53,7 @@
 
 import os
 import sys
-from urlparse import urlparse
+from urllib.parse import urlparse
 from ansible import utils, errors
 
 try:
@@ -63,9 +63,9 @@
 
 try:
     import consul
-except ImportError, e:
-    print "failed=True msg='python-consul required for this module. "\
-          "see http://python-consul.readthedocs.org/en/latest/#installation'"
+except ImportError as e:
+    print("failed=True msg='python-consul required for this module. "\
+          "see http://python-consul.readthedocs.org/en/latest/#installation'")
     sys.exit(1)
 
 
@@ -99,7 +99,7 @@
                             values.append(r['Value'])
                     else:
                         values.append(results[1]['Value'])
-        except Exception, e:
+        except Exception as e:
             raise errors.AnsibleError(
                 "Error locating '%s' in kv store. Error was %s" % (term, e))
 
@@ -122,7 +122,7 @@
                     name, value = param.split('=')
                     assert name in paramvals, "% not a valid consul lookup parameter" % name
                     paramvals[name] = value
-        except (ValueError, AssertionError), e:
+        except (ValueError, AssertionError) as e:
             raise errors.AnsibleError(e)
 
         return paramvals
--- ./lib/ansible/runner/lookup_plugins/csvfile.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/csvfile.py	(refactored)
@@ -34,7 +34,7 @@
             for row in creader:
                 if row[0] == key:
                     return row[int(col)]
-        except Exception, e:
+        except Exception as e:
             raise errors.AnsibleError("csvfile: %s" % str(e))
 
         return dflt
@@ -43,7 +43,7 @@
 
         terms = utils.listify_lookup_plugin_terms(terms, self.basedir, inject)
 
-        if isinstance(terms, str):
+        if isinstance(terms, str):
             terms = [ terms ]
 
         ret = []
@@ -64,7 +64,7 @@
                     name, value = param.split('=')
                     assert(name in paramvals)
                     paramvals[name] = value
-            except (ValueError, AssertionError), e:
+            except (ValueError, AssertionError) as e:
                 raise errors.AnsibleError(e)
 
             if paramvals['delimiter'] == 'TAB':
--- ./lib/ansible/runner/lookup_plugins/dig.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/dig.py	(refactored)
@@ -142,7 +142,7 @@
                         try:
                             nsaddr = dns.resolver.query(ns)[0].address
                             nameservers.append(nsaddr)
-                        except Exception, e:
+                        except Exception as e:
                             raise errors.AnsibleError("dns lookup NS: ", str(e))
                     myres.nameservers = nameservers
                 continue
@@ -177,7 +177,7 @@
                 domain = n.to_text()
             except dns.exception.SyntaxError:
                 pass
-            except Exception, e:
+            except Exception as e:
                 raise errors.AnsibleError("dns.reversename unhandled exception", str(e))
 
         try:
@@ -197,7 +197,7 @@
                         rd['ttl']       = answers.rrset.ttl
 
                         ret.append(rd)
-                    except Exception, e:
+                    except Exception as e:
                         ret.append(str(e))
 
         except dns.resolver.NXDOMAIN:
@@ -206,7 +206,7 @@
             ret.append("")
         except dns.resolver.Timeout:
             ret.append('')
-        except dns.exception.DNSException, e:
+        except dns.exception.DNSException as e:
             raise errors.AnsibleError("dns.resolver unhandled exception", e)
 
         return ret
--- ./lib/ansible/runner/lookup_plugins/dnstxt.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/dnstxt.py	(refactored)
@@ -44,7 +44,7 @@
 
         terms = utils.listify_lookup_plugin_terms(terms, self.basedir, inject) 
 
-        if isinstance(terms, str):
+        if isinstance(terms, str):
             terms = [ terms ]
 
         ret = []
@@ -61,7 +61,7 @@
                 string = 'NXDOMAIN'
             except dns.resolver.Timeout:
                 string = ''
-            except dns.exception.DNSException, e:
+            except dns.exception.DNSException as e:
                 raise errors.AnsibleError("dns.resolver unhandled exception", e)
 
             ret.append(''.join(string))
--- ./lib/ansible/runner/lookup_plugins/env.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/env.py	(refactored)
@@ -28,10 +28,10 @@
 
         try:
             terms = template.template(self.basedir, terms, inject)
-        except Exception, e:
+        except Exception as e:
             pass
 
-        if isinstance(terms, str):
+        if isinstance(terms, str):
             terms = [ terms ]
 
         ret = []
--- ./lib/ansible/runner/lookup_plugins/etcd.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/etcd.py	(refactored)
@@ -69,7 +69,7 @@
 
         terms = utils.listify_lookup_plugin_terms(terms, self.basedir, inject)
 
-        if isinstance(terms, str):
+        if isinstance(terms, str):
             terms = [ terms ]
 
         validate_certs = kwargs.get('validate_certs', True)
--- ./lib/ansible/runner/lookup_plugins/first_found.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/first_found.py	(refactored)
@@ -147,14 +147,14 @@
                     skip  = utils.boolean(term.get('skip', False))
 
                     filelist = files
-                    if isinstance(files, str):
+                    if isinstance(files, str):
                         files = files.replace(',', ' ')
                         files = files.replace(';', ' ')
                         filelist = files.split(' ')
 
                     pathlist = paths
                     if paths:
-                        if isinstance(paths, str):
+                        if isinstance(paths, str):
                             paths = paths.replace(',', ' ')
                             paths = paths.replace(':', ' ')
                             paths = paths.replace(';', ' ')
--- ./lib/ansible/runner/lookup_plugins/flattened.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/flattened.py	(refactored)
@@ -48,7 +48,7 @@
                 # ignore undefined items
                 break
 
-            if isinstance(term, str):
+            if isinstance(term, str):
                 # convert a variable to a list
                 term2 = utils.listify_lookup_plugin_terms(term, self.basedir, inject)
                 # but avoid converting a plain string to a list of one string
--- ./lib/ansible/runner/lookup_plugins/indexed_items.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/indexed_items.py	(refactored)
@@ -40,5 +40,5 @@
             raise errors.AnsibleError("with_indexed_items expects a list")
 
         items = flatten(terms)
-        return zip(range(len(items)), items)
+        return list(zip(list(range(len(items))), items))
 
--- ./lib/ansible/runner/lookup_plugins/password.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/password.py	(refactored)
@@ -68,7 +68,7 @@
                         paramvals['chars'] = use_chars
                     else:
                         paramvals[name] = value
-            except (ValueError, AssertionError), e:
+            except (ValueError, AssertionError) as e:
                 raise errors.AnsibleError(e)
 
             length  = paramvals['length']
@@ -81,8 +81,8 @@
                 pathdir = os.path.dirname(path)
                 if not os.path.isdir(pathdir):
                     try:
-                        os.makedirs(pathdir, mode=0700)
-                    except OSError, e:
+                        os.makedirs(pathdir, mode=0o700)
+                    except OSError as e:
                         raise errors.AnsibleError("cannot create the path for the password lookup: %s (error was %s)" % (pathdir, str(e)))
 
                 chars = "".join([getattr(string,c,c) for c in use_chars]).replace('"','').replace("'",'')
@@ -94,7 +94,7 @@
                 else:
                     content = password
                 with open(path, 'w') as f:
-                    os.chmod(path, 0600)
+                    os.chmod(path, 0o600)
                     f.write(content + '\n')
             else:
                 content = open(path).read().rstrip()
@@ -112,12 +112,12 @@
                     salt = self.random_salt()
                     content = '%s salt=%s' % (password, salt)
                     with open(path, 'w') as f:
-                        os.chmod(path, 0600)
+                        os.chmod(path, 0o600)
                         f.write(content + '\n')
                 # crypt not requested, remove salt if present
                 elif (encrypt is None and salt):
                     with open(path, 'w') as f:
-                        os.chmod(path, 0600)
+                        os.chmod(path, 0o600)
                         f.write(password + '\n')
 
             if encrypt:
--- ./lib/ansible/runner/lookup_plugins/pipe.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/pipe.py	(refactored)
@@ -27,7 +27,7 @@
 
         terms = utils.listify_lookup_plugin_terms(terms, self.basedir, inject) 
 
-        if isinstance(terms, str):
+        if isinstance(terms, str):
             terms = [ terms ] 
 
         ret = []
--- ./lib/ansible/runner/lookup_plugins/sequence.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/sequence.py	(refactored)
@@ -104,7 +104,7 @@
         if args:
             raise AnsibleError(
                 "unrecognized arguments to with_sequence: %r"
-                % args.keys()
+                % list(args.keys())
             )
 
     def parse_simple_args(self, term):
@@ -170,7 +170,7 @@
             adjust = 1
         else:
             adjust = -1
-        numbers = xrange(self.start, self.end + adjust, self.stride)
+        numbers = range(self.start, self.end + adjust, self.stride)
 
         for i in numbers:
             try:
@@ -186,7 +186,7 @@
 
         terms = utils.listify_lookup_plugin_terms(terms, self.basedir, inject)
 
-        if isinstance(terms, str):
+        if isinstance(terms, str):
             terms = [ terms ]
 
         for term in terms:
@@ -207,7 +207,7 @@
                     results.extend(self.generate_sequence())
             except AnsibleError:
                 raise
-            except Exception, e:
+            except Exception as e:
                 raise AnsibleError(
                     "unknown error generating sequence: %s" % str(e)
                 )
--- ./lib/ansible/runner/lookup_plugins/subelements.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/subelements.py	(refactored)
@@ -33,7 +33,7 @@
             raise errors.AnsibleError(
                 "subelements lookup expects a list of two items, first a dict or a list, and second a string")
         terms[0] = utils.listify_lookup_plugin_terms(terms[0], self.basedir, inject)
-        if not isinstance(terms[0], (list, dict)) or not isinstance(terms[1], str):
+        if not isinstance(terms[0], (list, dict)) or not isinstance(terms[1], str):
             raise errors.AnsibleError(
                 "subelements lookup expects a list of two items, first a dict or a list, and second a string")
 
@@ -42,7 +42,7 @@
                 # the registered result was completely skipped
                 return []
             elementlist = []
-            for key in terms[0].iterkeys():
+            for key in terms[0].keys():
                 elementlist.append(terms[0][key])
         else: 
             elementlist = terms[0]
--- ./lib/ansible/runner/lookup_plugins/together.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/together.py	(refactored)
@@ -18,7 +18,7 @@
 import ansible.utils as utils
 from ansible.utils import safe_eval
 import ansible.errors as errors
-from itertools import izip_longest
+from itertools import zip_longest
 
 def flatten(terms):
     ret = []
@@ -59,6 +59,6 @@
         my_list = terms[:]
         if len(my_list) == 0:
             raise errors.AnsibleError("with_together requires at least one element in each list")
-        return [flatten(x) for x in izip_longest(*my_list, fillvalue=None)]
+        return [flatten(x) for x in zip_longest(*my_list, fillvalue=None)]
 
 
--- ./lib/ansible/runner/lookup_plugins/url.py	(original)
+++ ./lib/ansible/runner/lookup_plugins/url.py	(refactored)
@@ -16,10 +16,10 @@
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
 from ansible import utils
-import urllib2
+import urllib.request, urllib.error, urllib.parse
 
 from ansible.module_utils.urls import open_url, ConnectionError, SSLValidationError
-from ansible.utils.unicode import to_unicode
+from ansible.utils.str import to_unicode
 
 class LookupModule(object):
 
@@ -30,7 +30,7 @@
 
         terms = utils.listify_lookup_plugin_terms(terms, self.basedir, inject)
 
-        if isinstance(terms, str):
+        if isinstance(terms, str):
             terms = [ terms ]
 
         validate_certs = kwargs.get('validate_certs', True)
@@ -39,10 +39,10 @@
         for term in terms:
             try:
                 response = open_url(term, validate_certs=validate_certs)
-            except urllib2.URLError as e:
+            except urllib.error.URLError as e:
                 utils.warning("Failed lookup url for %s : %s" % (term, str(e)))
                 continue
-            except urllib2.HTTPError as e:
+            except urllib.error.HTTPError as e:
                 utils.warning("Received HTTP error for %s : %s" % (term, str(e)))
                 continue
             except SSLValidationError as e:
--- ./lib/ansible/runner/shell_plugins/sh.py	(original)
+++ ./lib/ansible/runner/shell_plugins/sh.py	(refactored)
@@ -34,7 +34,7 @@
             LC_CTYPE = C.DEFAULT_MODULE_LANG,
         )
         env.update(kwargs)
-        return ' '.join(['%s=%s' % (k, pipes.quote(unicode(v))) for k,v in env.items()])
+        return ' '.join(['%s=%s' % (k, pipes.quote(str(v))) for k,v in list(env.items())])
 
     def join_path(self, *args):
         return os.path.join(*args)
--- ./lib/ansible/utils/__init__.py	(original)
+++ ./lib/ansible/utils/__init__.py	(refactored)
@@ -35,7 +35,7 @@
 #from ansible.callbacks import display
 from ansible.module_utils.splitter import split_args, unquote
 from ansible.module_utils.basic import heuristic_log_sanitize
-from ansible.utils.unicode import to_bytes, to_unicode
+from ansible.utils.str import to_bytes, to_unicode
 import ansible.constants as C
 import ast
 import time
@@ -198,7 +198,7 @@
 def err(msg):
     ''' print an error message to stderr '''
 
-    print >> sys.stderr, msg
+    print(msg, file=sys.stderr)
 
 def exit(msg, rc=1):
     ''' quit with an error to stdout and a failure code '''
@@ -212,7 +212,7 @@
     if result is None:
         return "{}"
     result2 = result.copy()
-    for key, value in result2.items():
+    for key, value in list(result2.items()):
         if type(value) is str:
             result2[key] = value.decode('utf-8', 'ignore')
 
@@ -257,7 +257,7 @@
                 return False
         return True
 
-    if not isinstance(conditional, str):
+    if not isinstance(conditional, str):
         return conditional
 
     conditional = conditional.replace("jinja2_compare ","")
@@ -317,7 +317,7 @@
     if not os.path.exists(tree):
         try:
             os.makedirs(tree, mode)
-        except (IOError, OSError)as e:
+        except (IOError, OSError) as e:
             raise errors.AnsibleError("Could not make dir %s: %s" % (tree, e))
     if not os.access(tree, os.W_OK):
         raise errors.AnsibleError("Cannot write to path %s" % tree)
@@ -465,7 +465,7 @@
 def _clean_data(orig_data, from_remote=False, from_inventory=False):
     ''' remove jinja2 template tags from a string '''
 
-    if not isinstance(orig_data, str):
+    if not isinstance(orig_data, str):
         return orig_data
 
     # when the data is marked as having come from a remote, we always
@@ -530,7 +530,7 @@
         data = orig_data[:]
         for i in range(0, len(data)):
             data[i] = _clean_data_struct(data[i], from_remote, from_inventory)
-    elif isinstance(orig_data, str):
+    elif isinstance(orig_data, str):
         data = _clean_data(orig_data, from_remote, from_inventory)
     else:
         data = orig_data
@@ -562,8 +562,8 @@
     Flattens a dictionary args to a k=v string
     '''
     module_args = ""
-    for (k,v) in args.iteritems():
-        if isinstance(v, str):
+    for (k,v) in args.items():
+        if isinstance(v, str):
             module_args = "%s=%s %s" % (k, pipes.quote(v), module_args)
         elif isinstance(v, bool):
             module_args = "%s=%s %s" % (k, str(v), module_args)
@@ -574,13 +574,13 @@
     merges either a dictionary or string of k=v pairs with another string of k=v pairs,
     and returns a new k=v string without duplicates.
     '''
-    if not isinstance(current_args, str):
+    if not isinstance(current_args, str):
         raise errors.AnsibleError("expected current_args to be a str")
     # we use parse_kv to split up the current args into a dictionary
     final_args = parse_kv(current_args)
     if isinstance(new_args, dict):
         final_args.update(new_args)
-    elif isinstance(new_args, str):
+    elif isinstance(new_args, str):
         new_args_kv = parse_kv(new_args)
         final_args.update(new_args_kv)
     return serialize_args(final_args)
@@ -817,7 +817,7 @@
 
     for dicts in a, b:
         # next, iterate over b keys and values
-        for k, v in dicts.iteritems():
+        for k, v in dicts.items():
             # if there's already such key in a
             # and that key contains dict
             if k in result and isinstance(result[k], dict):
@@ -1078,10 +1078,10 @@
     extra_vars = {}
     for extra_vars_opt in extra_vars_opts:
         extra_vars_opt = to_unicode(extra_vars_opt)
-        if extra_vars_opt.startswith(u"@"):
+        if extra_vars_opt.startswith("@"):
             # Argument is a YAML file (JSON is a subset of YAML)
             extra_vars = combine_vars(extra_vars, parse_yaml_from_file(extra_vars_opt[1:], vault_password=vault_pass))
-        elif extra_vars_opt and extra_vars_opt[0] in u'[{':
+        elif extra_vars_opt and extra_vars_opt[0] in '[{':
             # Arguments as YAML
             extra_vars = combine_vars(extra_vars, parse_yaml(extra_vars_opt))
         else:
@@ -1228,7 +1228,7 @@
     helper function for connection plugins to create privilege escalation commands
     """
 
-    randbits = ''.join(chr(random.randint(ord('a'), ord('z'))) for x in xrange(32))
+    randbits = ''.join(chr(random.randint(ord('a'), ord('z'))) for x in range(32))
     success_key = 'BECOME-SUCCESS-%s' % randbits
     prompt = None
     becomecmd = None
@@ -1310,13 +1310,13 @@
                 differ = difflib.unified_diff(to_unicode(diff['before']).splitlines(True), to_unicode(diff['after']).splitlines(True), before_header, after_header, '', '', 10)
                 for line in list(differ):
                     ret.append(line)
-            return u"".join(ret)
+            return "".join(ret)
     except UnicodeDecodeError:
         return ">> the files are different, but the diff library cannot compare unicode strings"
 
 def is_list_of_strings(items):
     for x in items:
-        if not isinstance(x, str):
+        if not isinstance(x, str):
             return False
     return True
 
@@ -1403,7 +1403,7 @@
 
     filter_list = []
     for filter in filter_loader.all():
-        filter_list.extend(filter.filters().keys())
+        filter_list.extend(list(filter.filters().keys()))
 
     CALL_WHITELIST = C.DEFAULT_CALLABLE_WHITELIST + filter_list
 
@@ -1420,7 +1420,7 @@
             for child_node in ast.iter_child_nodes(node):
                 self.generic_visit(child_node, inside_call)
 
-    if not isinstance(expr, str):
+    if not isinstance(expr, str):
         # already templated to a datastructure, perhaps?
         if include_exceptions:
             return (expr, None)
@@ -1453,7 +1453,7 @@
 
     from ansible.utils import template
 
-    if isinstance(terms, str):
+    if isinstance(terms, str):
         # someone did:
         #    with_items: alist
         # OR
@@ -1468,7 +1468,7 @@
             # not sure why the "/" is in above code :)
             try:
                 new_terms = template.template(basedir, "{{ %s }}" % terms, inject)
-                if isinstance(new_terms, str) and "{{" in new_terms:
+                if isinstance(new_terms, str) and "{{" in new_terms:
                     pass
                 else:
                     terms = new_terms
@@ -1481,7 +1481,7 @@
             # TODO: something a bit less heavy than eval
             return safe_eval(terms)
 
-        if isinstance(terms, str):
+        if isinstance(terms, str):
             terms = [ terms ]
 
     return terms
@@ -1493,7 +1493,7 @@
     if C.DEFAULT_HASH_BEHAVIOUR == "merge":
         return merge_hash(a, b)
     else:
-        return dict(a.items() + b.items())
+        return dict(list(a.items()) + list(b.items()))
 
 def random_password(length=20, chars=C.DEFAULT_PASSWORD_CHARS):
     '''Return a random password string of length containing only chars.'''
@@ -1638,7 +1638,7 @@
     screen
     '''
     new_data = {}
-    for (x,y) in data.iteritems():
+    for (x,y) in data.items():
        if x in [ 'skipped', 'changed', 'failed', 'rc' ]:
            new_data[x] = y
     new_data['censored'] = 'results hidden due to no_log parameter'
--- ./lib/ansible/utils/display_functions.py	(original)
+++ ./lib/ansible/utils/display_functions.py	(refactored)
@@ -38,12 +38,12 @@
             try:
                 print(msg2)
             except UnicodeEncodeError:
-                print(msg2.encode('utf-8'))
+                print((msg2.encode('utf-8')))
         else:
             try:
-                print >>sys.stderr, msg2
+                print(msg2, file=sys.stderr)
             except UnicodeEncodeError:
-                print >>sys.stderr, msg2.encode('utf-8')
+                print(msg2.encode('utf-8'), file=sys.stderr)
     if constants.DEFAULT_LOG_PATH != '':
         while msg.startswith("\n"):
             msg = msg.replace("\n","")
--- ./lib/ansible/utils/module_docs.py	(original)
+++ ./lib/ansible/utils/module_docs.py	(refactored)
@@ -72,18 +72,18 @@
                         fragment_yaml = getattr(fragment_class, fragment_var, '{}')
                         fragment = yaml.safe_load(fragment_yaml)
 
-                        if fragment.has_key('notes'):
+                        if 'notes' in fragment:
                             notes = fragment.pop('notes')
                             if notes:
-                                if not doc.has_key('notes'):
+                                if 'notes' not in doc:
                                     doc['notes'] = []
                                 doc['notes'].extend(notes)
 
-                        if 'options' not in fragment.keys():
+                        if 'options' not in list(fragment.keys()):
                             raise Exception("missing options in fragment, possibly misformatted?")
 
-                        for key, value in fragment.items():
-                            if not doc.has_key(key):
+                        for key, value in list(fragment.items()):
+                            if key not in doc:
                                 doc[key] = value
                             else:
                                 doc[key].update(value)
@@ -97,6 +97,6 @@
         traceback.print_exc() # temp
         if verbose == True:
             traceback.print_exc()
-            print "unable to parse %s" % filename
+            print("unable to parse %s" % filename)
     return doc, plainexamples, returndocs
 
--- ./lib/ansible/utils/template.py	(original)
+++ ./lib/ansible/utils/template.py	(refactored)
@@ -111,12 +111,12 @@
     from ansible import utils
 
     try:
-        if convert_bare and isinstance(varname, str):
+        if convert_bare and isinstance(varname, str):
             first_part = varname.split(".")[0].split("[")[0]
             if first_part in templatevars and '{{' not in varname and '$' not in varname:
                 varname = "{{%s}}" % varname
 
-        if isinstance(varname, str):
+        if isinstance(varname, str):
             if '{{' in varname or '{%' in varname:
                 try:
                     varname = template_from_string(basedir, varname, templatevars, fail_on_undefined)
@@ -134,7 +134,7 @@
             return [template(basedir, v, templatevars, lookup_fatal, depth, expand_lists, convert_bare, fail_on_undefined, filter_fatal) for v in varname]
         elif isinstance(varname, dict):
             d = {}
-            for (k, v) in varname.iteritems():
+            for (k, v) in varname.items():
                 d[k] = template(basedir, v, templatevars, lookup_fatal, depth, expand_lists, convert_bare, fail_on_undefined, filter_fatal)
             return d
         else:
@@ -313,7 +313,7 @@
     if data_newlines > res_newlines:
         res += '\n' * (data_newlines - res_newlines)
 
-    if isinstance(res, unicode):
+    if isinstance(res, str):
         # do not try to re-template a unicode string
         result = res
     else:
@@ -326,7 +326,7 @@
 
     try:
         if type(data) == str:
-            data = unicode(data, 'utf-8')
+            data = str(data, 'utf-8')
 
         def my_finalize(thing):
             return thing if thing is not None else ''
@@ -342,7 +342,7 @@
                 basedir = filesdir
 
         # 6227
-        if isinstance(data, unicode):
+        if isinstance(data, str):
             try:
                 data = data.decode('utf-8')
             except UnicodeEncodeError as e:
--- ./lib/ansible/utils/unicode.py	(original)
+++ ./lib/ansible/utils/unicode.py	(refactored)
@@ -88,19 +88,19 @@
     '''
     # Could use isbasestring/isunicode here but we want this code to be as
     # fast as possible
-    if isinstance(obj, str):
-        if isinstance(obj, unicode):
+    if isinstance(obj, str):
+        if isinstance(obj, str):
             return obj
         if encoding in _UTF8_ALIASES:
-            return unicode(obj, 'utf-8', errors)
+            return str(obj, 'utf-8', errors)
         if encoding in _LATIN1_ALIASES:
-            return unicode(obj, 'latin-1', errors)
+            return str(obj, 'latin-1', errors)
         return obj.decode(encoding, errors)
 
     if not nonstring:
         nonstring = 'simplerepr'
     if nonstring == 'empty':
-        return u''
+        return ''
     elif nonstring == 'passthru':
         return obj
     elif nonstring == 'simplerepr':
@@ -115,14 +115,14 @@
                 try:
                     simple = obj.__str__()
                 except (UnicodeError, AttributeError):
-                    simple = u''
+                    simple = ''
         if isinstance(simple, str):
-            return unicode(simple, encoding, errors)
+            return str(simple, encoding, errors)
         return simple
     elif nonstring in ('repr', 'strict'):
         obj_repr = repr(obj)
         if isinstance(obj_repr, str):
-            obj_repr = unicode(obj_repr, encoding, errors)
+            obj_repr = str(obj_repr, encoding, errors)
         if nonstring == 'repr':
             return obj_repr
         raise TypeError('to_unicode was given "%(obj)s" which is neither'
@@ -197,7 +197,7 @@
     '''
     # Could use isbasestring, isbytestring here but we want this to be as fast
     # as possible
-    if isinstance(obj, str):
+    if isinstance(obj, str):
         if isinstance(obj, str):
             return obj
         return obj.encode(encoding, errors)
@@ -221,7 +221,7 @@
                 simple = obj.__unicode__()
             except (AttributeError, UnicodeError):
                 simple = ''
-        if isinstance(simple, unicode):
+        if isinstance(simple, str):
             simple = simple.encode(encoding, 'replace')
         return simple
     elif nonstring in ('repr', 'strict'):
@@ -229,7 +229,7 @@
             obj_repr = obj.__repr__()
         except (AttributeError, UnicodeError):
             obj_repr = ''
-        if isinstance(obj_repr, unicode):
+        if isinstance(obj_repr, str):
             obj_repr =  obj_repr.encode(encoding, errors)
         else:
             obj_repr = str(obj_repr)
--- ./lib/ansible/utils/vault.py	(original)
+++ ./lib/ansible/utils/vault.py	(refactored)
@@ -525,7 +525,7 @@
         # 1) nbits (integer) - Length of the counter, in bits.
         # 2) initial_value (integer) - initial value of the counter. "iv" from gen_key_initctr
 
-        ctr = Counter.new(128, initial_value=long(iv, 16))
+        ctr = Counter.new(128, initial_value=int(iv, 16))
 
         # AES.new PARAMETERS
         # 1) AES key, must be either 16, 24, or 32 bytes long -- "key" from gen_key_initctr
@@ -560,7 +560,7 @@
             return None
 
         # SET THE COUNTER AND THE CIPHER
-        ctr = Counter.new(128, initial_value=long(iv, 16))
+        ctr = Counter.new(128, initial_value=int(iv, 16))
         cipher = AES.new(key1, AES.MODE_CTR, counter=ctr)
 
         # DECRYPT PADDED DATA
--- ./plugins/callbacks/context_demo.py	(original)
+++ ./plugins/callbacks/context_demo.py	(refactored)
@@ -28,4 +28,4 @@
     def on_any(self, *args, **kwargs):
         play = getattr(self, 'play', None)
         task = getattr(self, 'task', None)
-        print "play = %s, task = %s, args = %s, kwargs = %s" % (play,task,args,kwargs)
+        print("play = %s, task = %s, args = %s, kwargs = %s" % (play,task,args,kwargs))
--- ./plugins/callbacks/hipchat.py	(original)
+++ ./plugins/callbacks/hipchat.py	(refactored)
@@ -16,7 +16,7 @@
 # along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
 
 import os
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 from ansible import utils
 from ansible.module_utils.urls import open_url
@@ -77,7 +77,7 @@
 
         url = ('%s?auth_token=%s' % (self.msg_uri, self.token))
         try:
-            response = open_url(url, data=urllib.urlencode(params))
+            response = open_url(url, data=urllib.parse.urlencode(params))
             return response.read()
         except:
             utils.warning('Could not submit message to hipchat')
--- ./plugins/callbacks/mail.py	(original)
+++ ./plugins/callbacks/mail.py	(refactored)
@@ -54,13 +54,13 @@
         sender = '"Ansible: %s" <root>' % host
         subject = 'Failed: %(module_name)s %(module_args)s' % res['invocation']
         body = 'The following task failed for host ' + host + ':\n\n%(module_name)s %(module_args)s\n\n' % res['invocation']
-        if 'stdout' in res.keys() and res['stdout']:
+        if 'stdout' in list(res.keys()) and res['stdout']:
             subject = res['stdout'].strip('\r\n').split('\n')[-1]
             body += 'with the following output in standard output:\n\n' + res['stdout'] + '\n\n'
-        if 'stderr' in res.keys() and res['stderr']:
+        if 'stderr' in list(res.keys()) and res['stderr']:
             subject = res['stderr'].strip('\r\n').split('\n')[-1]
             body += 'with the following output in standard error:\n\n' + res['stderr'] + '\n\n'
-        if 'msg' in res.keys() and res['msg']:
+        if 'msg' in list(res.keys()) and res['msg']:
             subject = res['msg'].strip('\r\n').split('\n')[0]
             body += 'with the following message:\n\n' + res['msg'] + '\n\n'
         body += 'A complete dump of the error:\n\n' + str(res)
@@ -68,7 +68,7 @@
                   
     def runner_on_unreachable(self, host, res):
         sender = '"Ansible: %s" <root>' % host
-        if isinstance(res, str):
+        if isinstance(res, str):
             subject = 'Unreachable: %s' % res.strip('\r\n').split('\n')[-1]
             body = 'An error occurred for host ' + host + ' with the following message:\n\n' + res
         else:
@@ -79,7 +79,7 @@
 
     def runner_on_async_failed(self, host, res, jid):
         sender = '"Ansible: %s" <root>' % host
-        if isinstance(res, str):
+        if isinstance(res, str):
             subject = 'Async failure: %s' % res.strip('\r\n').split('\n')[-1]
             body = 'An error occurred for host ' + host + ' with the following message:\n\n' + res
         else:
--- ./plugins/callbacks/osx_say.py	(original)
+++ ./plugins/callbacks/osx_say.py	(refactored)
@@ -37,8 +37,8 @@
         # ansible will not call any callback if disabled is set to True
         if not os.path.exists(SAY_CMD):
             self.disabled = True
-            print "%s does not exist, plugin %s disabled" % \
-                    (SAY_CMD, os.path.basename(__file__))
+            print("%s does not exist, plugin %s disabled" % \
+                    (SAY_CMD, os.path.basename(__file__)))
 
     def on_any(self, *args, **kwargs):
         pass
--- ./plugins/callbacks/timer.py	(original)
+++ ./plugins/callbacks/timer.py	(refactored)
@@ -12,7 +12,7 @@
     
     def __init__(self):
         start_time = datetime.now()
-        print "Timer plugin is active."
+        print("Timer plugin is active.")
 
     def days_hours_minutes_seconds(self, timedelta):
         minutes = (timedelta.seconds//60)%60
@@ -22,6 +22,6 @@
     def playbook_on_stats(self, stats):
         end_time = datetime.now()
         timedelta = end_time - self.start_time
-        print "Playbook run took %s days, %s hours, %s minutes, %s seconds" % (self.days_hours_minutes_seconds(timedelta))
+        print("Playbook run took %s days, %s hours, %s minutes, %s seconds" % (self.days_hours_minutes_seconds(timedelta)))
 
 
--- ./plugins/inventory/abiquo.py	(original)
+++ ./plugins/inventory/abiquo.py	(refactored)
@@ -44,8 +44,8 @@
 import os
 import sys
 import time
-import ConfigParser
-import urllib2
+import configparser
+import urllib.request, urllib.error, urllib.parse
 import base64
 
 try:
@@ -56,15 +56,15 @@
 def api_get(link, config):
     try:
         if link == None:
-            request = urllib2.Request(config.get('api','uri')+config.get('api','login_path'))
+            request = urllib.request.Request(config.get('api','uri')+config.get('api','login_path'))
             request.add_header("Accept",config.get('api','login_type'))
         else:
-            request = urllib2.Request(link['href']+'?limit=0')
+            request = urllib.request.Request(link['href']+'?limit=0')
             request.add_header("Accept",link['type'])
         # Auth
         base64string = base64.encodestring('%s:%s' % (config.get('auth','apiuser'),config.get('auth','apipass'))).replace('\n', '')
         request.add_header("Authorization", "Basic %s" % base64string)
-        result = urllib2.urlopen(request)
+        result = urllib.request.urlopen(request)
         return json.loads(result.read())
     except:
         return None
@@ -76,7 +76,7 @@
         cache = open('/'.join([dpath,'inventory']), 'w')
         cache.write(json.dumps(data))
         cache.close()
-    except IOError, e:
+    except IOError as e:
         pass # not really sure what to do here
 
 
@@ -88,7 +88,7 @@
         cache = open('/'.join([dpath,'inventory']), 'r')
         inv = cache.read()
         cache.close()
-    except IOError, e:
+    except IOError as e:
         pass # not really sure what to do here
 
     return inv
@@ -151,15 +151,15 @@
                 vm_state = False
 
             if not vm_nic == None and vm_state:
-                if not vm_vapp in inventory.keys():
+                if not vm_vapp in list(inventory.keys()):
                     inventory[vm_vapp] = {}
                     inventory[vm_vapp]['children'] = []
                     inventory[vm_vapp]['hosts'] = []
-                if not vm_vdc in inventory.keys():
+                if not vm_vdc in list(inventory.keys()):
                     inventory[vm_vdc] = {}
                     inventory[vm_vdc]['hosts'] = []
                     inventory[vm_vdc]['children'] = []
-                if not vm_template in inventory.keys():
+                if not vm_template in list(inventory.keys()):
                     inventory[vm_template] = {}
                     inventory[vm_template]['children'] = []
                     inventory[vm_template]['hosts'] = []
@@ -172,7 +172,7 @@
                         else:
                             vm_metadata = metadata['metadata']['metadata']
                         inventory['_meta']['hostvars'][vm_nic] = vm_metadata
-                    except Exception, e:
+                    except Exception as e:
                         pass
 
                 inventory[vm_vapp]['children'].append(vmcollection['name'])
@@ -183,7 +183,7 @@
                 inventory[vmcollection['name']].append(vm_nic)
 
         return inventory
-    except Exception, e:
+    except Exception as e:
         # Return empty hosts output
         return { 'all': {'hosts': []}, '_meta': { 'hostvars': {} } }
 
@@ -205,7 +205,7 @@
     enterprise = {}
 
     # Read config
-    config = ConfigParser.SafeConfigParser()
+    config = configparser.SafeConfigParser()
     for configfilename in [os.path.abspath(sys.argv[0]).rstrip('.py') + '.ini', 'abiquo.ini']:
         if os.path.exists(configfilename):
             config.read(configfilename)
@@ -214,7 +214,7 @@
     try:
         login = api_get(None,config)
         enterprise = next(link for link in (login['links']) if (link['rel']=='enterprise'))
-    except Exception, e:
+    except Exception as e:
         enterprise = None
 
     if cache_available(config):
--- ./plugins/inventory/apache-libcloud.py	(original)
+++ ./plugins/inventory/apache-libcloud.py	(refactored)
@@ -35,7 +35,7 @@
 import argparse
 import re
 from time import time
-import ConfigParser
+import configparser
 
 from libcloud.compute.types import Provider
 from libcloud.compute.providers import get_driver
@@ -79,7 +79,7 @@
             else:
                 data_to_print = self.json_format_dict(self.inventory, True)
 
-        print data_to_print
+        print(data_to_print)
 
 
     def is_cache_valid(self):
@@ -98,7 +98,7 @@
     def read_settings(self):
         ''' Reads the settings from the libcloud.ini file '''
 
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         libcloud_default_ini_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'libcloud.ini')
         libcloud_ini_path = os.environ.get('LIBCLOUD_INI_PATH', libcloud_default_ini_path)
         config.read(libcloud_ini_path)
@@ -256,14 +256,14 @@
             # Handle complex types
             if type(value) in [int, bool]:
                 instance_vars[key] = value
-            elif type(value) in [str, unicode]:
+            elif type(value) in [str, str]:
                 instance_vars[key] = value.strip()
             elif type(value) == type(None):
                 instance_vars[key] = ''
             elif key == 'ec2_region':
                 instance_vars[key] = value.name
             elif key == 'ec2_tags':
-                for k, v in value.iteritems():
+                for k, v in value.items():
                     key = self.to_safe('ec2_tag_' + k)
                     instance_vars[key] = v
             elif key == 'ec2_groups':
--- ./plugins/inventory/cobbler.py	(original)
+++ ./plugins/inventory/cobbler.py	(refactored)
@@ -56,11 +56,11 @@
 
 
 import argparse
-import ConfigParser
+import configparser
 import os
 import re
 from time import time
-import xmlrpclib
+import xmlrpc.client
 
 try:
     import json
@@ -107,11 +107,11 @@
         else:  # default action with no options
             data_to_print = self.json_format_dict(self.inventory, True)
 
-        print data_to_print
+        print(data_to_print)
 
     def _connect(self):
         if not self.conn:
-            self.conn = xmlrpclib.Server(self.cobbler_host, allow_none=True)
+            self.conn = xmlrpc.client.Server(self.cobbler_host, allow_none=True)
 
     def is_cache_valid(self):
         """ Determines if the cache files have expired, or if it is still valid """
@@ -128,7 +128,7 @@
     def read_settings(self):
         """ Reads the settings from the cobbler.ini file """
 
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         config.read(os.path.dirname(os.path.realpath(__file__)) + '/cobbler.ini')
 
         self.cobbler_host = config.get('cobbler', 'host')
@@ -163,7 +163,7 @@
             dns_name = None
             ksmeta = None
             interfaces = host['interfaces']
-            for (iname, ivalue) in interfaces.iteritems():
+            for (iname, ivalue) in interfaces.items():
                 if ivalue['management']:
                     this_dns_name = ivalue.get('dns_name', None)
                     if this_dns_name is not None and this_dns_name is not "":
@@ -195,7 +195,7 @@
 
             self.cache[dns_name] = dict()
             if "ks_meta" in host:
-                for key, value in host["ks_meta"].iteritems():
+                for key, value in host["ks_meta"].items():
                     self.cache[dns_name][key] = value
 
         self.write_to_cache(self.cache, self.cache_path_cache)
--- ./plugins/inventory/collins.py	(original)
+++ ./plugins/inventory/collins.py	(refactored)
@@ -68,15 +68,15 @@
 
 import argparse
 import base64
-import ConfigParser
+import configparser
 import logging
 import os
 import re
 import sys
 from time import time
 import traceback
-import urllib
-import urllib2
+import urllib.request, urllib.parse, urllib.error
+import urllib.request, urllib.error, urllib.parse
 
 try:
     import json
@@ -124,7 +124,7 @@
             returns None. """
 
         if 'ATTRIBS' in asset:
-            for attrib_block in asset['ATTRIBS'].keys():
+            for attrib_block in list(asset['ATTRIBS'].keys()):
                 if attrib in asset['ATTRIBS'][attrib_block]:
                     return asset['ATTRIBS'][attrib_block][attrib]
         return None
@@ -133,7 +133,7 @@
         """ Returns whether a user-defined attribute is present on an asset. """
 
         if 'ATTRIBS' in asset:
-            for attrib_block in asset['ATTRIBS'].keys():
+            for attrib_block in list(asset['ATTRIBS'].keys()):
                 if attrib in asset['ATTRIBS'][attrib_block]:
                     return True
         return False
@@ -164,7 +164,7 @@
         else:  # default action with no options
             data_to_print = self.json_format_dict(self.inventory, self.args.pretty)
 
-        print data_to_print
+        print(data_to_print)
         return successful
 
     def find_assets(self, attributes = {}, operation = 'AND'):
@@ -174,7 +174,7 @@
         # the CQL search feature as described here:
         # http://tumblr.github.io/collins/recipes.html
         attributes_query = [ '='.join(attr_pair)
-            for attr_pair in attributes.iteritems() ]
+            for attr_pair in attributes.items() ]
         query_parameters = {
             'details': ['True'],
             'operation': [operation],
@@ -194,12 +194,12 @@
             query_parameters['page'] = cur_page
             query_url = "%s?%s" % (
                 (CollinsDefaults.ASSETS_API_ENDPOINT % self.collins_host),
-                urllib.urlencode(query_parameters, doseq=True)
+                urllib.parse.urlencode(query_parameters, doseq=True)
             )
-            request = urllib2.Request(query_url)
+            request = urllib.request.Request(query_url)
             request.add_header('Authorization', self.basic_auth_header)
             try:
-                response = urllib2.urlopen(request, timeout=self.collins_timeout_secs)
+                response = urllib.request.urlopen(request, timeout=self.collins_timeout_secs)
                 json_response = json.loads(response.read())
                 # Adds any assets found to the array of assets.
                 assets += json_response['data']['Data']
@@ -232,7 +232,7 @@
         config_loc = os.getenv('COLLINS_CONFIG',
             os.path.dirname(os.path.realpath(__file__)) + '/collins.ini')
 
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         config.read(os.path.dirname(os.path.realpath(__file__)) + '/collins.ini')
 
         self.collins_host = config.get('collins', 'host')
@@ -334,14 +334,14 @@
 
             # Indexes asset by all user-defined Collins attributes.
             if 'ATTRIBS' in asset:
-                for attrib_block in asset['ATTRIBS'].keys():
-                    for attrib in asset['ATTRIBS'][attrib_block].keys():
+                for attrib_block in list(asset['ATTRIBS'].keys()):
+                    for attrib in list(asset['ATTRIBS'][attrib_block].keys()):
                         asset['COLLINS'][attrib] = asset['ATTRIBS'][attrib_block][attrib]
                         attrib_key = self.to_safe('%s-%s' % (attrib, asset['ATTRIBS'][attrib_block][attrib]))
                         self.push(self.inventory, attrib_key, asset_identifier)
 
             # Indexes asset by all built-in Collins attributes.
-            for attribute in asset['ASSET'].keys():
+            for attribute in list(asset['ASSET'].keys()):
                 if attribute not in CollinsDefaults.SPECIAL_ATTRIBUTES:
                     attribute_val = asset['ASSET'][attribute]
                     if attribute_val is not None:
--- ./plugins/inventory/consul_io.py	(original)
+++ ./plugins/inventory/consul_io.py	(refactored)
@@ -125,8 +125,8 @@
 import re
 import argparse
 from time import time
-import ConfigParser
-import urllib, urllib2, base64
+import configparser
+import urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse, base64
 
 try:
   import json
@@ -135,9 +135,9 @@
 
 try:
   import consul
-except ImportError, e:
-  print """failed=True msg='python-consul required for this module. see
-  http://python-consul.readthedocs.org/en/latest/#installation'"""
+except ImportError as e:
+  print("""failed=True msg='python-consul required for this module. see
+  http://python-consul.readthedocs.org/en/latest/#installation'""")
   sys.exit(1)
 
 
@@ -170,7 +170,7 @@
       self.load_all_data_consul()
 
     self.combine_all_results()
-    print json.dumps(self.inventory, sort_keys=True, indent=2)
+    print(json.dumps(self.inventory, sort_keys=True, indent=2))
 
   def load_all_data_consul(self):
     ''' cycle through each of the datacenters in the consul catalog and process
@@ -186,7 +186,7 @@
     an 'available' or 'unavailable' grouping. The suffix for each group can be
     controlled from the config'''
     if self.config.has_config('availability'):
-      for service_name, service in node['Services'].iteritems():
+      for service_name, service in node['Services'].items():
         for node in self.consul_api.health.service(service_name)[1]:
             for check in node['Checks']:
                 if check['ServiceName'] == service_name:
@@ -222,7 +222,7 @@
     self.load_node_metadata_from_kv(node_data)
     self.load_availability_groups(node_data, datacenter)
 
-    for name, service in node_data['Services'].items():
+    for name, service in list(node_data['Services'].items()):
       self.load_data_from_service(name, service, node_data)
 
   def load_node_metadata_from_kv(self, node_data):
@@ -236,7 +236,7 @@
       if metadata and metadata['Value']:
         try:
             metadata = json.loads(metadata['Value'])
-            for k,v in metadata.items():
+            for k,v in list(metadata.items()):
               self.add_metadata(node_data, k, v)
         except:
             pass
@@ -287,7 +287,7 @@
     groupings = [self.nodes, self.nodes_by_datacenter, self.nodes_by_service,
                 self.nodes_by_tag, self.nodes_by_kv, self.nodes_by_availability]
     for grouping in groupings:
-      for name, addresses in grouping.items():
+      for name, addresses in list(grouping.items()):
         self.inventory[name] = sorted(list(set(addresses)))
 
   def add_metadata(self, node_data, key, value, is_list = False):
@@ -339,7 +339,7 @@
   def sanitize_dict(self, d):
 
     new_dict = {}
-    for k, v in d.items():
+    for k, v in list(d.items()):
       if v != None:
         new_dict[self.to_safe(str(k))] = self.to_safe(str(v))
     return new_dict
@@ -365,7 +365,7 @@
 
   def read_settings(self):
     ''' Reads the settings from the consul.ini file '''
-    config = ConfigParser.SafeConfigParser()
+    config = configparser.SafeConfigParser()
     config.read(os.path.dirname(os.path.realpath(__file__)) + '/consul.ini')
 
     config_options = ['host', 'token', 'datacenter', 'servers_suffix',
@@ -411,7 +411,7 @@
       token = None
 
       if hasattr(self, 'url'):
-          from urlparse import urlparse
+          from urllib.parse import urlparse
           o = urlparse(self.url)
           if o.hostname:
               host = o.hostname
--- ./plugins/inventory/digital_ocean.py	(original)
+++ ./plugins/inventory/digital_ocean.py	(refactored)
@@ -130,7 +130,7 @@
 import re
 import argparse
 from time import time
-import ConfigParser
+import configparser
 
 try:
     import json
@@ -139,8 +139,8 @@
 
 try:
     from dopy.manager import DoError, DoManager
-except ImportError, e:
-    print "failed=True msg='`dopy` library required for this script'"
+except ImportError as e:
+    print("failed=True msg='`dopy` library required for this script'")
     sys.exit(1)
 
 
@@ -170,14 +170,14 @@
 
         # Verify credentials were set
         if not hasattr(self, 'client_id') or not hasattr(self, 'api_key'):
-            print '''Could not find values for DigitalOcean client_id and api_key.
+            print('''Could not find values for DigitalOcean client_id and api_key.
 They must be specified via either ini file, command line argument (--client-id and --api-key),
-or environment variables (DO_CLIENT_ID and DO_API_KEY)'''
+or environment variables (DO_CLIENT_ID and DO_API_KEY)''')
             sys.exit(-1)
 
         # env command, show DigitalOcean credentials
         if self.args.env:
-            print "DO_CLIENT_ID=%s DO_API_KEY=%s" % (self.client_id, self.api_key)
+            print("DO_CLIENT_ID=%s DO_API_KEY=%s" % (self.client_id, self.api_key))
             sys.exit(0)
 
         # Manage cache
@@ -190,7 +190,7 @@
             self.load_from_cache()
             if len(self.data) == 0:
                 if self.args.force_cache:
-                    print '''Cache is empty and --force-cache was specified'''
+                    print('''Cache is empty and --force-cache was specified''')
                     sys.exit(-1)
                 self.load_all_data_from_digital_ocean()
             else:
@@ -214,9 +214,9 @@
                                  json_data = self.inventory
 
         if self.args.pretty:
-            print json.dumps(json_data, sort_keys=True, indent=2)
+            print(json.dumps(json_data, sort_keys=True, indent=2))
         else:
-            print json.dumps(json_data)
+            print(json.dumps(json_data))
         # That's all she wrote...
 
 
@@ -226,7 +226,7 @@
 
     def read_settings(self):
         ''' Reads the settings from the digital_ocean.ini file '''
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         config.read(os.path.dirname(os.path.realpath(__file__)) + '/digital_ocean.ini')
 
         # Credentials
@@ -329,7 +329,7 @@
     def build_index(self, source_seq, key_from, key_to, use_slug=True):
         dest_dict = {}
         for item in source_seq:
-            name = (use_slug and item.has_key('slug')) and item['slug'] or item[key_to]
+            name = (use_slug and 'slug' in item) and item['slug'] or item[key_to]
             key = item[key_from]
             dest_dict[key] = name
         return dest_dict
@@ -396,15 +396,15 @@
 
         # Put all the information in a 'do_' namespace
         info = {}
-        for k, v in droplet.items():
+        for k, v in list(droplet.items()):
             info['do_'+k] = v
 
         # Generate user-friendly variables (i.e. not the ID's) 
-        if droplet.has_key('region_id'):
+        if 'region_id' in droplet:
             info['do_region'] = self.index['region_to_name'].get(droplet['region_id'])
-        if droplet.has_key('size_id'):
+        if 'size_id' in droplet:
             info['do_size'] = self.index['size_to_name'].get(droplet['size_id'])
-        if droplet.has_key('image_id'):
+        if 'image_id' in droplet:
             info['do_image']  = self.index['image_to_name'].get(droplet['image_id'])
             info['do_distro'] = self.index['image_to_distro'].get(droplet['image_id'])
 
@@ -468,7 +468,7 @@
 
     def sanitize_dict(self, d):
         new_dict = {}
-        for k, v in d.items():
+        for k, v in list(d.items()):
             if v != None:
                 new_dict[self.to_safe(str(k))] = self.to_safe(str(v))
         return new_dict
--- ./plugins/inventory/docker.py	(original)
+++ ./plugins/inventory/docker.py	(refactored)
@@ -165,13 +165,13 @@
         if dict is None:
             pass
         elif isinstance(dict, UserDict):
-            for k, v in dict.data.items():
+            for k, v in list(dict.data.items()):
                 self[k] = v
         else:
-            for k, v in dict.items():
+            for k, v in list(dict.items()):
                 self[k] = v
         if len(kwargs):
-            for k, v in kwargs.items():
+            for k, v in list(kwargs.items()):
                 self[k] = v
 
 
@@ -288,7 +288,7 @@
 
             groups[id].append(name)
             groups[name].append(name)
-            if not short_id in groups.keys():
+            if not short_id in list(groups.keys()):
                 groups[short_id].append(name)
             groups[hostname].append(name)
 
@@ -334,7 +334,7 @@
     groups['docker_hosts'] = [host.get('base_url') for host in hosts]
     groups['_meta'] = dict()
     groups['_meta']['hostvars'] = hostvars
-    print json.dumps(groups, sort_keys=True, indent=4)
+    print(json.dumps(groups, sort_keys=True, indent=4))
     sys.exit(0)
 
 
--- ./plugins/inventory/ec2.py	(original)
+++ ./plugins/inventory/ec2.py	(refactored)
@@ -122,7 +122,7 @@
 from boto import ec2
 from boto import rds
 from boto import route53
-import ConfigParser
+import configparser
 from collections import defaultdict
 
 try:
@@ -166,7 +166,7 @@
             else:
                 data_to_print = self.json_format_dict(self.inventory, True)
 
-        print data_to_print
+        print(data_to_print)
 
 
     def is_cache_valid(self):
@@ -185,7 +185,7 @@
     def read_settings(self):
         ''' Reads the settings from the ec2.ini file '''
 
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         ec2_default_ini_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'ec2.ini')
         ec2_ini_path = os.environ.get('EC2_INI_PATH', ec2_default_ini_path)
         config.read(ec2_ini_path)
@@ -282,7 +282,7 @@
                 self.pattern_include = re.compile(pattern_include)
             else:
                 self.pattern_include = None
-        except ConfigParser.NoOptionError, e:
+        except configparser.NoOptionError as e:
             self.pattern_include = None
 
         # Do we need to exclude hosts that match a pattern?
@@ -292,7 +292,7 @@
                 self.pattern_exclude = re.compile(pattern_exclude)
             else:
                 self.pattern_exclude = None
-        except ConfigParser.NoOptionError, e:
+        except configparser.NoOptionError as e:
             self.pattern_exclude = None
 
         # Instance filters (see boto and EC2 API docs). Ignore invalid filters.
@@ -354,7 +354,7 @@
             conn = self.connect(region)
             reservations = []
             if self.ec2_instance_filters:
-                for filter_key, filter_values in self.ec2_instance_filters.iteritems():
+                for filter_key, filter_values in self.ec2_instance_filters.items():
                     reservations.extend(conn.get_all_instances(filters = { filter_key : filter_values }))
             else:
                 reservations = conn.get_all_instances()
@@ -363,7 +363,7 @@
                 for instance in reservation.instances:
                     self.add_instance(instance, region)
 
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             if e.error_code == 'AuthFailure':
                 error = self.get_auth_error_message()
             else:
@@ -381,7 +381,7 @@
                 instances = conn.get_all_dbinstances()
                 for instance in instances:
                     self.add_rds_instance(instance, region)
-        except boto.exception.BotoServerError, e:
+        except boto.exception.BotoServerError as e:
             error = e.message
             if e.error_code == 'AuthFailure':
                 error = self.get_auth_error_message()
@@ -514,7 +514,7 @@
 
         # Inventory: Group by tag keys
         if self.group_by_tag_keys:
-            for k, v in instance.tags.iteritems():
+            for k, v in instance.tags.items():
                 key = self.to_safe("tag_" + k + "=" + v)
                 self.push(self.inventory, key, dest)
                 if self.nested_groups:
@@ -689,7 +689,7 @@
                 instance_vars['ec2_previous_state_code'] = instance.previous_state_code
             elif type(value) in [int, bool]:
                 instance_vars[key] = value
-            elif type(value) in [str, unicode]:
+            elif type(value) in [str, str]:
                 instance_vars[key] = value.strip()
             elif type(value) == type(None):
                 instance_vars[key] = ''
@@ -698,7 +698,7 @@
             elif key == 'ec2__placement':
                 instance_vars['ec2_placement'] = value.zone
             elif key == 'ec2_tags':
-                for k, v in value.iteritems():
+                for k, v in value.items():
                     key = self.to_safe('ec2_tag_' + k)
                     instance_vars[key] = v
             elif key == 'ec2_groups':
--- ./plugins/inventory/freeipa.py	(original)
+++ ./plugins/inventory/freeipa.py	(refactored)
@@ -37,7 +37,7 @@
 
     inventory['_meta'] = {'hostvars': hostvars}
     inv_string = json.dumps(inventory, indent=1, sort_keys=True)
-    print inv_string
+    print(inv_string)
     
     return None
 
@@ -65,7 +65,7 @@
     This function expects one string, this hostname to lookup variables for.
     '''
 
-    print json.dumps({})
+    print(json.dumps({}))
 
     return None
 
--- ./plugins/inventory/gce.py	(original)
+++ ./plugins/inventory/gce.py	(refactored)
@@ -88,7 +88,7 @@
 import sys
 import os
 import argparse
-import ConfigParser
+import configparser
 
 try:
     import json
@@ -112,14 +112,14 @@
 
         # Just display data for specific host
         if self.args.host:
-            print self.json_format_dict(self.node_to_dict(
+            print(self.json_format_dict(self.node_to_dict(
                     self.get_instance(self.args.host)),
-                    pretty=self.args.pretty)
+                    pretty=self.args.pretty))
             sys.exit(0)
 
         # Otherwise, assume user wants all instances grouped
-        print(self.json_format_dict(self.group_instances(),
-            pretty=self.args.pretty))
+        print((self.json_format_dict(self.group_instances(),
+            pretty=self.args.pretty)))
         sys.exit(0)
 
     def get_gce_driver(self):
@@ -134,7 +134,7 @@
         # This provides empty defaults to each key, so that environment
         # variable configuration (as opposed to INI configuration) is able
         # to work.
-        config = ConfigParser.SafeConfigParser(defaults={
+        config = configparser.SafeConfigParser(defaults={
             'gce_service_account_email_address': '',
             'gce_service_account_pem_file_path': '',
             'gce_project_id': '',
@@ -210,7 +210,7 @@
         if inst is None:
             return {}
 
-        if inst.extra['metadata'].has_key('items'):
+        if 'items' in inst.extra['metadata']:
             for entry in inst.extra['metadata']['items']:
                 md[entry['key']] = entry['value']
 
@@ -237,7 +237,7 @@
         '''Gets details about a specific instance '''
         try:
             return self.driver.ex_get_node(instance_name)
-        except Exception, e:
+        except Exception as e:
             return None
 
     def group_instances(self):
@@ -252,31 +252,31 @@
             meta["hostvars"][name] = self.node_to_dict(node)
 
             zone = node.extra['zone'].name
-            if groups.has_key(zone): groups[zone].append(name)
+            if zone in groups: groups[zone].append(name)
             else: groups[zone] = [name]
 
             tags = node.extra['tags']
             for t in tags:
                 tag = 'tag_%s' % t
-                if groups.has_key(tag): groups[tag].append(name)
+                if tag in groups: groups[tag].append(name)
                 else: groups[tag] = [name]
 
             net = node.extra['networkInterfaces'][0]['network'].split('/')[-1]
             net = 'network_%s' % net
-            if groups.has_key(net): groups[net].append(name)
+            if net in groups: groups[net].append(name)
             else: groups[net] = [name]
 
             machine_type = node.size
-            if groups.has_key(machine_type): groups[machine_type].append(name)
+            if machine_type in groups: groups[machine_type].append(name)
             else: groups[machine_type] = [name]
 
             image = node.image and node.image or 'persistent_disk'
-            if groups.has_key(image): groups[image].append(name)
+            if image in groups: groups[image].append(name)
             else: groups[image] = [name]
 
             status = node.extra['status']
             stat = 'status_%s' % status.lower()
-            if groups.has_key(stat): groups[stat].append(name)
+            if stat in groups: groups[stat].append(name)
             else: groups[stat] = [name]
 
         groups["_meta"] = meta
--- ./plugins/inventory/jail.py	(original)
+++ ./plugins/inventory/jail.py	(refactored)
@@ -30,8 +30,8 @@
 result['all']['vars']['ansible_connection'] = 'jail'
 
 if len(sys.argv) == 2 and sys.argv[1] == '--list':
-    print json.dumps(result)
+    print(json.dumps(result))
 elif len(sys.argv) == 3 and sys.argv[1] == '--host':
-    print json.dumps({'ansible_connection': 'jail'})
+    print(json.dumps({'ansible_connection': 'jail'}))
 else:
-    print "Need an argument, either --list or --host <host>"
+    print("Need an argument, either --list or --host <host>")
--- ./plugins/inventory/libvirt_lxc.py	(original)
+++ ./plugins/inventory/libvirt_lxc.py	(refactored)
@@ -30,8 +30,8 @@
 result['all']['vars']['ansible_connection'] = 'lxc'
 
 if len(sys.argv) == 2 and sys.argv[1] == '--list':
-    print json.dumps(result)
+    print(json.dumps(result))
 elif len(sys.argv) == 3 and sys.argv[1] == '--host':
-    print json.dumps({'ansible_connection': 'lxc'})
+    print(json.dumps({'ansible_connection': 'lxc'}))
 else:
-    print "Need an argument, either --list or --host <host>"
+    print("Need an argument, either --list or --host <host>")
--- ./plugins/inventory/linode.py	(original)
+++ ./plugins/inventory/linode.py	(refactored)
@@ -101,13 +101,13 @@
         from chube.linode_obj import Linode
 
         sys.path = old_path
-    except Exception, e:
+    except Exception as e:
         raise Exception("could not import chube")
 
 load_chube_config()
 
 # Imports for ansible
-import ConfigParser
+import configparser
 
 class LinodeInventory(object):
     def __init__(self):
@@ -139,7 +139,7 @@
             else:
                 data_to_print = self.json_format_dict(self.inventory, True)
 
-        print data_to_print
+        print(data_to_print)
 
     def is_cache_valid(self):
         """Determines if the cache file has expired, or if it is still valid."""
@@ -153,7 +153,7 @@
 
     def read_settings(self):
         """Reads the settings from the .ini file."""
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         config.read(os.path.dirname(os.path.realpath(__file__)) + '/linode.ini')
 
         # Cache related
@@ -184,20 +184,20 @@
         try:
             for node in Linode.search(status=Linode.STATUS_RUNNING):
                 self.add_node(node)
-        except chube_api.linode_api.ApiError, e:
-            print "Looks like Linode's API is down:"
-            print
-            print e
+        except chube_api.linode_api.ApiError as e:
+            print("Looks like Linode's API is down:")
+            print()
+            print(e)
             sys.exit(1)
 
     def get_node(self, linode_id):
         """Gets details about a specific node."""
         try:
             return Linode.find(api_id=linode_id)
-        except chube_api.linode_api.ApiError, e:
-            print "Looks like Linode's API is down:"
-            print
-            print e
+        except chube_api.linode_api.ApiError as e:
+            print("Looks like Linode's API is down:")
+            print()
+            print(e)
             sys.exit(1)
 
     def populate_datacenter_cache(self):
--- ./plugins/inventory/nova.py	(original)
+++ ./plugins/inventory/nova.py	(refactored)
@@ -20,7 +20,7 @@
 import sys
 import re
 import os
-import ConfigParser
+import configparser
 from novaclient import client as nova_client
 
 try:
@@ -45,7 +45,7 @@
 
 
 def nova_load_config_file():
-    p = ConfigParser.SafeConfigParser(NOVA_DEFAULTS)
+    p = configparser.SafeConfigParser(NOVA_DEFAULTS)
 
     for path in NOVA_CONFIG_FILES:
         if os.path.exists(path):
@@ -77,7 +77,7 @@
         public = openstack_find_nova_addresses(getattr(server, 'addresses'), 'floating', 'public')
 	    
 	# Define group (or set to empty string)
-        group = server.metadata['group'] if server.metadata.has_key('group') else 'undefined'
+        group = server.metadata['group'] if 'group' in server.metadata else 'undefined'
 
         # Create group if not exist
         if group not in groups:
@@ -95,7 +95,7 @@
 		continue
 
     # Return server list
-    print(json.dumps(groups, sort_keys=True, indent=2))
+    print((json.dumps(groups, sort_keys=True, indent=2)))
     sys.exit(0)
 
 #####################################################
@@ -124,9 +124,9 @@
                 if key != 'os_manager':
                     results[key] = value
 
-    print(json.dumps(results, sort_keys=True, indent=2))
+    print((json.dumps(results, sort_keys=True, indent=2)))
     sys.exit(0)
 
 else:
-    print "usage: --list  ..OR.. --host <hostname>"
+    print("usage: --list  ..OR.. --host <hostname>")
     sys.exit(1)
--- ./plugins/inventory/openshift.py	(original)
+++ ./plugins/inventory/openshift.py	(refactored)
@@ -28,7 +28,7 @@
 author: Michael Scherer
 '''
 
-import urllib2
+import urllib.request, urllib.error, urllib.parse
 try:
     import json
 except ImportError:
@@ -36,8 +36,8 @@
 import os
 import os.path
 import sys
-import ConfigParser
-import StringIO
+import configparser
+import io
 
 configparser = None
 
@@ -48,11 +48,11 @@
     if os.path.exists(CONF_FILE):
         if not configparser:
             ini_str = '[root]\n' + open(CONF_FILE, 'r').read()
-            configparser = ConfigParser.SafeConfigParser()
-            configparser.readfp(StringIO.StringIO(ini_str))
+            configparser = configparser.SafeConfigParser()
+            configparser.readfp(io.StringIO(ini_str))
         try:
             return configparser.get('root', variable)
-        except ConfigParser.NoOptionError:
+        except configparser.NoOptionError:
             return None
 
 
@@ -61,26 +61,26 @@
     if not result:
         result = get_from_rhc_config(config_var)
     if not result:
-        print "failed=True msg='missing %s'" % env_var
+        print("failed=True msg='missing %s'" % env_var)
         sys.exit(1)
     return result
 
 
 def get_json_from_api(url):
-    req = urllib2.Request(url, None, {'Accept': 'application/json; version=1.5'})
-    response = urllib2.urlopen(req)
+    req = urllib.request.Request(url, None, {'Accept': 'application/json; version=1.5'})
+    response = urllib.request.urlopen(req)
     return json.loads(response.read())['data']
 
 
 def passwd_setup(top_level_url, username, password):
     # create a password manager
-    password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
+    password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
     password_mgr.add_password(None, top_level_url, username, password)
 
-    handler = urllib2.HTTPBasicAuthHandler(password_mgr)
-    opener = urllib2.build_opener(handler)
+    handler = urllib.request.HTTPBasicAuthHandler(password_mgr)
+    opener = urllib.request.build_opener(handler)
 
-    urllib2.install_opener(opener)
+    urllib.request.install_opener(opener)
 
 
 username = get_config('ANSIBLE_OPENSHIFT_USERNAME', 'default_rhlogin')
@@ -109,8 +109,8 @@
     result[app_name]['vars']['ansible_ssh_user'] = user
 
 if len(sys.argv) == 2 and sys.argv[1] == '--list':
-    print json.dumps(result)
+    print(json.dumps(result))
 elif len(sys.argv) == 3 and sys.argv[1] == '--host':
-    print json.dumps({})
+    print(json.dumps({}))
 else:
-    print "Need an argument, either --list or --host <host>"
+    print("Need an argument, either --list or --host <host>")
--- ./plugins/inventory/openstack.py	(original)
+++ ./plugins/inventory/openstack.py	(refactored)
@@ -120,13 +120,13 @@
     def list_instances(self):
         groups = self.get_host_groups()
         # Return server list
-        print(self.json_format_dict(groups))
+        print((self.json_format_dict(groups)))
 
     def get_host(self, hostname):
         groups = self.get_host_groups()
         hostvars = groups['_meta']['hostvars']
         if hostname in hostvars:
-            print(self.json_format_dict(hostvars[hostname]))
+            print((self.json_format_dict(hostvars[hostname])))
 
 
 def parse_args():
@@ -152,7 +152,7 @@
         elif args.host:
             inventory.get_host(args.host)
     except shade.OpenStackCloudException as e:
-        print(e.message)
+        print((e.message))
         sys.exit(1)
     sys.exit(0)
 
--- ./plugins/inventory/rax.py	(original)
+++ ./plugins/inventory/rax.py	(refactored)
@@ -151,7 +151,7 @@
 import argparse
 import warnings
 import collections
-import ConfigParser
+import configparser
 
 from ansible.constants import get_config, mk_boolean
 
@@ -167,16 +167,16 @@
     print('pyrax is required for this module')
     sys.exit(1)
 
-NON_CALLABLES = (str, bool, dict, int, list, type(None))
+NON_CALLABLES = (str, bool, dict, int, list, type(None))
 
 
 def load_config_file():
-    p = ConfigParser.ConfigParser()
+    p = configparser.ConfigParser()
     config_file = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                'rax.ini')
     try:
         p.read(config_file)
-    except ConfigParser.Error:
+    except configparser.Error:
         return None
     else:
         return p
@@ -206,12 +206,12 @@
         cs = pyrax.connect_to_cloudservers(region=region)
         for server in cs.servers.list():
             if server.name == hostname:
-                for key, value in to_dict(server).items():
+                for key, value in list(to_dict(server).items()):
                     hostvars[key] = value
 
                 # And finally, add an IP address
                 hostvars['ansible_ssh_host'] = server.accessIPv4
-    print(json.dumps(hostvars, sort_keys=True, indent=4))
+    print((json.dumps(hostvars, sort_keys=True, indent=4)))
 
 
 def _list(regions):
@@ -225,9 +225,9 @@
     networks = get_config(p, 'rax', 'access_network', 'RAX_ACCESS_NETWORK',
                           'public', islist=True)
     try:
-        ip_versions = map(int, get_config(p, 'rax', 'access_ip_version',
+        ip_versions = list(map(int, get_config(p, 'rax', 'access_ip_version',
                                           'RAX_ACCESS_IP_VERSION', 4,
-                                          islist=True))
+                                          islist=True)))
     except:
         ip_versions = [4]
     else:
@@ -259,12 +259,12 @@
                     groups[extra_group].append(server.name)
 
             # Add host metadata
-            for key, value in to_dict(server).items():
+            for key, value in list(to_dict(server).items()):
                 hostvars[server.name][key] = value
 
             hostvars[server.name]['rax_region'] = region
 
-            for key, value in server.metadata.iteritems():
+            for key, value in server.metadata.items():
                 groups['%s_%s_%s' % (prefix, key, value)].append(server.name)
 
             groups['instance-%s' % server.id].append(server.name)
@@ -334,7 +334,7 @@
 
     if hostvars:
         groups['_meta'] = {'hostvars': hostvars}
-    print(json.dumps(groups, sort_keys=True, indent=4))
+    print((json.dumps(groups, sort_keys=True, indent=4)))
 
 
 def parse_args():
@@ -382,7 +382,7 @@
             pyrax.keyring_auth(keyring_username, region=region)
         else:
             pyrax.set_credential_file(creds_file, region=region)
-    except Exception, e:
+    except Exception as e:
         sys.stderr.write("%s: %s\n" % (e, e.message))
         sys.exit(1)
 
--- ./plugins/inventory/softlayer.py	(original)
+++ ./plugins/inventory/softlayer.py	(refactored)
@@ -53,10 +53,10 @@
 
         if self.args.list:
             self.get_all_servers()
-            print self.json_format_dict(self.inventory, True)
+            print(self.json_format_dict(self.inventory, True))
         elif self.args.host:
             self.get_virtual_servers(client)
-            print self.json_format_dict(self.inventory["_meta"]["hostvars"][self.args.host], True)
+            print(self.json_format_dict(self.inventory["_meta"]["hostvars"][self.args.host], True))
 
     def to_safe(self, word):
         '''Converts 'bad' characters in a string to underscores so they can be used as Ansible groups'''
--- ./plugins/inventory/spacewalk.py	(original)
+++ ./plugins/inventory/spacewalk.py	(refactored)
@@ -54,7 +54,7 @@
 
 # Sanity check
 if not os.path.exists(SW_REPORT):
-    print >> sys.stderr, 'Error: %s is required for operation.' % (SW_REPORT)
+    print('Error: %s is required for operation.' % (SW_REPORT), file=sys.stderr)
     sys.exit(1)
 
 # Pre-startup work
@@ -83,7 +83,7 @@
     for line in lines[1:]:
         values = line.strip().split(',')
         if len(keys) == len(values):
-            yield dict(zip(keys, values))
+            yield dict(list(zip(keys, values)))
 
 
 # Options
@@ -112,16 +112,16 @@
 
             groups[system['group_name']].add(system['server_name'])
 
-    except (OSError), e:
-        print >> sys.stderr, 'Problem executing the command "%s system-groups-systems": %s' % \
-            (SW_REPORT, str(e))
+    except (OSError) as e:
+        print('Problem executing the command "%s system-groups-systems": %s' % \
+            (SW_REPORT, str(e)), file=sys.stderr)
         sys.exit(2)
 
     if options.human:
-        for group, systems in groups.iteritems():
-            print '[%s]\n%s\n' % (group, '\n'.join(systems))
+        for group, systems in groups.items():
+            print('[%s]\n%s\n' % (group, '\n'.join(systems)))
     else:
-        print json.dumps(dict([ (k, list(s)) for k, s in groups.iteritems() ]))
+        print(json.dumps(dict([ (k, list(s)) for k, s in groups.items() ])))
 
     sys.exit(0)
 
@@ -137,17 +137,17 @@
                 host_details = system
                 break
 
-    except (OSError), e:
-        print >> sys.stderr, 'Problem executing the command "%s inventory": %s' % \
-            (SW_REPORT, str(e))
+    except (OSError) as e:
+        print('Problem executing the command "%s inventory": %s' % \
+            (SW_REPORT, str(e)), file=sys.stderr)
         sys.exit(2)
     
     if options.human:
-        print 'Host: %s' % options.host
-        for k, v in host_details.iteritems():
-            print '  %s: %s' % (k, '\n    '.join(v.split(';')))
+        print('Host: %s' % options.host)
+        for k, v in host_details.items():
+            print('  %s: %s' % (k, '\n    '.join(v.split(';'))))
     else:
-        print json.dumps(host_details)
+        print(json.dumps(host_details))
 
     sys.exit(0)
 
--- ./plugins/inventory/ssh_config.py	(original)
+++ ./plugins/inventory/ssh_config.py	(refactored)
@@ -71,7 +71,7 @@
 def print_list():
     cfg = get_config()
     meta = {'hostvars': {}}
-    for alias, attributes in cfg.items():
+    for alias, attributes in list(cfg.items()):
         tmp_dict = {}
         for ssh_opt, ans_opt in _ssh_to_ansible:
             if ssh_opt in attributes:
@@ -79,12 +79,12 @@
         if tmp_dict:
             meta['hostvars'][alias] = tmp_dict
 
-    print json.dumps({_key: list(set(meta['hostvars'].keys())), '_meta': meta})
+    print(json.dumps({_key: list(set(meta['hostvars'].keys())), '_meta': meta}))
 
 
 def print_host(host):
     cfg = get_config()
-    print json.dumps(cfg[host])
+    print(json.dumps(cfg[host]))
 
 
 def get_args(args_list):
--- ./plugins/inventory/vagrant.py	(original)
+++ ./plugins/inventory/vagrant.py	(refactored)
@@ -106,7 +106,7 @@
     for data in ssh_config:
         hosts['vagrant'].append(data['HostName'])
 
-    print json.dumps(hosts)
+    print(json.dumps(hosts))
     sys.exit(1)
 
 # Get out the host details
@@ -115,13 +115,13 @@
     result = {}
     ssh_config = get_ssh_config()
 
-    details = filter(lambda x: (x['HostName'] == options.host), ssh_config)
+    details = [x for x in ssh_config if (x['HostName'] == options.host)]
     if len(details) > 0:
         #pass through the port, in case it's non standard.
         result = details[0]
         result['ansible_ssh_port'] = result['Port']
 
-    print json.dumps(result)
+    print(json.dumps(result))
     sys.exit(1)
 
 
--- ./plugins/inventory/vbox.py	(original)
+++ ./plugins/inventory/vbox.py	(refactored)
@@ -111,4 +111,4 @@
         inventory = get_hosts()
 
     import pprint
-    print pprint.pprint(inventory)
+    print(pprint.pprint(inventory))
--- ./plugins/inventory/vmware.py	(original)
+++ ./plugins/inventory/vmware.py	(refactored)
@@ -35,7 +35,7 @@
 import os
 import sys
 import time
-import ConfigParser
+import configparser
 
 # Disable logging message trigged by pSphere/suds.
 try:
@@ -57,7 +57,7 @@
 class VMwareInventory(object):
     
     def __init__(self, guests_only=None):
-        self.config = ConfigParser.SafeConfigParser()
+        self.config = configparser.SafeConfigParser()
         if os.environ.get('VMWARE_INI', ''):
             config_files = [os.environ['VMWARE_INI']]
         else:
@@ -126,14 +126,14 @@
         only string items are included as is; any other lists are discarded.
         '''
         items = []
-        for k, v in d.items():
+        for k, v in list(d.items()):
             if k.startswith('_'):
                 continue
             new_key = parent_key + sep + k if parent_key else k
             if isinstance(v, collections.MutableMapping):
-                items.extend(self._flatten_dict(v, new_key, sep).items())
+                items.extend(list(self._flatten_dict(v, new_key, sep).items()))
             elif isinstance(v, (list, tuple)):
-                if all([isinstance(x, str) for x in v]):
+                if all([isinstance(x, str) for x in v]):
                     items.append((new_key, v))
             else:
                 items.append((new_key, v))
@@ -147,7 +147,7 @@
         seen = seen or set()
         if isinstance(obj, ManagedObject):
             try:
-                obj_unicode = unicode(getattr(obj, 'name'))
+                obj_unicode = str(getattr(obj, 'name'))
             except AttributeError:
                 obj_unicode = ()
             if obj in seen:
@@ -164,7 +164,7 @@
                     obj_info = self._get_obj_info(val, depth - 1, seen)
                     if obj_info != ():
                         d[attr] = obj_info
-                except Exception, e:
+                except Exception as e:
                     pass
             return d
         elif isinstance(obj, SudsObject):
@@ -181,7 +181,7 @@
                 if obj_info != ():
                     l.append(obj_info)
             return l
-        elif isinstance(obj, (type(None), bool, int, long, float, str)):
+        elif isinstance(obj, (type(None), bool, int, float, str)):
             return obj
         else:
             return ()
@@ -199,16 +199,16 @@
                 host_info['%ss' % attr] = self._get_obj_info(value, depth=0)
             except AttributeError:
                 host_info['%ss' % attr] = []
-        for k, v in self._get_obj_info(host.summary, depth=0).items():
+        for k, v in list(self._get_obj_info(host.summary, depth=0).items()):
             if isinstance(v, collections.MutableMapping):
-                for k2, v2 in v.items():
+                for k2, v2 in list(v.items()):
                     host_info[k2] = v2
             elif k != 'host':
                 host_info[k] = v
         try:
             host_info['ipAddress'] = host.config.network.vnic[0].spec.ip.ipAddress
-        except Exception, e:
-            print >> sys.stderr, e
+        except Exception as e:
+            print(e, file=sys.stderr)
         host_info = self._flatten_dict(host_info, prefix)
         if ('%s_ipAddress' % prefix) in host_info:
             host_info['ansible_ssh_host'] = host_info['%s_ipAddress' % prefix]
@@ -235,9 +235,9 @@
             vm_info['guestState'] = vm.guest.guestState
         except AttributeError:
             vm_info['guestState'] = ''
-        for k, v in self._get_obj_info(vm.summary, depth=0).items():
+        for k, v in list(self._get_obj_info(vm.summary, depth=0).items()):
             if isinstance(v, collections.MutableMapping):
-                for k2, v2 in v.items():
+                for k2, v2 in list(v.items()):
                     if k2 == 'host':
                         k2 = 'hostSystem'
                     vm_info[k2] = v2
--- ./plugins/inventory/windows_azure.py	(original)
+++ ./plugins/inventory/windows_azure.py	(refactored)
@@ -39,7 +39,7 @@
 import sys
 import argparse
 import os
-from urlparse import urlparse
+from urllib.parse import urlparse
 from time import time
 try:
     import json
@@ -51,12 +51,12 @@
     from azure import WindowsAzureError
     from azure.servicemanagement import ServiceManagementService
 except ImportError as e:
-    print "failed=True msg='`azure` library required for this script'"
+    print("failed=True msg='`azure` library required for this script'")
     sys.exit(1)
 
 
 # Imports for ansible
-import ConfigParser
+import configparser
 
 class AzureInventory(object):
     def __init__(self):
@@ -89,7 +89,7 @@
             else:
                 data_to_print = self.json_format_dict(self.inventory, True)
 
-        print data_to_print
+        print(data_to_print)
 
     def get_images(self):
         images = []
@@ -110,7 +110,7 @@
 
     def read_settings(self):
         """Reads the settings from the .ini file."""
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         config.read(os.path.dirname(os.path.realpath(__file__)) + '/windows_azure.ini')
 
         # Credentials related
@@ -157,9 +157,9 @@
             for cloud_service in self.sms.list_hosted_services():
                 self.add_deployments(cloud_service)
         except WindowsAzureError as e:
-            print "Looks like Azure's API is down:"
-            print
-            print e
+            print("Looks like Azure's API is down:")
+            print()
+            print(e)
             sys.exit(1)
 
     def add_deployments(self, cloud_service):
@@ -169,9 +169,9 @@
                 if deployment.deployment_slot == "Production":
                     self.add_deployment(cloud_service, deployment)
         except WindowsAzureError as e:
-            print "Looks like Azure's API is down:"
-            print
-            print e
+            print("Looks like Azure's API is down:")
+            print()
+            print(e)
             sys.exit(1)
 
     def add_deployment(self, cloud_service, deployment):
--- ./plugins/inventory/zabbix.py	(original)
+++ ./plugins/inventory/zabbix.py	(refactored)
@@ -32,12 +32,12 @@
 
 import os, sys
 import argparse
-import ConfigParser
+import configparser
 
 try:
     from zabbix_api import ZabbixAPI
 except:
-    print >> sys.stderr, "Error: Zabbix API library must be installed: pip install zabbix-api."
+    print("Error: Zabbix API library must be installed: pip install zabbix-api.", file=sys.stderr)
     sys.exit(1)
 
 try:
@@ -48,7 +48,7 @@
 class ZabbixInventory(object):
 
     def read_settings(self):
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         config.read(os.path.dirname(os.path.realpath(__file__)) + '/zabbix.ini')
         # server
         if config.has_option('zabbix', 'server'):
@@ -109,24 +109,24 @@
             try:
                 api = ZabbixAPI(server=self.zabbix_server)
                 api.login(user=self.zabbix_username, password=self.zabbix_password)
-            except BaseException, e:
-                print >> sys.stderr, "Error: Could not login to Zabbix server. Check your zabbix.ini."
+            except BaseException as e:
+                print("Error: Could not login to Zabbix server. Check your zabbix.ini.", file=sys.stderr)
                 sys.exit(1)
 
             if self.options.host:
                 data = self.get_host(api, self.options.host)
-                print json.dumps(data, indent=2)
+                print(json.dumps(data, indent=2))
 
             elif self.options.list:
                 data = self.get_list(api)
-                print json.dumps(data, indent=2)
+                print(json.dumps(data, indent=2))
 
             else:
-                print >> sys.stderr, "usage: --list  ..OR.. --host <hostname>"
+                print("usage: --list  ..OR.. --host <hostname>", file=sys.stderr)
                 sys.exit(1)
 
         else:
-            print >> sys.stderr, "Error: Configuration of server and credentials are required. See zabbix.ini."
+            print("Error: Configuration of server and credentials are required. See zabbix.ini.", file=sys.stderr)
             sys.exit(1)
 
 ZabbixInventory()
--- ./plugins/inventory/zone.py	(original)
+++ ./plugins/inventory/zone.py	(refactored)
@@ -36,8 +36,8 @@
 result['all']['vars']['ansible_connection'] = 'zone'
 
 if len(sys.argv) == 2 and sys.argv[1] == '--list':
-    print json.dumps(result)
+    print(json.dumps(result))
 elif len(sys.argv) == 3 and sys.argv[1] == '--host':
-    print json.dumps({'ansible_connection': 'zone'})
+    print(json.dumps({'ansible_connection': 'zone'}))
 else:
-    print "Need an argument, either --list or --host <host>"
+    print("Need an argument, either --list or --host <host>")
--- ./test/integration/cleanup_ec2.py	(original)
+++ ./test/integration/cleanup_ec2.py	(refactored)
@@ -25,7 +25,7 @@
     try:
       eip_log = open(opts.eip_log, 'r').read().splitlines()
     except IOError:
-      print opts.eip_log, 'not found.'
+      print(opts.eip_log, 'not found.')
       return
 
     for item in get_func():
@@ -40,15 +40,15 @@
 
 def prompt_and_delete(item, prompt, assumeyes):
     if not assumeyes:
-        assumeyes = raw_input(prompt).lower() == 'y'
+        assumeyes = input(prompt).lower() == 'y'
     assert hasattr(item, 'delete') or hasattr(item, 'terminate') , "Class <%s> has no delete or terminate attribute" % item.__class__
     if assumeyes:
         if  hasattr(item, 'delete'):
             item.delete()
-            print ("Deleted %s" % item)
+            print(("Deleted %s" % item))
         if  hasattr(item, 'terminate'):
             item.terminate()
-            print ("Terminated %s" % item)
+            print(("Terminated %s" % item))
 
 def parse_args():
     # Load details from credentials.yml
@@ -143,5 +143,5 @@
         filters = {"tag:Name":opts.match_re.replace('^',''), "instance-state-name": ['running', 'pending', 'stopped' ]}
         delete_aws_instances(aws.get_all_instances(filters=filters), opts)
 
-    except KeyboardInterrupt, e:
-        print "\nExiting on user command."
+    except KeyboardInterrupt as e:
+        print("\nExiting on user command.")
--- ./test/integration/cleanup_gce.py	(original)
+++ ./test/integration/cleanup_gce.py	(refactored)
@@ -17,8 +17,8 @@
             ResourceExistsError, ResourceInUseError, ResourceNotFoundError
     _ = Provider.GCE
 except ImportError:
-    print("failed=True " + \
-        "msg='libcloud with GCE support (0.13.3+) required for this module'")
+    print(("failed=True " + \
+        "msg='libcloud with GCE support (0.13.3+) required for this module'"))
     sys.exit(1)
 
 import gce_credentials
@@ -32,11 +32,11 @@
 
 def prompt_and_delete(item, prompt, assumeyes):
     if not assumeyes:
-        assumeyes = raw_input(prompt).lower() == 'y'
+        assumeyes = input(prompt).lower() == 'y'
     assert hasattr(item, 'destroy'), "Class <%s> has no delete attribute" % item.__class__
     if assumeyes:
         item.destroy()
-        print ("Deleted %s" % item)
+        print(("Deleted %s" % item))
 
 def parse_args():
     parser = optparse.OptionParser(usage="%s [options]" % (sys.argv[0],),
@@ -73,5 +73,5 @@
       delete_gce_resources(get_snapshots, 'name', opts)
       # Delete matching disks
       delete_gce_resources(gce.list_volumes, 'name', opts)
-    except KeyboardInterrupt, e:
-        print "\nExiting on user command."
+    except KeyboardInterrupt as e:
+        print("\nExiting on user command.")
--- ./test/integration/cleanup_rax.py	(original)
+++ ./test/integration/cleanup_rax.py	(refactored)
@@ -53,21 +53,21 @@
 
 def prompt_and_delete(item, prompt, assumeyes):
     if not assumeyes:
-        assumeyes = raw_input(prompt).lower() == 'y'
+        assumeyes = input(prompt).lower() == 'y'
     assert (hasattr(item, 'delete') or hasattr(item, 'terminate'),
             "Class <%s> has no delete or terminate attribute" % item.__class__)
     if assumeyes:
         if hasattr(item, 'delete'):
             item.delete()
-            print ("Deleted %s" % item)
+            print(("Deleted %s" % item))
         if hasattr(item, 'terminate'):
             item.terminate()
-            print ("Terminated %s" % item)
+            print(("Terminated %s" % item))
 
 
 def delete_rax(args):
     """Function for deleting CloudServers"""
-    print ("--- Cleaning CloudServers matching '%s'" % args.match_re)
+    print(("--- Cleaning CloudServers matching '%s'" % args.match_re))
     search_opts = dict(name='^%s' % args.match_re)
     for region in pyrax.identity.services.compute.regions:
         cs = pyrax.connect_to_cloudservers(region=region)
@@ -80,7 +80,7 @@
 
 def delete_rax_clb(args):
     """Function for deleting Cloud Load Balancers"""
-    print ("--- Cleaning Cloud Load Balancers matching '%s'" % args.match_re)
+    print(("--- Cleaning Cloud Load Balancers matching '%s'" % args.match_re))
     for region in pyrax.identity.services.load_balancer.regions:
         clb = pyrax.connect_to_cloud_loadbalancers(region=region)
         for lb in rax_list_iterator(clb):
@@ -92,7 +92,7 @@
 
 def delete_rax_keypair(args):
     """Function for deleting Rackspace Key pairs"""
-    print ("--- Cleaning Key Pairs matching '%s'" % args.match_re)
+    print(("--- Cleaning Key Pairs matching '%s'" % args.match_re))
     for region in pyrax.identity.services.compute.regions:
         cs = pyrax.connect_to_cloudservers(region=region)
         for keypair in cs.keypairs.list():
@@ -104,7 +104,7 @@
 
 def delete_rax_network(args):
     """Function for deleting Cloud Networks"""
-    print ("--- Cleaning Cloud Networks matching '%s'" % args.match_re)
+    print(("--- Cleaning Cloud Networks matching '%s'" % args.match_re))
     for region in pyrax.identity.services.network.regions:
         cnw = pyrax.connect_to_cloud_networks(region=region)
         for network in cnw.list():
@@ -116,7 +116,7 @@
 
 def delete_rax_cbs(args):
     """Function for deleting Cloud Networks"""
-    print ("--- Cleaning Cloud Block Storage matching '%s'" % args.match_re)
+    print(("--- Cleaning Cloud Block Storage matching '%s'" % args.match_re))
     for region in pyrax.identity.services.network.regions:
         cbs = pyrax.connect_to_cloud_blockstorage(region=region)
         for volume in cbs.list():
@@ -128,7 +128,7 @@
 
 def delete_rax_cdb(args):
     """Function for deleting Cloud Databases"""
-    print ("--- Cleaning Cloud Databases matching '%s'" % args.match_re)
+    print(("--- Cleaning Cloud Databases matching '%s'" % args.match_re))
     for region in pyrax.identity.services.database.regions:
         cdb = pyrax.connect_to_cloud_databases(region=region)
         for db in rax_list_iterator(cdb):
@@ -145,12 +145,12 @@
     args = parse_args()
     authenticate()
 
-    funcs = [f for n, f in globals().items() if n.startswith('delete_rax')]
+    funcs = [f for n, f in list(globals().items()) if n.startswith('delete_rax')]
     for func in sorted(funcs, key=lambda f: f.__name__):
         try:
             func(args)
         except Exception as e:
-            print ("---- %s failed (%s)" % (func.__name__, e.message))
+            print(("---- %s failed (%s)" % (func.__name__, e.message)))
 
 
 if __name__ == '__main__':
--- ./test/integration/consul_running.py	(original)
+++ ./test/integration/consul_running.py	(refactored)
@@ -6,6 +6,6 @@
         import consul
         consul = consul.Consul(host='0.0.0.0', port=8500)
         consul.catalog.nodes()
-        print "True"
+        print("True")
     except:
         pass
--- ./test/integration/gce_credentials.py	(original)
+++ ./test/integration/gce_credentials.py	(refactored)
@@ -7,8 +7,8 @@
     from libcloud.compute.providers import get_driver
     _ = Provider.GCE
 except ImportError:
-    print("failed=True " + \
-        "msg='libcloud with GCE support (0.13.3+) required for this module'")
+    print(("failed=True " + \
+        "msg='libcloud with GCE support (0.13.3+) required for this module'"))
     sys.exit(1)
 
 
--- ./test/integration/setup_gce.py	(original)
+++ ./test/integration/setup_gce.py	(refactored)
@@ -38,5 +38,5 @@
       gce.create_volume_snapshot(base_volume, name=prefix+'-snapshot')
       gce.create_volume(
           size=10, name=prefix+'-extra', location='us-central1-a')
-    except KeyboardInterrupt, e:
-        print "\nExiting on user command."
+    except KeyboardInterrupt as e:
+        print("\nExiting on user command.")
--- ./test/units/TestConstants.py	(original)
+++ ./test/units/TestConstants.py	(refactored)
@@ -3,7 +3,7 @@
 import unittest
 
 from ansible.constants import get_config
-import ConfigParser
+import configparser
 import random
 import string
 import os
@@ -12,7 +12,7 @@
 def random_string(length):
     return ''.join(random.choice(string.ascii_uppercase) for x in range(6))
 
-p = ConfigParser.ConfigParser()
+p = configparser.ConfigParser()
 p.read(os.path.join(os.path.dirname(__file__), 'ansible.cfg'))
 
 class TestConstants(unittest.TestCase):
@@ -39,7 +39,7 @@
         
         res = get_config(p, 'defaults', 'test_key', env_var, 'default')
 
-        print res
+        print(res)
         assert res == 'test_value'
 
 
--- ./test/units/TestInventory.py	(original)
+++ ./test/units/TestInventory.py	(refactored)
@@ -18,17 +18,17 @@
         self.inventory_script           = os.path.join(self.test_dir, 'inventory_api.py')
         self.inventory_dir              = os.path.join(self.test_dir, 'inventory_dir')
 
-        os.chmod(self.inventory_script, 0755)
+        os.chmod(self.inventory_script, 0o755)
 
     def tearDown(self):
-        os.chmod(self.inventory_script, 0644)
+        os.chmod(self.inventory_script, 0o644)
 
     def compare(self, left, right, sort=True):
         if sort:
             left = sorted(left)
             right = sorted(right)
-        print left
-        print right
+        print(left)
+        print(right)
         assert left == right
 
     def empty_inventory(self):
@@ -233,7 +233,7 @@
         inventory = self.complex_inventory()
 
         vars = inventory.get_variables('rtp_a')
-        print vars
+        print(vars)
 
         expected = dict(
             a=1, b=2, c=3, d=10002, e=10003, f='10004 != 10005',
@@ -243,8 +243,8 @@
             inventory_hostname='rtp_a', inventory_hostname_short='rtp_a',
             group_names=[ 'eastcoast', 'nc', 'redundantgroup', 'redundantgroup2', 'redundantgroup3', 'rtp', 'us' ]
         )
-        print vars
-        print expected
+        print(vars)
+        print(expected)
         assert vars == expected
 
     def test_complex_group_names(self):
@@ -254,7 +254,7 @@
             'host2': [ 'role1', 'role2' ],
             'host3': [ 'role2', 'role3' ]
         }
-        for host, roles in tests.iteritems():
+        for host, roles in tests.items():
             group_names = inventory.get_variables(host)['group_names']
             assert sorted(group_names) == sorted(roles)
 
@@ -262,24 +262,24 @@
         inventory = self.complex_inventory()
         hosts = inventory.list_hosts("nc:florida:!triangle:!orlando")
         expected_hosts = ['miami', 'rtp_a', 'rtp_b', 'rtp_c']
-        print "HOSTS=%s" % sorted(hosts)
-        print "EXPECTED=%s" % sorted(expected_hosts)
+        print("HOSTS=%s" % sorted(hosts))
+        print("EXPECTED=%s" % sorted(expected_hosts))
         assert sorted(hosts) == sorted(expected_hosts)
 
     def test_regex_exclude(self):
         inventory = self.complex_inventory()
         hosts = inventory.list_hosts("~rtp_[ac]")
         expected_hosts = ['rtp_a', 'rtp_c']
-        print "HOSTS=%s" % sorted(hosts)
-        print "EXPECTED=%s" % sorted(expected_hosts)
+        print("HOSTS=%s" % sorted(hosts))
+        print("EXPECTED=%s" % sorted(expected_hosts))
         assert sorted(hosts) == sorted(expected_hosts)
 
     def test_regex_grouping(self):
         inventory = self.simple_inventory()
         hosts = inventory.list_hosts("~(cer[a-z]|berc)(erus00[13])")
         expected_hosts = ['cerberus001', 'cerberus003']
-        print "HOSTS=%s" % sorted(hosts)
-        print "EXPECTED=%s" % sorted(expected_hosts)
+        print("HOSTS=%s" % sorted(hosts))
+        print("EXPECTED=%s" % sorted(expected_hosts))
         assert sorted(hosts) == sorted(expected_hosts)
 
     def test_complex_enumeration(self):
@@ -351,8 +351,8 @@
 
         expected_hosts=['jupiter', 'saturn', 'zeus', 'hera', 'poseidon', 'thor', 'odin', 'loki']
 
-        print "Expected: %s"%(expected_hosts)
-        print "Got     : %s"%(hosts)
+        print("Expected: %s"%(expected_hosts))
+        print("Got     : %s"%(hosts))
         assert sorted(hosts) == sorted(expected_hosts)
 
     def test_script_all(self):
@@ -396,7 +396,7 @@
         inventory = self.script_inventory()
         vars = inventory.get_variables('thor')
 
-        print "VARS=%s" % vars
+        print("VARS=%s" % vars)
 
         assert vars == {'hammer':True,
                         'group_names': ['norse'],
@@ -415,7 +415,7 @@
         inventory = self.script_inventory()
         vars = inventory.get_variables('zeus')
 
-        print "VARS=%s" % vars
+        print("VARS=%s" % vars)
 
         assert vars == {'inventory_hostname': 'zeus',
                         'inventory_hostname_short': 'zeus',
@@ -436,8 +436,8 @@
                          'group_names': ['greek', 'major-god'],
                          'var_a': '3#4'}
 
-        print "HOST     VARS=%s" % host_vars
-        print "EXPECTED VARS=%s" % expected_vars
+        print("HOST     VARS=%s" % host_vars)
+        print("EXPECTED VARS=%s" % expected_vars)
 
         assert host_vars == expected_vars
 
@@ -445,7 +445,7 @@
         inventory = self.dir_inventory()
         group_greek = inventory.get_hosts('greek')
         actual_host_names = [host.name for host in group_greek]
-        print "greek : %s " % actual_host_names
+        print("greek : %s " % actual_host_names)
         assert actual_host_names == ['zeus', 'morpheus']
 
     def test_dir_inventory_skip_extension(self):
@@ -464,8 +464,8 @@
         actual_groups = {}
         for group in inventory.get_groups():
             actual_groups[group.name] = sorted([h.name for h in group.get_hosts()])
-            print "INVENTORY groups[%s].hosts=%s" % (group.name, actual_groups[group.name])
-            print "EXPECTED  groups[%s].hosts=%s" % (group.name, expected_groups[group.name])
+            print("INVENTORY groups[%s].hosts=%s" % (group.name, actual_groups[group.name]))
+            print("EXPECTED  groups[%s].hosts=%s" % (group.name, expected_groups[group.name]))
 
         assert actual_groups == expected_groups
 
@@ -476,12 +476,12 @@
                                     'zeus': ['all', 'greek', 'major-god']}
 
         actual_groups_for_host = {}
-        for (host, expected) in expected_groups_for_host.iteritems():
+        for (host, expected) in expected_groups_for_host.items():
             groups = inventory.groups_for_host(host)
             names = sorted([g.name for g in groups])
             actual_groups_for_host[host] = names
-            print "INVENTORY groups_for_host(%s)=%s" % (host, names)
-            print "EXPECTED  groups_for_host(%s)=%s" % (host, expected)
+            print("INVENTORY groups_for_host(%s)=%s" % (host, names))
+            print("EXPECTED  groups_for_host(%s)=%s" % (host, expected))
 
         assert actual_groups_for_host == expected_groups_for_host
 
@@ -496,10 +496,10 @@
                            'greek': ['morpheus', 'zeus'],
                            'ungrouped': []}
 
-        for (name, expected_hosts) in expected_groups.iteritems():
+        for (name, expected_hosts) in expected_groups.items():
             inventory_groups[name] = sorted(inventory_groups.get(name, []))
-            print "INVENTORY groups_list['%s']=%s" % (name, inventory_groups[name])
-            print "EXPECTED  groups_list['%s']=%s" % (name, expected_hosts)
+            print("INVENTORY groups_list['%s']=%s" % (name, inventory_groups[name]))
+            print("EXPECTED  groups_list['%s']=%s" % (name, expected_hosts))
 
         assert inventory_groups == expected_groups
 
--- ./test/units/TestModuleUtilsDatabase.py	(original)
+++ ./test/units/TestModuleUtilsDatabase.py	(refactored)
@@ -12,7 +12,7 @@
         try:
             callable(*a, **kw)
         except expected as e:
-            if isinstance(regexp, str):
+            if isinstance(regexp, str):
                 regexp = re.compile(regexp)
             if not regexp.search(str(e)):
                 raise Exception('"%s" does not match "%s"' %
--- ./test/units/TestModules.py	(original)
+++ ./test/units/TestModules.py	(refactored)
@@ -27,6 +27,6 @@
         for m in module_list:
             try:
                 ast.parse(''.join(open(m)))
-            except Exception, e:
+            except Exception as e:
                 ERRORS.append((m, e))
         assert len(ERRORS) == 0, "get_docstring errors: %s" % ERRORS
--- ./test/units/TestPlayVarsFiles.py	(original)
+++ ./test/units/TestPlayVarsFiles.py	(refactored)
@@ -219,7 +219,7 @@
 
         try:
             play = Play(playbook, ds, basedir)
-        except ansible.errors.AnsibleError, e:
+        except ansible.errors.AnsibleError as e:
             error_hit = True
             error_msg = e
 
--- ./test/units/TestUtils.py	(original)
+++ ./test/units/TestUtils.py	(refactored)
@@ -9,7 +9,7 @@
 import yaml
 import passlib.hash
 import string
-import StringIO
+import io
 import copy
 import tempfile
 import shutil
@@ -26,7 +26,8 @@
 from ansible import __version__
 
 import sys
-reload(sys)
+import imp
+imp.reload(sys)
 sys.setdefaultencoding("utf8") 
 
 class TestUtils(unittest.TestCase):
@@ -167,9 +168,9 @@
 
     def test_check_conditional_jinja2_unicode(self):
         self.assertEqual(ansible.utils.check_conditional(
-            u'"\u00df"', '/', {}), True)
-        self.assertEqual(ansible.utils.check_conditional(
-            u'var == "\u00df"', '/', {'var': u'\u00df'}), True)
+            '"\u00df"', '/', {}), True)
+        self.assertEqual(ansible.utils.check_conditional(
+            'var == "\u00df"', '/', {'var': '\u00df'}), True)
 
 
     #####################################
@@ -185,7 +186,7 @@
     def test_jsonify(self):
         self.assertEqual(ansible.utils.jsonify(None), '{}')
         self.assertEqual(ansible.utils.jsonify(dict(foo='bar', baz=['qux'])), '{"baz": ["qux"], "foo": "bar"}')
-        expected = u'{"baz":["qux"],"foo":"bar"}'
+        expected = '{"baz":["qux"],"foo":"bar"}'
         self.assertEqual("".join(ansible.utils.jsonify(dict(foo='bar', baz=['qux']), format=True).split()), expected)
 
     def test_is_failed(self):
@@ -227,7 +228,7 @@
         # No closing quotation
         try:
             rc = ansible.utils.parse_json('foo=bar "')
-            print rc
+            print(rc)
         except ValueError:
             pass
         else:
@@ -289,10 +290,10 @@
         data = 'foo: bar\n baz: qux'
         try:
             ansible.utils.parse_yaml(data)
-        except yaml.YAMLError, exc:
+        except yaml.YAMLError as exc:
             try:
                 ansible.utils.process_yaml_error(exc, data, __file__)
-            except ansible.errors.AnsibleYAMLValidationFailed, e:
+            except ansible.errors.AnsibleYAMLValidationFailed as e:
                 self.assertTrue('Syntax Error while loading' in str(e))
             else:
                 raise AssertionError('Incorrect exception, expected AnsibleYAMLValidationFailed')
@@ -300,10 +301,10 @@
         data = 'foo: bar\n baz: {{qux}}'
         try:
             ansible.utils.parse_yaml(data)
-        except yaml.YAMLError, exc:
+        except yaml.YAMLError as exc:
             try:
                 ansible.utils.process_yaml_error(exc, data, __file__)
-            except ansible.errors.AnsibleYAMLValidationFailed, e:
+            except ansible.errors.AnsibleYAMLValidationFailed as e:
                 self.assertTrue('Syntax Error while loading' in str(e))
             else:
                 raise AssertionError('Incorrect exception, expected AnsibleYAMLValidationFailed')
@@ -311,10 +312,10 @@
         data = '\xFF'
         try:
             ansible.utils.parse_yaml(data)
-        except yaml.YAMLError, exc:
+        except yaml.YAMLError as exc:
             try:
                 ansible.utils.process_yaml_error(exc, data, __file__)
-            except ansible.errors.AnsibleYAMLValidationFailed, e:
+            except ansible.errors.AnsibleYAMLValidationFailed as e:
                 self.assertTrue('Check over' in str(e))
             else:
                 raise AssertionError('Incorrect exception, expected AnsibleYAMLValidationFailed')
@@ -322,10 +323,10 @@
         data = '\xFF'
         try:
             ansible.utils.parse_yaml(data)
-        except yaml.YAMLError, exc:
+        except yaml.YAMLError as exc:
             try:
                 ansible.utils.process_yaml_error(exc, data, None)
-            except ansible.errors.AnsibleYAMLValidationFailed, e:
+            except ansible.errors.AnsibleYAMLValidationFailed as e:
                 self.assertTrue('Could not parse YAML.' in str(e))
             else:
                 raise AssertionError('Incorrect exception, expected AnsibleYAMLValidationFailed')
@@ -351,7 +352,7 @@
 
         try:
             ansible.utils.parse_yaml_from_file(broken)
-        except ansible.errors.AnsibleYAMLValidationFailed, e:
+        except ansible.errors.AnsibleYAMLValidationFailed as e:
             self.assertTrue('Syntax Error while loading' in str(e))
         else:
             raise AssertionError('Incorrect exception, expected AnsibleYAMLValidationFailed')
@@ -509,20 +510,20 @@
         self.assertTrue('echo BECOME-SUCCESS-' in cmd[0] and cmd[2].startswith('BECOME-SUCCESS-'))
 
     def test_to_unicode(self):
-        uni = ansible.utils.unicode.to_unicode(u'ansible')
-        self.assertTrue(isinstance(uni, unicode))
-        self.assertEqual(uni, u'ansible')
-
-        none = ansible.utils.unicode.to_unicode(None, nonstring='passthru')
+        uni = ansible.utils.str.to_unicode('ansible')
+        self.assertTrue(isinstance(uni, str))
+        self.assertEqual(uni, 'ansible')
+
+        none = ansible.utils.str.to_unicode(None, nonstring='passthru')
         self.assertTrue(isinstance(none, type(None)))
         self.assertTrue(none is None)
 
-        utf8 = ansible.utils.unicode.to_unicode('ansible')
-        self.assertTrue(isinstance(utf8, unicode))
-        self.assertEqual(utf8, u'ansible')
+        utf8 = ansible.utils.str.to_unicode('ansible')
+        self.assertTrue(isinstance(utf8, str))
+        self.assertEqual(utf8, 'ansible')
 
     def test_is_list_of_strings(self):
-        self.assertEqual(ansible.utils.is_list_of_strings(['foo', 'bar', u'baz']), True)
+        self.assertEqual(ansible.utils.is_list_of_strings(['foo', 'bar', 'baz']), True)
         self.assertEqual(ansible.utils.is_list_of_strings(['foo', 'bar', True]), False)
         self.assertEqual(ansible.utils.is_list_of_strings(['one', 2, 'three']), False)
 
@@ -569,19 +570,19 @@
 
     def test_deprecated(self):
         sys_stderr = sys.stderr
-        sys.stderr = StringIO.StringIO()
+        sys.stderr = io.StringIO()
         ansible.utils.deprecated('Ack!', '0.0')
         out = sys.stderr.getvalue()
         self.assertTrue('0.0' in out)
         self.assertTrue('[DEPRECATION WARNING]' in out)
 
-        sys.stderr = StringIO.StringIO()
+        sys.stderr = io.StringIO()
         ansible.utils.deprecated('Ack!', None)
         out = sys.stderr.getvalue()
         self.assertTrue('0.0' not in out)
         self.assertTrue('[DEPRECATION WARNING]' in out)
 
-        sys.stderr = StringIO.StringIO()
+        sys.stderr = io.StringIO()
         warnings = C.DEPRECATION_WARNINGS
         C.DEPRECATION_WARNINGS = False
         ansible.utils.deprecated('Ack!', None)
@@ -593,7 +594,7 @@
 
         try:
             ansible.utils.deprecated('Ack!', '0.0', True)
-        except ansible.errors.AnsibleError, e:
+        except ansible.errors.AnsibleError as e:
             self.assertTrue('0.0' not in str(e))
             self.assertTrue('[DEPRECATED]' in str(e))
         else:
@@ -601,7 +602,7 @@
 
     def test_warning(self):
         sys_stderr = sys.stderr
-        sys.stderr = StringIO.StringIO()
+        sys.stderr = io.StringIO()
         ansible.utils.warning('ANSIBLE')
         out = sys.stderr.getvalue()
         sys.stderr = sys_stderr
@@ -621,7 +622,7 @@
 
     def test_err(self):
         sys_stderr = sys.stderr
-        sys.stderr = StringIO.StringIO()
+        sys.stderr = io.StringIO()
         ansible.utils.err('ANSIBLE')
         out = sys.stderr.getvalue()
         sys.stderr = sys_stderr
@@ -629,10 +630,10 @@
 
     def test_exit(self):
         sys_stderr = sys.stderr
-        sys.stderr = StringIO.StringIO()
+        sys.stderr = io.StringIO()
         try:
             ansible.utils.exit('ansible')
-        except SystemExit, e:
+        except SystemExit as e:
             self.assertEqual(e.code, 1)
             self.assertEqual(sys.stderr.getvalue(), 'ansible\n')
         else:
@@ -672,15 +673,15 @@
         del diff[0]
         del diff[0]
         diff = '\n'.join(diff)
-        self.assertEqual(diff, unicode(standard_expected))
+        self.assertEqual(diff, str(standard_expected))
 
     def test_split_args(self):
         # split_args is a smarter shlex.split for the needs of the way ansible uses it
 
         def _split_info(input, desired, actual):
-            print "SENT: ", input
-            print "WANT: ", desired 
-            print "GOT: ", actual
+            print("SENT: ", input)
+            print("WANT: ", desired) 
+            print("GOT: ", actual)
 
         def _test_combo(input, desired):
             actual = split_args(input)
--- ./test/units/TestUtilsStringFunctions.py	(original)
+++ ./test/units/TestUtilsStringFunctions.py	(refactored)
@@ -7,7 +7,7 @@
 import yaml
 import passlib.hash
 import string
-import StringIO
+import io
 import copy
 
 from nose.plugins.skip import SkipTest
@@ -20,7 +20,8 @@
 from ansible import __version__
 
 import sys
-reload(sys)
+import imp
+imp.reload(sys)
 sys.setdefaultencoding("utf8") 
 
 class TestUtilsStringFunctions(unittest.TestCase):
--- ./test/units/TestVault.py	(original)
+++ ./test/units/TestVault.py	(refactored)
@@ -116,7 +116,7 @@
         error_hit = False
         try:
             enc_data = v.encrypt(data)
-        except errors.AnsibleError, e:
+        except errors.AnsibleError as e:
             error_hit = True
         assert error_hit, "No error was thrown when trying to encrypt data with a header"    
 
@@ -128,7 +128,7 @@
         error_hit = False
         try:
             dec_data = v.decrypt(data)
-        except errors.AnsibleError, e:
+        except errors.AnsibleError as e:
             error_hit = True
         assert error_hit, "No error was thrown when trying to decrypt data without a header"    
 
@@ -141,7 +141,7 @@
         error_hit = False
         try:
             enc_data = v.encrypt(data)
-        except errors.AnsibleError, e:
+        except errors.AnsibleError as e:
             error_hit = True
         assert not error_hit, "An error was thrown when trying to encrypt data without the cipher set"    
         assert v.cipher_name == "AES256", "cipher name is not set to AES256: %s" % v.cipher_name               
--- ./test/units/TestVaultEditor.py	(original)
+++ ./test/units/TestVaultEditor.py	(refactored)
@@ -74,7 +74,7 @@
         error_hit = False
         try:        
             ve.decrypt_file()
-        except errors.AnsibleError, e:
+        except errors.AnsibleError as e:
             error_hit = True
 
         # verify decrypted content
@@ -99,7 +99,7 @@
         error_hit = False
         try:
             ve.decrypt_file()
-        except errors.AnsibleError, e:
+        except errors.AnsibleError as e:
             error_hit = True
 
         # verify decrypted content
@@ -125,7 +125,7 @@
         error_hit = False
         try:
             ve.decrypt_file()
-        except errors.AnsibleError, e:
+        except errors.AnsibleError as e:
             error_hit = True
 
         # verify decrypted content
@@ -153,7 +153,7 @@
         error_hit = False
         try:        
             ve.rekey_file('ansible2')
-        except errors.AnsibleError, e:
+        except errors.AnsibleError as e:
             error_hit = True
 
         # verify decrypted content
@@ -170,7 +170,7 @@
         error_hit = False
         try:
             dec_data = vl.decrypt(fdata)
-        except errors.AnsibleError, e:
+        except errors.AnsibleError as e:
             error_hit = True
 
         assert vl.cipher_name == "AES256", "wrong cipher name set after rekey: %s" % vl.cipher_name
--- ./test/units/inventory_test_data/inventory_api.py	(original)
+++ ./test/units/inventory_test_data/inventory_api.py	(refactored)
@@ -27,7 +27,7 @@
 }
 
 if options.list_hosts == True:
-    print json.dumps(systems)
+    print(json.dumps(systems))
     sys.exit(0)
 
 if options.host is not None:
@@ -35,9 +35,9 @@
         k,v = options.extra.split("=")
         variables[options.host][k] = v
     if options.host in variables:
-        print json.dumps(variables[options.host])
+        print(json.dumps(variables[options.host]))
     else:
-        print "{}"
+        print("{}")
     sys.exit(0)
 
 parser.print_help()
--- ./test/units/parsing/test_unquote.py	(original)
+++ ./test/units/parsing/test_unquote.py	(refactored)
@@ -30,24 +30,24 @@
 # http://nose.readthedocs.org/en/latest/writing_tests.html#test-generators
 class TestUnquote:
     UNQUOTE_DATA = (
-            (u'1', u'1'),
-            (u'\'1\'', u'1'),
-            (u'"1"', u'1'),
-            (u'"1 \'2\'"', u'1 \'2\''),
-            (u'\'1 "2"\'', u'1 "2"'),
-            (u'\'1 \'2\'\'', u'1 \'2\''),
-            (u'"1\\"', u'"1\\"'),
-            (u'\'1\\\'', u'\'1\\\''),
-            (u'"1 \\"2\\" 3"', u'1 \\"2\\" 3'),
-            (u'\'1 \\\'2\\\' 3\'', u'1 \\\'2\\\' 3'),
-            (u'"', u'"'),
-            (u'\'', u'\''),
+            ('1', '1'),
+            ('\'1\'', '1'),
+            ('"1"', '1'),
+            ('"1 \'2\'"', '1 \'2\''),
+            ('\'1 "2"\'', '1 "2"'),
+            ('\'1 \'2\'\'', '1 \'2\''),
+            ('"1\\"', '"1\\"'),
+            ('\'1\\\'', '\'1\\\''),
+            ('"1 \\"2\\" 3"', '1 \\"2\\" 3'),
+            ('\'1 \\\'2\\\' 3\'', '1 \\\'2\\\' 3'),
+            ('"', '"'),
+            ('\'', '\''),
             # Not entirely sure these are good but they match the current
             # behaviour
-            (u'"1""2"', u'1""2'),
-            (u'\'1\'\'2\'', u'1\'\'2'),
-            (u'"1" 2 "3"', u'1" 2 "3'),
-            (u'"1"\'2\'"3"', u'1"\'2\'"3'),
+            ('"1""2"', '1""2'),
+            ('\'1\'\'2\'', '1\'\'2'),
+            ('"1" 2 "3"', '1" 2 "3'),
+            ('"1"\'2\'"3"', '1"\'2\'"3'),
             )
 
     def check_unquote(self, quoted, expected):
